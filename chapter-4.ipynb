{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a90ac87",
   "metadata": {},
   "source": [
    "[Back to Table of Contents](https://www.shannonmburns.com/Psyc158/intro.html)\n",
    "\n",
    "[Previous: Chapter 3 - Organizing Data](https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-3.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907352d0",
   "metadata": {},
   "source": [
    "# Chapter 4 - Cleaning Data\n",
    "\n",
    "The scientific study of humans is a messy process. They don't always understand what we're asking in a survey, or do what we want them to do in a behavioral study. Some people are nervous of looking a certain way, so will answer questions not as they truly believe but as they want other people to think of them. Other people just want to finish the study as fast as possible and get paid, so they complete tasks without paying much attention. Sometimes, participants don't want to answer a question at all. Other times we the researchers made a mistake in creating the study in the first place.\n",
    "\n",
    "For these reasons, the preparation of human data for analysis - called **data cleaning** - is an important skill. It is the process of reorganizing a dataset so that it most closely resembles the true values we want to analyze, in a format that works for our chosen analysis process. Data cleaning is also a time consuming process. Analysis of any research study is often 80%+ data cleaning with a much smaller proportion of time dedicated to running models or testing hypotheses. \n",
    "\n",
    "The difference between clean and dirty data can be the difference between a successful research study and noisy data that no one can understand. In this chapter, we will spend time learning the most helpful data cleaning steps for psychological data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9efbca",
   "metadata": {},
   "source": [
    "## 4.1 Subsetting data\n",
    "\n",
    "Some research studies are simple to conduct, with just a couple variables recorded. Other studies can be massive endeavors with many variables collected at once for the purpose of several different hypotheses. \n",
    "\n",
    "For example, the [General Social Survey](https://gss.norc.org/) is a nationally representative survey run every year in the US since 1972. It collects data from hundreds of thousands of people on hundreds of variables, including demographics, behaviors, and attitudes relevant to US society. It has provided data for more than 130 research papers that all studied a different hypothesis. \n",
    "\n",
    "That's a lot of data to manage! For this reason, sometimes you want to focus on viewing only a subset of your variables in a data frame. To continue our use of the ```tetrismemories``` dataset from last chapter, you might care about only the hypothesis regarding different study conditions affecting number of intrusive memories, and thus only the variables ```condition``` and ```instrusive_memories```. The data frame would be easier to read if it only included these variables and not all the others. Let's open up that dataset and see where these variables are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f964871b",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "filepath <- \"https://raw.githubusercontent.com/smburns47/Psyc158/main/tetrismemories.csv\"\n",
    "\n",
    "#write code here to load the data into an object called tetrismemories\n",
    "tetrismemories <- #your code here\n",
    "\n",
    "head(tetrismemories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ff8e98",
   "metadata": {},
   "source": [
    "By counting columns from the left, we can see that ```condition``` is the first column and ```intrusive_memories``` is the 16th column. Thus, one way we can subset our data is by indexing the data frame to just those column numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896fe7d5",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "tetrismemories_subset <- tetrismemories[,c(1,16)]\n",
    "\n",
    "head(tetrismemories_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a378ef55",
   "metadata": {},
   "source": [
    "Notice that we saved the subsetted data as a separate object here. What do you think would happen if we saved ```tetrismemories[,c(1,16)]``` to the object name ```tetrismemories```? \n",
    "\n",
    "If we save the subsetted data to the same data frame name, it will overwrite the original data frame. Doing this would mean we can no longer access the data we filtered out, and we'd have to reload the data file to get it back. This process is called **destructive editing**. In general, we don't want to do this - we don't want to permanently erase any data. Thus if you're manipulating data in a data frame, it's usually best to save the manipulated data as a new object. That way you can always access the original data again if needed. *Definitely* don't save manipulated data frames as a csv that replaces the original file you loaded the data from, or you won't be able to get it back!  \n",
    "\n",
    "The above process works for subsetting variables, but is kind of clunky. You have to manually count column numbers, which is prone to error. What most people do instead is use a package written specifically for making data cleaning easier, called ```dplyr``` (dee-ply-er). \n",
    "\n",
    "After we install the ```dplyr``` package and load it from the library, the ```select()``` function provides easy syntax for subsetting. When using ```select()```, we just need to provide arguments to tell R which data frame to work on (as the first argument) and which variables to select from that data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12a8f7e",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "install.packages(\"dplyr\")  #downloading package from the internet - this may take a few moments\n",
    "library(dplyr)             #loading package from library into workspace\n",
    "\n",
    "#Make a prediction, what do you think this code will do? \n",
    "select(tetrismemories, condition, intrusive_memories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435e6581",
   "metadata": {},
   "source": [
    "You may need to scroll the output up and down to see it all. Itâ€™s quite a lot because the function ```select()``` will print out all the values of the selected variables. \n",
    "\n",
    "Sometimes you might want to look at a subset of observations, not variables. Notice the first person in the ```tetrismemories``` dataframe had 4 instrusive memories over the course of the study. Are they the only person with that many? What happens if we put 4 as an argument in ```select()```?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48e9801",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "select(tetrismemories, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734037b2",
   "metadata": {},
   "source": [
    "```select()``` only works on *variables* (or columns of the data frame), not values. In this case, since you gave it the number 4 for the second argument, it thought you were asking for the 4th column, so it gave you that.  \n",
    "\n",
    "To get a subset of observations (or rows of the data frame) we use a different ```dplyr``` function: ```filter()```. This function filters the data frame to show only the observations (rows) that match some criteria. For example, here is the code that will return only the observations where the number of memories is 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11ee02e",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "filter(tetrismemories, intrusive_memories == 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2d3f02",
   "metadata": {},
   "source": [
    "The function ```filter()```, like ```select()```, returns a data frame. In this case, the data frame has ten rows because ten people in the study reported having four intrusive memories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d37dc03",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#How would you use filter() to return a data frame of everyone who had *at least* 4 memories?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d18271f",
   "metadata": {},
   "source": [
    "One challenge for students is to keep track of the difference between an observation (e.g., participants, represented in rows) and a variable (e.g., ```condition``` or ```intrusive_memories```, represented in columns). It is helpful to imagine the rows and columns of a data frame when you read about observations and variables, respectively. If the data are in a data frame format like this (also known as \"tidy\"), the rows will always be observations and the columns, variables.\n",
    "\n",
    "In this course we will be providing most of the data you analyze in a tidy format. However, the world is not always tidy. One day, in the wild world outside of this course, you may have to transform a non-tidy data set into a tidy one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb47f961",
   "metadata": {},
   "source": [
    "## 4.2 Filtering bad data\n",
    "\n",
    "Filtering is very useful for removing data points we don't want, such as the bad outliers and missing values discussed in chapter 2. To remove outliers, we need to decide what counts as realistic values for a variable. There are different opinions on this among researchers. Some believe you should remove any data points that are sufficiently far away from the average of a variable (chapter 5 will discuss ways to calculate this). Other researchers are more conservative and think you should only remove data points if the value is clearly incorrect, like someone mistyping their age as 211 instead of 21. This is an example of a situation where statistics aren't completely objective, and different decisions lead to different analysis outcomes. You will have to develop domain knowledge in the topic you are studying in order to be confident that the decision you made on outlier classification is the best decision for your data.  \n",
    "\n",
    "Let's say for our purposes that it wouldn't be realistic for anyone to have more than 100 intrusive memories during the tetris study (that would be at least 10 per day). Thus if an observation has a value of >100 in ```instrusive_memories```, we want to exclude it as bad data. Write code below to create a new data frame that excludes anyone with more than 100 reported intrusive memories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d01365",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "tetrismemories_clean <- filter(#your code here)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451e4f4b",
   "metadata": {},
   "source": [
    "Note that ```filter()``` filters *in*, so the filtering criteria should apply to all the data points you want to keep. So your code above should be using ```intrusive_memories <= 100``` as the filtering criteria to exclude people with unrealistic values. \n",
    "\n",
    "Got it working? Let's see how many people we filtered out by comparing the length of this cleaned dataset to the original raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930973dd",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "nrow(tetrismemories)\n",
    "nrow(tetrismemories_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692f7bbe",
   "metadata": {},
   "source": [
    "Looks like everyone had valid values on ```intrusive_memories```, because we did not remove anyone based on our exclusion criteria for that variable.\n",
    "\n",
    "There are other reasons you might exclude data. For instance, was a person with 2 intrusive memories less affected by the traumatic videos? Or did they only record information in their diary for a couple days? We probably want to exclude people who did not comply with the study instructions for the majority of the time (say, 8+ days of diary entry). So let's filter our dataset to exclude anyone with too few days:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb54e389",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "tetrismemories_clean <- filter(tetrismemories, diary_compliance >= 8)\n",
    "\n",
    "nrow(tetrismemories)\n",
    "nrow(tetrismemories_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e0afe6",
   "metadata": {},
   "source": [
    "Using this approach, we removed 12 participants for poor complaince. \n",
    "\n",
    "Another reason to exclude observations from a dataset is because of missing values. It is very common in psychology to have at least a few missing values somewhere. In a data file, this would likely look like a blank cell where a value should otherwise be. When loaded into R, blank cells are represented with the value NA (\"not available\"). If your data set represents missing data in some other way (e.g., some people put a nonsense value like -999), you should recode the values as NA when working in R (recoding will be discussed later in this chapter).  \n",
    "\n",
    "Letâ€™s consider the ```tetris_total_score``` variable in the ```tetrismemories``` data frame. First, a function called ```is.na()``` can be used to tell you whether a datapoint is NA or not (it will return ```FALSE``` or ```TRUE```). If we apply that to an entire vector, it will return a vector of falses and trues corresponding to what indices in the vector have an NA value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bbb651",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Using is.na() on the tetris_total_score variable to see where NA values might be\n",
    "\n",
    "is.na(tetrismemories$tetris_total_score) #remember variable names are case sensitive!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9801523",
   "metadata": {},
   "source": [
    "Based on this, we can easily see some missing data in this variable - there are ```TRUE``` results to the question \"is this datapoint NA?\" \n",
    "\n",
    "Now that you can find missing data, the big question is - what to do about it? Again, there are different opinions. Most commonly, researchers just remove observations with values missing on important variables. There's also something called imputation, which involves figuring out what the missing value most likely is and inserting that value into the dataset. For this exercise, we will use the exclusion method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa022a3",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "filter(tetrismemories, tetris_total_score != \"NA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cc925e",
   "metadata": {},
   "source": [
    "Can you remember what the ```!=``` operator does? This code returns a data frame that includes only cases for which the variable ```tetris_total_score``` is *not* equal to NA. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6a0f24",
   "metadata": {},
   "source": [
    "## 4.3 Creating new variables \n",
    "\n",
    "Often we use multiple measures of a single attribute because no single measure would be adequate. As we talked about in chapter 2, aggregating over multiple measurements can help with measurement error, such as surveys with multiple related questions or behavioral studies with multiple trials. \n",
    "\n",
    "If you do have multiple measures of one thing in a dataset, you will want to combine them into a single variable. For example, in ```tetrismemories```, participants gave ratings for how strongly they felt various negative emotions before and after video watching, on a scale from 0 to 10. These values are recorded in the ```pre_sad_rating```, ```pre_hopeless_rating```, ```pre_depressed_rating```, ```pre_fear_rating```, ```pre_horror_rating```, and ```pre_anxious_rating``` (and corresponding variables for the post ratings). If we have a hypothesis about different video conditions inducing more negative affect in general, we may want to sum up these scores into one combined negative affect variable. \n",
    "\n",
    "To do so, we create a new variable in a data frame using values from these original variables. The ```mutate()``` function in R mutates a data frame to include added or changed columns. The first argument is again the data frame to mutate, and then we define a new variable name and how it is computed. If the new variable created with ```mutate()``` already exists in the data frame, R will overwrite it with these new values. If it doesn't, ```mutate()``` will create a new variable and append it as a new column to the end of the mutated data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2e977b",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "mutate(tetrismemories, pre_negative_affect = pre_sad_rating + pre_hopeless_rating + pre_depressed_rating + \n",
    "    pre_fear_rating + pre_horror_rating + pre_anxious_rating)\n",
    "\n",
    "#If a line of code is really long, hitting return will make it wrap onto the next line. \n",
    "#It is still evaluated as one line of code. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e01014",
   "metadata": {},
   "source": [
    "Other reasons you might create a new variable is because you want to represent an existing variable in a different way. For example, in ```tetrismemories```, participants reported the total number of intrusive memories they experienced (```intrusive_memories```) over a certain number of days they kept track for (```diary_compliance```). We don't know how many memories per day they were having on average, but we could calculate this by dividing ```intrusive_memories``` by ```diary_compliance``` to make a new variable ```memory_rate```. Try it yourself in the code block below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98331309",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "mutate(tetrismemories, #your code here)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e60c73",
   "metadata": {},
   "source": [
    "```dplyr``` and its functions are very popular among R coders because of their easy syntax when working with tidy data. In fact this package is among those colloquially called the \"tidyverse\", a name you might come across while googling R functions. But like with ```subset()``` and ```filter()```, there is also a way to create new variables without downloading ```dplyr``` functions (using what's called \"base R\"). The base R version of creating new variables is to reference a new variable name using the ```$``` operator we learned last chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f620a6",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# making a new memory_rate variable using the base R approach\n",
    "tetrismemories_clean$memory_rate <- tetrismemories$instrusive_memories / tetrismemories$diary_compliance\n",
    "head(tetrismemories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb90297",
   "metadata": {},
   "source": [
    "As we learn more R, you will often find that there are multiple ways to do the same thing. Neither the tidyverse approach or the base R approach is more correct than the other. Like linguistic quirks in spoken language, your choice of method will just depend on the way that is easier for you to remember or how you prefer to \"say\" things in code. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3db5ba",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note</b>: Are we learning too many functions to memorize? Create a \"cheatsheet\" or page of notes for keeping track of R functions and how to use them.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26980d9a",
   "metadata": {},
   "source": [
    "## 4.4 Recoding variables\n",
    "\n",
    "Another very common step in data cleaning is changing the values or data types used to represent variables. Changing these values is called **recoding** a variable. For instance, the variable ```condition``` is coded 1-4, depending on which condition a participant was in:\n",
    "\n",
    "1. No-task control: These participants completed a 10-minute music filler task.\n",
    "2. Reactivation + Tetris: These participants were shown a series of images from the trauma film to\n",
    "reactivate the traumatic memories (i.e., reactivation task). After a 10-minute music filler task,\n",
    "participants played the video game Tetris for 12 minutes.\n",
    "3. Tetris Only: These participants played Tetris for 12 minutes, but did not complete the reactivation\n",
    "task.\n",
    "4. Reactivation Only: These participants completed the reactivation task, but did not play Tetris.\n",
    "\n",
    "These data are currently stored as numbers. But since these numbers represent study conditions, the variable's scale of measurement is inherently categorical. Thus we probably want to transform this variable into character labels that are easier to remember the meaning of. What happens if we simply convert the ```condition``` variable to a character data type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b74be0f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "tetrismemories_recoded <- tetrismemories #avoiding destructive editing by making a new copy of data frame\n",
    "str(tetrismemories_recoded$condition)\n",
    "\n",
    "tetrismemories_recoded$condition <- as.character(tetrismemories$condition)\n",
    "str(tetrismemories_recoded$condition)\n",
    "\n",
    "#or the tidyverse way with a function inside a function:\n",
    "# mutate(tetrismemories, condition = as.character(condition))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1257ea19",
   "metadata": {},
   "source": [
    "This makes the ```condition``` variable a character type, but the number labels still aren't very descriptive. Let's go further, and change those actual values into words that are easier to understand. In base R, you could set up a for loop and several if/else statements to change these values based on the current labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cb24e4",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "tetrismemories_recoded <- tetrismemories #avoiding destructive editing by making a new copy of data frame\n",
    "\n",
    "for (row in 1:nrow(tetrismemories_recoded)) {\n",
    "    if (tetrismemories_recoded$condition[row] == 1) {\n",
    "        tetrismemories_recoded$condition[row] <- 'control'\n",
    "    } else if (tetrismemories_recoded$condition[row] == 2) {\n",
    "        tetrismemories_recoded$condition[row] <- 'reactivation_tetris'\n",
    "    } else if (tetrismemories_recoded$condition[row] == 3) {\n",
    "        tetrismemories_recoded$condition[row] <- 'tetris'\n",
    "    } else {\n",
    "       tetrismemories_recoded$condition[row] <- 'reactivation' \n",
    "    }\n",
    "}\n",
    "\n",
    "tetrismemories_recoded$condition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6c6c32",
   "metadata": {},
   "source": [
    "Whew, that was a lot! Alternatively, ```dplyr``` has a function that handles all that control flow for you under the hood, making it much easier to write the code. This function is ```case_match()```. As the first argument, ```case_match()``` takes a variable you want to modify. The remaining arguments are mapping specification for which values should turn into which other values, separated by a `~` symbol. When combined with ```mutate()``` using a **nested function** (one function creating the argument for another from the inside) we can modify an existing variable to have new labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdebfb3",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "mutate(tetrismemories, condition = case_match(condition, 1 ~ 'control',    #existing value ~ new value\n",
    "                                                        2 ~ 'reactivation_tetris',\n",
    "                                                        3 ~ 'tetris',\n",
    "                                                        4 ~ 'reactivation'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e27f3f8",
   "metadata": {},
   "source": [
    "## 4.5 Combining multiple cleaning steps\n",
    "\n",
    "Cleaning a dataset is rarely simple. Often we need to do multiple of the steps described above such as subsetting, filtering, creating new variables, and/or recoding. One could feasibly write a new line of code for each step, defining a new data frame object each time in order to avoid destructive editing:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c15c57",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "tetrismemories2 <- filter(tetrismemories, diary_compliance >= 8)\n",
    "\n",
    "tetrismemories3 <- mutate(tetrismemories2, pre_negative_affect = pre_sad_rating + pre_hopeless_rating + pre_depressed_rating + \n",
    "    pre_fear_rating + pre_horror_rating + pre_anxious_rating)\n",
    "\n",
    "tetrismemories4 <- mutate(tetrismemories3, post_negative_affect = post_sad_rating + post_hopeless_rating + post_depressed_rating + \n",
    "    post_fear_rating + post_horror_rating + post_anxious_rating)\n",
    "\n",
    "tetrismemories5 <- mutate(tetrismemories4, negative_affect_change = post_negative_affect - pre_negative_affect)\n",
    "\n",
    "tetrismemories6 <- mutate(tetrismemories5, condition = case_match(condition, 1 ~ 'control', \n",
    "                                                        2 ~ 'reactivation_tetris',\n",
    "                                                        3 ~ 'tetris',\n",
    "                                                        4 ~ 'reactivation'))\n",
    "\n",
    "tetrismemories7 <- select(tetrismemories6, condition, intrusive_memories, negative_affect_change)\n",
    "\n",
    "#What cleaning steps are done by each line of code?\n",
    "\n",
    "#looking at raw vs. cleaned data\n",
    "head(tetrismemories)\n",
    "head(tetrismemories7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e481e3",
   "metadata": {},
   "source": [
    "This works, but isn't best practice for a couple reasons. First, there are now several data frames stored in the R workspace. It can be hard for you as the researcher to remember which is which. Second, especially when data frames a large, storing this many data frames at once can cause your computer to run out of memory.\n",
    "\n",
    "A better approach is to combine multiple cleaning steps into one object declaration call. We could use nested functions like so: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2c7d87",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#inside filter function creates a value that is used as the first argument to outer select() function\n",
    "tetrismemories_clean <- select(filter(tetrismemories, diary_compliance >= 8), condition, intrusive_memories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707c639a",
   "metadata": {},
   "source": [
    "But that gets difficult to read if there are more than a couple levels to the nesting. \n",
    "\n",
    "To solve this issue, the ```dplyr``` packages provides functionality for a new operator that looks like ```%>%```. This is called a **pipe**. Piping lets you pass the output of one function immediately as an argument to another without the need to define an intermediate data frame object. Doing the same command above with a pipe looks like so: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b11fdd",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "tetrismemories_clean <- tetrismemories %>% \n",
    "                        filter(., diary_compliance >= 8) %>%\n",
    "                        select(., condition, intrusive_memories)\n",
    "\n",
    "head(tetrismemories_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18ed7a6",
   "metadata": {},
   "source": [
    "Chaining functions together with a pipe is easier for a human to read (and thus use and debug). The first item in the chain (```tetrismemories```) is the object you want to start operating on. That object is piped in as the argument of the next function denoted with a ```.```. The output of that function is further piped in as an argument in the next function, and so on. Putting these piping steps on separate lines makes it further easier to read. Finally, this whole chain is saved to a data frame object which will hold the final resulting value. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note</b>: If the argument you are piping into is the first one, you don't need to include a dot at all as a placeholder - you can simply leave out the first argument in the function call. R programmers frequently do this. If the argument is anything besides the first, the dot is needed. In this course we will always include the dot as a way to more explicitly keep track of what argument is being piped into.\n",
    "</div>\n",
    "\n",
    "In the code block below, try it out yourself by adding a step that recodes the ```condition``` variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9994b441",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "tetrismemories_clean <- tetrismemories %>% \n",
    "                        filter(., diary_compliance >= 8) %>%\n",
    "                        #add a step here, followed by a pipe\n",
    "                        select(., condition, intrusive_memories)\n",
    "\n",
    "head(tetrismemories_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31bd3d6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note</b>: Base R has its own version of the pipe, |>. It works very similarly to the %>% pipe in dplyr, except it can't pipe into any argument position besides the first one. For this reason %>% is more flexible, but you do need to load the dplyr library to use it.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43fd23b",
   "metadata": {},
   "source": [
    "## 4.6 Saving data\n",
    "\n",
    "The majority of data projects you will ever work on will involve some data manipulation steps like this. We often do this to fix problems with raw data files or arrange things in a way that will give us easier time later in analysis. We've already mentioned how data cleaning is an important step, but it's worth repeating again. While we are only spending one chapter dedicated to this in this course, you will actually find (maybe to some [frustration](https://www.quora.com/Why-do-people-state-that-the-majority-of-work-for-a-data-scientist-is-data-cleaning-not-the-machine-learning-part)) that the majority of time you spend on a data file is cleaning, rather than analyzing. Once you get comfortable with statistics, analysis can be as simple as a few lines of code. But data cleaning can involve many steps and a lot of time figuring out what cleaning steps you even need to take!\n",
    "\n",
    "For this reason, it is very helpful to save the results of your data cleaning after you're done. You don't want to have to go through all that again if you decide later on you want to do a different kind of data analysis. \n",
    "\n",
    "As we used ```read.csv()``` to read in data files to R, we can use ```write.csv()``` to save .csv files of our cleaned data. In its most basic use, it only needs two arguments: the data frame object you wish to save, and a string of the file name you wish to save it as (.csv extension must be included). So if we were to save the results of ```tetrismemories2```, we would simply type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2653fd59",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#saving a data frame into a csv file\n",
    "write.csv(tetrismemories2, \"tetrismemories2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03326df",
   "metadata": {},
   "source": [
    "This would create a \"tetrismemories2.csv\" file in the current working directory. Make sure to save it as a different file name from your raw file so you can always refer back to the original if needed (no destructive editing!). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6323c693",
   "metadata": {},
   "source": [
    "## Chapter summary\n",
    "\n",
    "After reading this chapter, you should be able to:\n",
    "\n",
    "- Explain why we would do the common data cleaning processes of subsetting, filtering, creating new variables, and recoding.\n",
    "- Subset a data frame with code \n",
    "- Filter a data frame code\n",
    "- Add a new variable to a dataframe and change an existing one\n",
    "- Recode a variable to new data types or values\n",
    "- String multiple data cleaning steps together with pipes\n",
    "- Save a dataframe to a new file\n",
    "\n",
    "## New concepts\n",
    "\n",
    "- **data cleaning**: Ahe process of identifying and fixing errors in a dataset, and reformatting the dataset to be more analysis-compliant. \n",
    "- **destructive editing**: An editing practice where the original copy of a file is overwritten by an edited copy, destroying the original. \n",
    "- **pipe**: An operator in R that allows a coder to pass the output of one function immediately as an argument in another.\n",
    "\n",
    "## New R functionality\n",
    "\n",
    "- [dplyr::select()](https://dplyr.tidyverse.org/reference/select.html)\n",
    "- [dplyr::filter()](https://dplyr.tidyverse.org/reference/filter.html)\n",
    "- [is.na()](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/NA)\n",
    "- [dplyr::mutate()](https://dplyr.tidyverse.org/reference/mutate.html)\n",
    "- [$ operator](https://www.geeksforgeeks.org/dollar-sign-in-r/)\n",
    "- [dplyr::case_match()](https://dplyr.tidyverse.org/reference/case_match.html)\n",
    "- [nested functions](https://www.w3schools.com/r/r_functions_nested.asp)\n",
    "- [%>% pipe](https://www.datacamp.com/tutorial/pipe-r-tutorial)\n",
    "- [write.csv()](https://www.geeksforgeeks.org/writing-to-csv-files-in-r/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6dcc60",
   "metadata": {},
   "source": [
    "[Next: Chapter 5 - Describing Data](https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-5.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
