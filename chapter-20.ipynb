{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bfb9d4c",
   "metadata": {},
   "source": [
    "[Back to Table of Contents](https://www.shannonmburns.com/Psyc158/intro.html)\n",
    "\n",
    "[Previous: Chapter 19 - Model Bias](https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-19.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "14b5dbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/Library/Frameworks/R.framework/Versions/4.2-arm64’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The downloaded binary packages are in\n",
      "\t/var/folders/mg/1wy1xcls587_h0tqnj42l5740000gn/T//Rtmpo3HL6S/downloaded_packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/Library/Frameworks/R.framework/Versions/4.2-arm64’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The downloaded binary packages are in\n",
      "\t/var/folders/mg/1wy1xcls587_h0tqnj42l5740000gn/T//Rtmpo3HL6S/downloaded_packages\n"
     ]
    }
   ],
   "source": [
    "# Run this first so it's ready by the time you need it\n",
    "install.packages(\"dplyr\")\n",
    "install.packages(\"ggformula\")\n",
    "library(dplyr)\n",
    "library(ggformula)\n",
    "trackscores <- read.csv(\"https://raw.githubusercontent.com/smburns47/Psyc158/main/trackscores.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddafa7b",
   "metadata": {},
   "source": [
    "# Chapter 20 - Traditional Statistical Tools\n",
    "\n",
    "## 20.1 Different teaching philosophies\n",
    "\n",
    "In this course you have spent a long time learning about how to make predictions and do inference with the general linear model. However, most statistics students don't learn this framework for doing analysis. Instead, they learn an assortment of different statistical procedures like the t-test, ANOVA, chi-square, etc. Indeed many practicing researchers also use these tools instead of the GLM.\n",
    "\n",
    "So why learn the GLM at all if not as many people use it? There are two pedagogical reasons for why this course emphasized this method instead of the traditional content:\n",
    "\n",
    "1) **Traditional tools require learning how to do hypothesis testing first** - Traditional methods fundamentally depend on Null Hypothesis Significance testing. They start with defining a null hypothesis and cannot be interpreted without computing a t/F score and finding a p-value. This means to learn how to use these tools, students first have to learn about sampling distributions and significance testing. This is a rather abstract thing to learn first and impedes understanding for many people. This leads them to using intellectual short cuts like \"always look for p < 0.05\" despite the dangers of overrelying on that number. \n",
    "\n",
    "2) **Traditional tools are more variable, harder to remember** - When first starting out, the list of all the common statistical tools often seems daunting. They are calculated all different ways with different names and it's hard to remember what goes where. In contrast, the GLM is ultimatly one tool - $Y_i = b_0 + b_1X_i + e_i$. How many predictors you add to the equation and how you interpret the coefficients varies depending on your use situation, but just knowing about this one equation gets you 80% of the way there, making it a better starting point for building conceptual understanding.\n",
    "\n",
    "Despite the advantages of the GLM however, many people still use the traditional tools. Thus, it is good for you to be able to identify them and understand how they map onto what you have learned with the GLM. Ultimately, the GLM and these tools will give you the same answer and you can choose which you prefer in your own research. Knowing both will enable you to read and understand research reports no matter what method the authors used. You may even find that most of these tools build on concepts you've already learned. They're just a different way of showing that information. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74dc2e3",
   "metadata": {},
   "source": [
    "## 20.2 T-tests \n",
    "\n",
    "### One-sample t-test\n",
    "\n",
    "Previously in chapter 11, we were introduced to the idea of a t-test. To explain it in more depth, let's start with the **one-sample t-test**. \n",
    "\n",
    "Let's say you are a track coach and you're assessing the progress of your runners' training. They all recorded their best times for running the 400m when they initially joined the team. Now after a month of training with track drills, you want to know if they, as a group, have improved. \n",
    "\n",
    "Here is some data from your team. We will filter it down to just those scores at tryouts and 1 month later at the first meet, then calculate their change in running times. Negative scores mean they got faster (less time to complete the 100m), positive scores mean they ran slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f9b5c60f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 6</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>athlete</th><th scope=col>session</th><th scope=col>condition</th><th scope=col>weight_training</th><th scope=col>track_training</th><th scope=col>time</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>1</td><td>tryouts</td><td>no-training</td><td>0</td><td>0</td><td>48.50</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>2</td><td>tryouts</td><td>no-training</td><td>0</td><td>0</td><td>48.87</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>3</td><td>tryouts</td><td>no-training</td><td>0</td><td>0</td><td>49.28</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>4</td><td>tryouts</td><td>no-training</td><td>0</td><td>0</td><td>46.97</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>5</td><td>tryouts</td><td>no-training</td><td>0</td><td>0</td><td>48.18</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>6</td><td>tryouts</td><td>no-training</td><td>0</td><td>0</td><td>50.36</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 6\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & athlete & session & condition & weight\\_training & track\\_training & time\\\\\n",
       "  & <int> & <chr> & <chr> & <int> & <int> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & 1 & tryouts & no-training & 0 & 0 & 48.50\\\\\n",
       "\t2 & 2 & tryouts & no-training & 0 & 0 & 48.87\\\\\n",
       "\t3 & 3 & tryouts & no-training & 0 & 0 & 49.28\\\\\n",
       "\t4 & 4 & tryouts & no-training & 0 & 0 & 46.97\\\\\n",
       "\t5 & 5 & tryouts & no-training & 0 & 0 & 48.18\\\\\n",
       "\t6 & 6 & tryouts & no-training & 0 & 0 & 50.36\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 6\n",
       "\n",
       "| <!--/--> | athlete &lt;int&gt; | session &lt;chr&gt; | condition &lt;chr&gt; | weight_training &lt;int&gt; | track_training &lt;int&gt; | time &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|\n",
       "| 1 | 1 | tryouts | no-training | 0 | 0 | 48.50 |\n",
       "| 2 | 2 | tryouts | no-training | 0 | 0 | 48.87 |\n",
       "| 3 | 3 | tryouts | no-training | 0 | 0 | 49.28 |\n",
       "| 4 | 4 | tryouts | no-training | 0 | 0 | 46.97 |\n",
       "| 5 | 5 | tryouts | no-training | 0 | 0 | 48.18 |\n",
       "| 6 | 6 | tryouts | no-training | 0 | 0 | 50.36 |\n",
       "\n"
      ],
      "text/plain": [
       "  athlete session condition   weight_training track_training time \n",
       "1 1       tryouts no-training 0               0              48.50\n",
       "2 2       tryouts no-training 0               0              48.87\n",
       "3 3       tryouts no-training 0               0              49.28\n",
       "4 4       tryouts no-training 0               0              46.97\n",
       "5 5       tryouts no-training 0               0              48.18\n",
       "6 6       tryouts no-training 0               0              50.36"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#take a look at how this dataset was organized\n",
    "head(trackscores)\n",
    "\n",
    "tryout_scores <- filter(trackscores, session==\"tryouts\", condition==\"track-training\")\n",
    "meet1_scores <- filter(trackscores, session==\"meet1\", condition==\"track-training\")\n",
    "\n",
    "change_scores <- meet1_scores$time - tryout_scores$time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac046b65",
   "metadata": {},
   "source": [
    "If our question is restricted to just our team of runners and no one else, we can figure out their improvement really easily. We simply find the mean of their change scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c10672ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "-0.318999999999999"
      ],
      "text/latex": [
       "-0.318999999999999"
      ],
      "text/markdown": [
       "-0.318999999999999"
      ],
      "text/plain": [
       "[1] -0.319"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(change_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8f7ca3",
   "metadata": {},
   "source": [
    "Great! This number means that, on average, our team ran faster than before after training for a month. If we only care about evaluating our current team, we can stop here and don't need to use any more statistics. \n",
    "\n",
    "But let's say our question goes beyond just our team. If we were to recruit new runners the following year, would they also improve their scores with this training regimen? Is it good enough to use for everyone?\n",
    "\n",
    "Now we are hypothesizing about data we don't have. At this point we need inferential statistics, and a one-sample t-test can help.\n",
    "\n",
    "A one-sample t-test answers a particular kind of question: is the mean of some data $\\bar{X}$ likely or unlikely to be from a population with a specific $\\mu$? In other words, if we think the population $\\mu$ is a particular value and our data sample is drawn from that population, is it reasonable or surprising to find that our sample's mean is the value we measured? \n",
    "\n",
    "For how this translates to our specific example: is our data sample likely to happen even in a population of runners who on average didn't improve? \n",
    "\n",
    "In order to do a one-sample t-test to answer this question, we first need to set down our idea about what $\\mu$ should be. This is specifying the null hypothesis. For our particular example, the data we are evaluating are improvements in running time. We want to know if these data came from a population of scores where there's no improvement. In such a population some people might run a bit faster than their initial time, some a bit slower, but on average there's no change. Thus, to set our null hypothesis: \n",
    "\n",
    "$$H_0: \\mu = 0$$\n",
    "\n",
    "When we calculated our data sample earlier, it was about -0.32, not 0. Does that mean we can conclude these runners did not come from a population of no improvement? \n",
    "\n",
    "Not necessarily. Remember, due to random sampling, it is frequently possible to get a sample mean that is not the same value as the population mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "329de335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "-0.490656847829322"
      ],
      "text/latex": [
       "-0.490656847829322"
      ],
      "text/markdown": [
       "-0.490656847829322"
      ],
      "text/plain": [
       "[1] -0.4906568"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(10)\n",
    "sim_sample <- rnorm(10, mean=0, sd=1) #random sample of 10 scores from population with mean 0\n",
    "mean(sim_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd06273",
   "metadata": {},
   "source": [
    "Thus we need a way refining our question: given a population $\\mu$ *and* an expected variation among samples from that population, is our sample really surprising or not?\n",
    "\n",
    "Enter the t-value. It is a way of scaling the difference between a sample and hypothesized population mean by the standard error of that population. For a one-sample t-test, this is calculated as: \n",
    "\n",
    "$$t = \\frac{\\bar{X} - \\mu}{SEM}$$\n",
    "\n",
    "If you recall from chapter 15, SEM in turn is calculated as:\n",
    "\n",
    "$$SEM = \\frac{\\hat{σ}}{\\sqrt{N}}$$\n",
    "\n",
    "All this together means that a t-value will be larger when there's a bigger difference between our sample mean and the hypothesized population mean, or when the standard error is smaller. \n",
    "\n",
    "The type of t-score we can get falls somewhere in the t distribution that we first encountered in chapter 16:\n",
    "\n",
    "<img src=\"images/ch16-tdist.png\" width=\"600\">\n",
    "\n",
    "You'll notice that the exact shape of the t distribution changes based on the degrees of freedom for our sample. That's because higher sample size Ns reduce the standard error, making it easier to get large t values even when a sample really is from a population with mean $\\mu$. The cumulative probability outside of our t-value is the corresponding p-value for that t-score, so t-scores in smaller sample sizes have larger p-values because there's a relatively larger amount of the distribution that is more extreme than that value compared to the t-distribution made of larger sample sizes.  \n",
    "\n",
    "Altogether, this means that to answer our question about whether our data likely come from a population of no improvement, we need to calculate a t-score and its associated p-value. The larger this t-score is, the more suprising it would be to draw a sample with our mean given a true population $\\mu = 0$. If the associated p-value is <0.05, we would decide it's so surprising that our sample probably came from a different sort of population instead - one with some alternative $\\mu$ that suggests improvement due to our training regimen. \n",
    "\n",
    "R provides us with a built-in function to quickly compute a one sample t-test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "31d2b5a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tOne Sample t-test\n",
       "\n",
       "data:  change_scores\n",
       "t = -1.7664, df = 9, p-value = 0.1111\n",
       "alternative hypothesis: true mean is not equal to 0\n",
       "95 percent confidence interval:\n",
       " -0.72751897  0.08951897\n",
       "sample estimates:\n",
       "mean of x \n",
       "   -0.319 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t.test(change_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff2cb52",
   "metadata": {},
   "source": [
    "The output of this function gives us information about the calculated t-score (-1.7664), the degrees of freedom of the test (9, which is N-1), and the p-value (0.1111). It also gives us a 95% CI for our estimate of the mean, [-0.73, 0.09]. Note that a t-value can be positive or negative, signifying if our sample mean is higher or lower than the hypothesized population mean.\n",
    "\n",
    "Based on these results, there is not enough evidence to reject the null hypothesis that our training regimen results in no improvement. In APA format, we would write these results as \"The mean change in running time was -0.32 seconds [-0.73, 0.09], but there was no significant improvement in running time for this sample of runners (*t(9)* = -1.77, *p* = 0.11). \n",
    "\n",
    "The different parts of doing a t-test (calculating a mean, null hypothesis, standard error, and p-value) are all concepts you've learned before. For this reason, a t-test is actually just another way of getting to the same answer as we previously did with the general linear model. Check out the t and p values in the model output below, and compare them to the results of the above t-test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "01d3d6eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = change_scores ~ NULL)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-0.7510 -0.3685 -0.1510  0.2415  1.1690 \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error t value Pr(>|t|)\n",
       "(Intercept)  -0.3190     0.1806  -1.766    0.111\n",
       "\n",
       "Residual standard error: 0.5711 on 9 degrees of freedom\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(lm(change_scores ~ NULL))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3be547",
   "metadata": {},
   "source": [
    "In the null model of the GLM framework, we are estimating the sample mean as $b_0$ and evaluating if it is significantly different from 0. In a one-sample t-test, we are evaluating whether a sample mean $\\bar{X}$ is significantly different from the null hypothesis $\\mu = 0$. These are the exact same question, just posed different ways. Thus, you can get the same result using a null model form of the GLM or the one-sample t-test.\n",
    "\n",
    "However, we should also point out that in the null model, the significance of $b_0$ is specifically compared in the context of a null hypothesis where $\\beta_0 = 0$. In the one-sample t-test, we can be more general that this. We don't have to restrict ourselves to a null hypothesis of 0. For instance, let's imagine that instead of running improvement, we are interested in whether our team's new running times are significantly better than the [Division III track and field recruiting cut off](https://www.ncsasports.org/mens-track-and-field/scholarship-standards) of 51.76. First we calculate the mean of everyone's new running times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6eeefbdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "48.084"
      ],
      "text/latex": [
       "48.084"
      ],
      "text/markdown": [
       "48.084"
      ],
      "text/plain": [
       "[1] 48.084"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(meet1_scores$time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd045436",
   "metadata": {},
   "source": [
    "Then we specify a null hypothesis:\n",
    "\n",
    "$$H_0: \\mu = 51.76$$\n",
    "\n",
    "This is a different null hypothesis than before. Now, we are wondering if our sample is likely to come from DIII track and field athletes, or if we should conclude they come from an even faster population.\n",
    "\n",
    "To specify a null hypothesis in a t-test that is different than 0, add the ```mu=``` argument to the ```t.test()``` with this specific null hypothesis value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "747dd6f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tOne Sample t-test\n",
       "\n",
       "data:  meet1_scores$time\n",
       "t = -9.5046, df = 9, p-value = 5.453e-06\n",
       "alternative hypothesis: true mean is not equal to 51.76\n",
       "95 percent confidence interval:\n",
       " 47.20909 48.95891\n",
       "sample estimates:\n",
       "mean of x \n",
       "   48.084 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t.test(meet1_scores$time, mu=51.76)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b63afe",
   "metadata": {},
   "source": [
    "Based on these results, our sample mean of 48.08 would be very unusual if it were drawn from a population with $\\mu = 51.76$ (p < 0.001). Thus we reject this null hypothesis in favor of the alternative hypothesis that our team is from a faster population.  \n",
    "\n",
    "### independent-samples t-test\n",
    "\n",
    "A one sample t-test is used when you have one group of data, and want to understand how likely it is that that one group came from a particular population. If you have two separate groups of data and want to be able to distingush them from each other, this calls for a different kind of t-test called an **independent samples t-test** or **two-sample t-test**. \n",
    "\n",
    "Let's say you're still the track coach, but this time you want to compare how two different kinds of training impact your athletes. This time, you have half the team run track drills for a month and half the team do weights in the gym. Afterwards, you assess their running time on the 400m at their first meet. In this situation you no longer have one group of data like last time. You have two groups who went through different experiences that might make them different from each other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2f054a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_training <- filter(trackscores, session==\"meet1\", condition==\"track-training\")\n",
    "weight_training <- filter(trackscores, session==\"meet1\", condition==\"weight-training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59de7cfe",
   "metadata": {},
   "source": [
    "An independent samples t-test answers the question \"are these two groups likely drawn from the same population?\" The null hypothesis of this question would be: \n",
    "\n",
    "$$H_0: \\mu_1 = \\mu_2$$\n",
    "\n",
    "Where $\\mu_1$ is the population from which group 1 came, and $\\mu_2$ is the population from which group 2 came. The alternative hypothesis, then, is that they come from different populations.\n",
    "\n",
    "An independent samples t-score is calculated a bit differently than a one-sample t-score. This one comes out to: \n",
    "\n",
    "$$ t = \\frac{\\bar{X}_1 - \\bar{X}_2}{s_p\\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}} $$\n",
    "\n",
    "where $s_p$ stands for the *pooled* standard deviation, a way of combining the standard deviations of two samples:\n",
    "\n",
    "$$s_p = \\sqrt{\\frac{(n_1 - 1)s^2_1 + (n_2 - 1)s^2_2}{n_1 + n_2 + 2}} $$\n",
    "\n",
    "While this equation is more complicated, in general it gets larger based on the same factors as the one-sample t-test. You will get a larger t-score, and thus more likely to reject the null hypothesis, if there is a large difference between the group means *or* if the sample sizes are large. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6583d0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tWelch Two Sample t-test\n",
       "\n",
       "data:  track_training$time and weight_training$time\n",
       "t = -0.10901, df = 16.815, p-value = 0.9145\n",
       "alternative hypothesis: true difference in means is not equal to 0\n",
       "95 percent confidence interval:\n",
       " -1.0796673  0.9736673\n",
       "sample estimates:\n",
       "mean of x mean of y \n",
       "   48.084    48.137 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t.test(track_training$time, weight_training$time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d89e6d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = time ~ condition, data = trainingdata)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-1.7370 -0.7115  0.1945  0.6955  1.7660 \n",
       "\n",
       "Coefficients:\n",
       "                         Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)               48.0840     0.3438 139.861   <2e-16 ***\n",
       "conditionweight-training   0.0530     0.4862   0.109    0.914    \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 1.087 on 18 degrees of freedom\n",
       "Multiple R-squared:  0.0006597,\tAdjusted R-squared:  -0.05486 \n",
       "F-statistic: 0.01188 on 1 and 18 DF,  p-value: 0.9144\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainingdata <- filter(trackscores, session=='meet1',\n",
    "                       (condition=='track-training' | condition=='weight-training'))\n",
    "summary(lm(time ~ condition, data = trainingdata))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02524061",
   "metadata": {},
   "source": [
    "## 20.3 ANOVA tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91883486",
   "metadata": {},
   "source": [
    "## 20.4 Chi-square\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8569d84d",
   "metadata": {},
   "source": [
    "## 20.5 Repeated measures tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ecb320",
   "metadata": {},
   "source": [
    "[Next: Chapter 21 - Alternate Approaches - Bayesian Statistics](https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-21.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
