

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Chapter 19 - Model Bias &#8212; Pomona Psych 158 Online Textbook</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapter-19';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Pomona College Psych 158 Online Textbook
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Unit 1 Describing Data</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-1.ipynb">Chapter 1 - Introduction to Statistical Thinking</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-2.ipynb">Chapter 2 - What are Data</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-3.ipynb">Chapter 3 - Organizing Data</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-4.ipynb">Chapter 4 - Cleaning Data</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-5.ipynb">Chapter 5 - Describing Data</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-6.ipynb">Chapter 6 - Variation in Multiple Variables</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-7.ipynb">Chapter 7 - Principles of Data Visualization</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Unit 2 - Modeling Data</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-8.ipynb">Chapter 8 - Where Data Come From</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-9.ipynb">Chapter 9 - Modeling the Data Generation Process</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-10.ipynb">Chapter 10 - Quantifying Model Error</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-11.ipynb">Chapter 11 - Adding an Explanatory Variable</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-12.ipynb">Chapter 12 - Quantitative Predictor Models</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-13.ipynb">Chapter 13 - Multivariable Models</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-14.ipynb">Chapter 14 - Models with Moderation</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Unit 3 - Evaluating Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-15.ipynb">Chapter 15 - Estimating Populations</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-16.ipynb">Chapter 16 - Significance Testing</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-17.ipynb">Chapter 17 - Significance Testing Whole Models</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-18.ipynb">Chapter 18 - Effect Sizes &amp; Statistical Power</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-19.ipynb">Chapter 19 - Model Bias</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-20.ipynb">Chapter 20 - Alternate Approaches - Traditional Statistical Tools</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-21.ipynb">Chapter 21 - Lying with Statistics</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/smburns47/Psyc158/main?urlpath=tree/chapter-19.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onBinder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="initThebeSBT()"
  class="btn btn-sm btn-launch-thebe dropdown-item"
  title="Launch Thebe"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="btn__text-container">Live Code</span>
</button>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/smburns47/Psyc158" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/smburns47/Psyc158/issues/new?title=Issue%20on%20page%20%2Fchapter-19.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/chapter-19.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Chapter 19 - Model Bias</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#error-vs-bias">19.1 Error vs. bias</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#out-of-sample-predictions">19.2 Out-of-sample predictions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#biased-and-unbiased-estimates">19.3 Biased and unbiased estimates</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#assumption-1-linearity">19.4 Assumption 1: Linearity</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#assumption-2-homogeneity-of-variance">19.5 Assumption 2: Homogeneity of variance</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#assumption-3-low-leverage">19.6 Assumption 3: Low leverage</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#assumption-4-normality-of-residuals">19.7 Assumption 4: Normality of residuals</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#assumption-5-no-multicollinearity">19.8 Assumption 5: No multicollinearity</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#checking-for-violations-of-model-assumptions">19.9 Checking for violations of model assumptions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-to-do-about-model-assumption-violations">19.10 What to do about model assumption violations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#other-sources-of-bias">19.11 Other sources of bias</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#non-representative-samples">Non-representative samples</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#omitted-variable-bias">Omitted variable bias</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#qualitative-outcome-variable">Qualitative outcome variable</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#repeated-measures">Repeated measures</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#chapter-summary">Chapter Summary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#new-concepts">New concepts</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#new-r-functionality">New R functionality</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <p><a class="reference external" href="https://www.shannonmburns.com/Psyc158/intro.html">Back to Table of Contents</a></p>
<p><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-18.ipynb">Previous: Chapter 18 - Evaluating Effect Sizes</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Run this first so it&#39;s ready by the time you need it</span>
<span class="nf">install.packages</span><span class="p">(</span><span class="s">&quot;dplyr&quot;</span><span class="p">)</span>
<span class="nf">install.packages</span><span class="p">(</span><span class="s">&quot;ggformula&quot;</span><span class="p">)</span>
<span class="nf">install.packages</span><span class="p">(</span><span class="s">&quot;performance&quot;</span><span class="p">)</span>
<span class="nf">install.packages</span><span class="p">(</span><span class="s">&quot;see&quot;</span><span class="p">)</span>
<span class="nf">install.packages</span><span class="p">(</span><span class="s">&quot;patchwork&quot;</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">dplyr</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">ggformula</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">performance</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section class="tex2jax_ignore mathjax_ignore" id="chapter-19-model-bias">
<h1>Chapter 19 - Model Bias<a class="headerlink" href="#chapter-19-model-bias" title="Permalink to this heading">#</a></h1>
<section id="error-vs-bias">
<h2>19.1 Error vs. bias<a class="headerlink" href="#error-vs-bias" title="Permalink to this heading">#</a></h2>
<p>We use statistics to try and explain complex things in the world, and arrive at some general conclusions about what we can expect. More specifically in the context of the general linear model, we try to model the data generation process of data we care about and see what information helps us make the best predictions about those data.</p>
<p>We know from our discussion of model error that it is hard and maybe impossible to make perfectly correct predictions. In any data generation process, we might be able to figure out that using information from some predictor variables helps us explain some variation in an outcome variable and make <em>better</em> predictions, but there is almost always some error left unexplained.</p>
<img src="images/ch10-var1.png" width="500">
<p>For any particular prediction we make about the outcome value of one data point, that prediction is likely to be off by a bit. This amount that we typically miss by is the error of a model. We can quantify it by looking at the distribution of the residuals a model produces when making predictions. For example, let’s simulate a sample of data with a partially-known data generation process, and make predictions using the part of the model that we know:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rnorm</span><span class="p">(</span><span class="m">100</span><span class="p">,</span><span class="m">0</span><span class="p">,</span><span class="m">1</span><span class="p">)</span><span class="w">  </span><span class="c1">#defining a random variable</span>
<span class="n">e</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rnorm</span><span class="p">(</span><span class="m">100</span><span class="p">,</span><span class="m">0</span><span class="p">,</span><span class="m">1</span><span class="p">)</span><span class="w">  </span><span class="c1">#some unexplained error</span>
<span class="n">y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">0.5</span><span class="o">*</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">e</span><span class="w">   </span><span class="c1">#the data generation process </span>
<span class="n">sim_df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>

<span class="n">sim_df</span><span class="o">$</span><span class="n">predicted_y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">0.5</span><span class="o">*</span><span class="n">sim_df</span><span class="o">$</span><span class="n">x</span>
<span class="n">sim_df</span><span class="o">$</span><span class="n">residuals</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sim_df</span><span class="o">$</span><span class="n">y</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">sim_df</span><span class="o">$</span><span class="n">predicted_y</span>
</pre></div>
</div>
</div>
</div>
<p>If we plot the residuals of the model in this sample, making a histogram of the error distribution, we see that most of them are non-zero. We are missing our predictions by a bit.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">gf_histogram</span><span class="p">(</span><span class="o">~</span><span class="w"> </span><span class="n">sim_df</span><span class="o">$</span><span class="n">residuals</span><span class="p">)</span><span class="o">%&gt;%</span><span class="w"> </span><span class="nf">gf_vline</span><span class="p">(</span><span class="n">.</span><span class="p">,</span><span class="w"> </span><span class="n">xintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The spread of the error distribution tells us by how much we typically miss our predictions. A wide error distribution means a model has a lot of error. The narrower we can make the error distribution, and the less error there is, the better our model.</p>
<p>However, model error isn’t the only thing for us to be aware of when relying on the predictions a model makes. Let’s imagine a situation where the true data generation process only has a very small amount of unaccountable variation, so that we are able to explain almost all the error. We can still make very inaccurate predictions if we use the wrong coefficients in a model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rnorm</span><span class="p">(</span><span class="m">100</span><span class="p">,</span><span class="m">0</span><span class="p">,</span><span class="m">1</span><span class="p">)</span><span class="w">     </span><span class="c1">#defining a random variable</span>
<span class="n">e</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rnorm</span><span class="p">(</span><span class="m">100</span><span class="p">,</span><span class="m">0</span><span class="p">,</span><span class="m">0.1</span><span class="p">)</span><span class="w">   </span><span class="c1">#tiny unexplained error</span>
<span class="n">y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">0.5</span><span class="o">*</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">e</span><span class="w">      </span><span class="c1">#data generation process</span>
<span class="n">sim_df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>

<span class="n">sim_df</span><span class="o">$</span><span class="n">biased_y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">0.5</span><span class="o">*</span><span class="n">sim_df</span><span class="o">$</span><span class="n">x</span>
<span class="n">sim_df</span><span class="o">$</span><span class="n">residuals</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sim_df</span><span class="o">$</span><span class="n">y</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">sim_df</span><span class="o">$</span><span class="n">biased_y</span>

<span class="nf">gf_histogram</span><span class="p">(</span><span class="o">~</span><span class="w"> </span><span class="n">sim_df</span><span class="o">$</span><span class="n">residuals</span><span class="p">)</span><span class="o">%&gt;%</span><span class="w"> </span><span class="nf">gf_vline</span><span class="p">(</span><span class="n">.</span><span class="p">,</span><span class="w"> </span><span class="n">xintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Take a look at the center of both these error distributions. In the first error distribution we made, few residual values were exactly equal to 0 (few predictions were perfect), but across all the residuals they clustered <em>around</em> 0. That means even if any one prediction is unlikely to be perfect, the predictions as a whole aren’t missing in any systematic way.</p>
<p>In contrast, the spread of the second error distribution is narrow, but the central tendency is way off 0. This means that every prediction we are making is wrong, and they’re all wrong in the same way.</p>
<p>This is known as <strong>bias</strong>. A model has error if its predictions are sometimes wrong. A model has bias if the predictions are wrong in a systematic way.</p>
<p>We can use a bulls-eye metaphor to understand predictions in terms of error and bias. If the bulls-eye is the actual value of a datapoint on an outcome variable and each dot is a prediction, model error refers to the spread of those predictions while model bias refers to where those predictions are centered on.</p>
<img src="images/ch20-errorbias.png" width="500"><p>What will make a model biased? Take a look at the model coefficients that were used to make predictions for both error distributions above. In the unbiased model, we used the values “2” and “0.5” as coefficients for the <code class="docutils literal notranslate"><span class="pre">intercept</span></code> and <code class="docutils literal notranslate"><span class="pre">x</span></code>, respectively, in order to make predictions about <code class="docutils literal notranslate"><span class="pre">y</span></code>. These are the exact same values we used in the data generation process for y, so we know the only reason our predictions were off is because we didn’t know the value of <code class="docutils literal notranslate"><span class="pre">e</span></code> to include in the prediction equation.</p>
<p>In the biased model, we used “4” instead of “2” for the coefficient of the intercept. This made our predictions systematically overshoot the actual values of <code class="docutils literal notranslate"><span class="pre">y</span></code>.</p>
<p>While error speaks to the spread of the error distribution, bias is about the central tendency. If the central tendency of the the error distribution is not zero, a model is biased.</p>
</section>
<section id="out-of-sample-predictions">
<h2>19.2 Out-of-sample predictions<a class="headerlink" href="#out-of-sample-predictions" title="Permalink to this heading">#</a></h2>
<p>In practice, if you fit models in R, the model will never be biased <em>for this data sample</em>. This is because R automatically computes the best-fitting coefficients to reduce error and eliminate bias (this is what using the mean as a model does inherently). However, usually we care about more than just these data. A bigger concern is thus whether the model will be biased <em>for new data</em>.</p>
<p>Recall from our discussion of sampling distributions that any one estimate derived from a data sample is unlikely to exactly match the population parameter. For example, let’s simulate an entire population of data with the same data generation process above, and fit a model in just a sample of it:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">set.seed</span><span class="p">(</span><span class="m">30</span><span class="p">)</span>
<span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rnorm</span><span class="p">(</span><span class="m">10000</span><span class="p">,</span><span class="m">0</span><span class="p">,</span><span class="m">1</span><span class="p">)</span><span class="w">  </span><span class="c1">#defining a random variable</span>
<span class="n">e</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rnorm</span><span class="p">(</span><span class="m">10000</span><span class="p">,</span><span class="m">0</span><span class="p">,</span><span class="m">1</span><span class="p">)</span><span class="w">  </span><span class="c1">#some unexplained error</span>
<span class="n">y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">0.5</span><span class="o">*</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">e</span><span class="w">     </span><span class="c1">#data generation process </span>
<span class="n">sim_df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>

<span class="n">sim_sample</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">slice_sample</span><span class="p">(</span><span class="n">sim_df</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="o">=</span><span class="m">100</span><span class="p">,</span><span class="w"> </span><span class="n">replace</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span>

<span class="n">sim_model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sim_sample</span><span class="p">)</span>
<span class="n">sim_model</span>
</pre></div>
</div>
</div>
</div>
<p>Whereas the true intercept and effect of x are 2 and 0.5 respectively, our estimates for those coefficients are 1.95 and 0.57. If we were to use these values to make predictions within a separate dataset:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">set.seed</span><span class="p">(</span><span class="m">40</span><span class="p">)</span>
<span class="n">sim_sample2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">slice_sample</span><span class="p">(</span><span class="n">sim_df</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="o">=</span><span class="m">100</span><span class="p">,</span><span class="w"> </span><span class="n">replace</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span>

<span class="n">sim_sample2</span><span class="o">$</span><span class="n">predicted_y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="n">sim_model</span><span class="p">,</span><span class="w"> </span><span class="n">sim_sample2</span><span class="p">)</span>
<span class="n">sim_sample2</span><span class="o">$</span><span class="n">residuals</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sim_sample2</span><span class="o">$</span><span class="n">y</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">sim_sample2</span><span class="o">$</span><span class="n">predicted_y</span>
<span class="nf">mean</span><span class="p">(</span><span class="n">sim_sample2</span><span class="o">$</span><span class="n">residuals</span><span class="p">)</span><span class="w"> </span><span class="c1">#center of the error distribution</span>
</pre></div>
</div>
</div>
</div>
<p>The residuals are not centered on 0. This is because the model coefficients we used for predictions are just estimates of the population parameter and in this case didn’t exactly match. Making predictions about new data will thus be wrong in a systemic way.</p>
<p>There are a few things we can do to minimize bias when making out-of-sample predictions. One of them is to collect larger samples:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">set.seed</span><span class="p">(</span><span class="m">50</span><span class="p">)</span>
<span class="n">sim_sample</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">slice_sample</span><span class="p">(</span><span class="n">sim_df</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="o">=</span><span class="m">1000</span><span class="p">,</span><span class="w"> </span><span class="n">replace</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span><span class="w"> </span><span class="c1">#bigger sample</span>
<span class="n">sim_model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sim_sample</span><span class="p">)</span>


<span class="n">sim_sample2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">slice_sample</span><span class="p">(</span><span class="n">sim_df</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="o">=</span><span class="m">1000</span><span class="p">,</span><span class="w"> </span><span class="n">replace</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span><span class="w"> </span><span class="c1">#bigger sample</span>

<span class="n">sim_sample2</span><span class="o">$</span><span class="n">predicted_y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="n">sim_model</span><span class="p">,</span><span class="w"> </span><span class="n">newdata</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sim_sample2</span><span class="p">)</span>
<span class="n">sim_sample2</span><span class="o">$</span><span class="n">residuals</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sim_sample2</span><span class="o">$</span><span class="n">y</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">sim_sample2</span><span class="o">$</span><span class="n">predicted_y</span>
<span class="nf">mean</span><span class="p">(</span><span class="n">sim_sample2</span><span class="o">$</span><span class="n">residuals</span><span class="p">)</span><span class="w"> </span><span class="c1">#center of the error distribution</span>
</pre></div>
</div>
</div>
</div>
<p>The center of the error distribution when we make predictions in <code class="docutils literal notranslate"><span class="pre">sim_sample2</span></code> using the model fitted on <code class="docutils literal notranslate"><span class="pre">sim_sample1</span></code> is still not 0, but it’s much closer to 0. This is because of the Central Limit Theorem - with bigger samples, there is less variance in coefficient estimates sample to sample.</p>
<p>Another option is to collect several small samples and then average together their effect:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1">#drawing many samples and saving their coefficients</span>
<span class="n">b0s</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">vector</span><span class="p">(</span><span class="n">length</span><span class="o">=</span><span class="m">100</span><span class="p">)</span>
<span class="n">b1s</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">vector</span><span class="p">(</span><span class="n">length</span><span class="o">=</span><span class="m">100</span><span class="p">)</span>
<span class="nf">for </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="n">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">100</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">sim_sample</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">slice_sample</span><span class="p">(</span><span class="n">sim_df</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="o">=</span><span class="m">100</span><span class="p">,</span><span class="w"> </span><span class="n">replace</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span><span class="w"> </span>
<span class="w">    </span><span class="n">sim_model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sim_sample</span><span class="p">)</span>
<span class="w">    </span><span class="n">b0s</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sim_model</span><span class="o">$</span><span class="n">coefficients</span><span class="p">[[</span><span class="m">1</span><span class="p">]]</span>
<span class="w">    </span><span class="n">b1s</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sim_model</span><span class="o">$</span><span class="n">coefficients</span><span class="p">[[</span><span class="m">2</span><span class="p">]]</span>
<span class="p">}</span>

<span class="n">mean_b0</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">b0s</span><span class="p">)</span>
<span class="n">mean_b1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">b1s</span><span class="p">)</span>

<span class="c1">#predicting new data in the population based on average estimated effect</span>
<span class="n">sim_df</span><span class="o">$</span><span class="n">predicted_y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mean_b0</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">mean_b1</span><span class="o">*</span><span class="n">sim_df</span><span class="o">$</span><span class="n">x</span>
<span class="n">sim_df</span><span class="o">$</span><span class="n">residuals</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sim_df</span><span class="o">$</span><span class="n">y</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">sim_df</span><span class="o">$</span><span class="n">predicted_y</span>
<span class="nf">mean</span><span class="p">(</span><span class="n">sim_df</span><span class="o">$</span><span class="n">residuals</span><span class="p">)</span><span class="w"> </span><span class="c1">#center of the error distribution</span>
</pre></div>
</div>
</div>
</div>
<p>This is what people are doing when they perform a meta-analysis. They are compiling the estimates across many different studies to arrive at one average effect that is hopefully closer to the true population parameter, and thus produces less bias in new predictions.</p>
</section>
<section id="biased-and-unbiased-estimates">
<h2>19.3 Biased and unbiased estimates<a class="headerlink" href="#biased-and-unbiased-estimates" title="Permalink to this heading">#</a></h2>
<p>In the example above, we saw that even if coefficient estimates derived in one sample are different from the true population parameter and produced biased out-of-sample predictions by themselves, <em>on average</em> across many studies these estimates converged on the population parameter. This means that if we repeat our sampling and analysis process many times (or if we get a really big sample size), there is no systematic bias in our estimation of the population parameter. This is the difference between bias in predictions and bias in estimates. Over many data points there may be error in residuals but no bias in predictions. Comparably, over many studies there may be error in effect estimations but no bias in the estimated population parameter.</p>
<p>It is possible to get bias in coefficient estimations, however. This is the worst situation for bias because if your effect estimate is always off, your predictions will always be off too in a systematic way and no amount of sample size or meta-analyzing will help you.</p>
<p>Biased estimators come from the process of building and fitting a model. Typically, the GLM framework produces unbiased estimates. But this only holds if your data meets certain assumptions that the GLM has about it. The GLM framework is really powerful, but it’s not infallible. There are situations where it is not the appropriate statistical method to use. For the rest of the chapter we will learn about the assumptions of the GLM and how to check for them. If your data violate these assumptions, the GLM will produce biased estimates that will never give you good predictions in out-of-sample data. We will also learn what to do about this situation if you find that it is the case with your data.</p>
<p>There are 5 assumptions about how a model fits our data that we want to meet if we are to avoid bias. Violations of these threaten the validity of your statistical conclusions.</p>
<ol class="arabic simple">
<li><p>Linearity</p></li>
<li><p>Homogeneity of variance</p></li>
<li><p>Low leverage</p></li>
<li><p>No multicollinearity</p></li>
<li><p>Normality of residuals</p></li>
</ol>
<p>These assumptions can be evaluated within your data sample, enabling you to take a different modeling approach if this evaluation is less than satisfactory.</p>
</section>
<section id="assumption-1-linearity">
<h2>19.4 Assumption 1: Linearity<a class="headerlink" href="#assumption-1-linearity" title="Permalink to this heading">#</a></h2>
<p>Throughout this course we’ve been learning how to use the General <em>Linear</em> Model for prediction and inference. A “linear” model means that the best fitting regression line through the scatterplot of X/Y association is straight. This is specified during the fitting process by combining predictors with addition. Another way of looking at it is that the slope of the effect of X is the same regardless of the value of X.</p>
<img src="images/ch14-linear.png" width="250">
<p>However another data situation is when the effect of X <em>changes</em> depending on the value of X. In this case, the best-fitting regression line through the data is not straight.</p>
<img src="images/ch14-nonlinear.png" width="250">
<p>The GLM form that we’ve been using assumes that the linear type of relationship is what best fits the data. Much of the time it is safe to assume that the relationship between a predictor and an outcome is linear. However if you happen to be dealing with a nonlinear situation and you misspecify the model as linear by using the basic form of the GLM, this can result in bias.</p>
<p>We can use simulation to see how this bias would play out. First, we will simulate a relationship between x and y where the true <span class="math notranslate nohighlight">\(\beta_1\)</span> is 0.5, but in a log relationship such that as x gets larger, its effect on y gets smaller. You can see such a relationship in the scatterplot below, where the red line is the curved log relationship between x and y:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">set.seed</span><span class="p">(</span><span class="m">10</span><span class="p">)</span>
<span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">runif</span><span class="p">(</span><span class="m">10000</span><span class="p">,</span><span class="m">0</span><span class="p">,</span><span class="m">5</span><span class="p">)</span><span class="w">    </span><span class="c1">#defining a random variable</span>
<span class="n">e</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rnorm</span><span class="p">(</span><span class="m">10000</span><span class="p">,</span><span class="m">0</span><span class="p">,</span><span class="m">1</span><span class="p">)</span><span class="w">    </span><span class="c1">#some unexplained error</span>
<span class="n">x_log</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">log</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">0.5</span><span class="o">*</span><span class="n">x_log</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">e</span><span class="w">  </span><span class="c1">#0.5 is the true b1 value in a log model </span>
<span class="n">sim_df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">x_log</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">)</span>

<span class="n">sim_sample</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sample_n</span><span class="p">(</span><span class="n">sim_df</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="o">=</span><span class="m">100</span><span class="p">,</span><span class="w"> </span><span class="n">replace</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span>

<span class="c1">#scatterplot of true data generation process with incorrect linear predictions</span>
<span class="nf">gf_point</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sim_sample</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="nf">gf_smooth</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s">&#39;red&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now let’s draw many such samples from this data generation process to see the sampling distribution of the <span class="math notranslate nohighlight">\(b_1\)</span> estimates:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1">#sampling many estimates of unbiased b1</span>
<span class="n">nobias_b1s</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">vector</span><span class="p">(</span><span class="n">length</span><span class="o">=</span><span class="m">1000</span><span class="p">)</span>
<span class="nf">for </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="n">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">1000</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">sim_sample</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sample_n</span><span class="p">(</span><span class="n">sim_df</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="o">=</span><span class="m">100</span><span class="p">,</span><span class="w"> </span><span class="n">replace</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span><span class="w"> </span>
<span class="w">    </span><span class="n">sim_model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">x_log</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sim_sample</span><span class="p">)</span><span class="w">  </span>
<span class="w">    </span><span class="n">nobias_b1s</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sim_model</span><span class="o">$</span><span class="n">coefficients</span><span class="p">[[</span><span class="m">2</span><span class="p">]]</span>
<span class="p">}</span>

<span class="c1">#red = unbiased sampling distribution</span>
<span class="n">nobias_b1s_df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span><span class="n">nobias_b1s</span><span class="p">)</span>
<span class="nf">gf_histogram</span><span class="p">(</span><span class="o">~</span><span class="w"> </span><span class="n">nobias_b1s</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">nobias_b1s_df</span><span class="p">,</span><span class="w"> </span><span class="n">fill</span><span class="o">=</span><span class="s">&quot;red&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="m">0.5</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span>
<span class="w">    </span><span class="nf">gf_vline</span><span class="p">(</span><span class="n">.</span><span class="p">,</span><span class="w"> </span><span class="n">xintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">)</span><span class="w"> </span><span class="c1">#true b1 is 0.5</span>
</pre></div>
</div>
</div>
</div>
<p>As we can see from these results, any one sample may find a <span class="math notranslate nohighlight">\(b_1\)</span> estimate that is larger or smaller than the true effect 0.5, but in general they will cluster around 0.5.</p>
<p>Now let’s try a simulation of what happens when the true data generation process is nonlinear like this, but we try to make predictions with a linear model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1">#sampling many estimates of biased b1</span>
<span class="n">bias_b1s</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">vector</span><span class="p">(</span><span class="n">length</span><span class="o">=</span><span class="m">1000</span><span class="p">)</span>
<span class="nf">for </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="n">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">1000</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">sim_sample</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sample_n</span><span class="p">(</span><span class="n">sim_df</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="o">=</span><span class="m">100</span><span class="p">,</span><span class="w"> </span><span class="n">replace</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span><span class="w"> </span>
<span class="w">    </span><span class="n">sim_model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sim_sample</span><span class="p">)</span><span class="w">  </span><span class="c1">#fitting a linear model instead of nonlinear</span>
<span class="w">    </span><span class="n">bias_b1s</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sim_model</span><span class="o">$</span><span class="n">coefficients</span><span class="p">[[</span><span class="m">2</span><span class="p">]]</span>
<span class="p">}</span>

<span class="c1">#red = unbiased sampling distribution</span>
<span class="c1">#blue = biased sampling distribution</span>
<span class="n">nobias_b1s_df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span><span class="n">nobias_b1s</span><span class="p">)</span>
<span class="n">bias_b1s_df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span><span class="n">bias_b1s</span><span class="p">)</span>
<span class="nf">gf_histogram</span><span class="p">(</span><span class="o">~</span><span class="w"> </span><span class="n">nobias_b1s</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">nobias_b1s_df</span><span class="p">,</span><span class="w"> </span><span class="n">fill</span><span class="o">=</span><span class="s">&quot;red&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="m">0.5</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span>
<span class="w">    </span><span class="nf">gf_histogram</span><span class="p">(</span><span class="o">~</span><span class="w"> </span><span class="n">bias_b1s</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">bias_b1s_df</span><span class="p">,</span><span class="w"> </span><span class="n">fill</span><span class="o">=</span><span class="s">&quot;blue&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="m">0.5</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">    </span><span class="nf">gf_vline</span><span class="p">(</span><span class="n">.</span><span class="p">,</span><span class="w"> </span><span class="n">xintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">)</span><span class="w"> </span><span class="c1">#true b1 is 0.5</span>
</pre></div>
</div>
</div>
</div>
<p>This model misspecification causes the sampling distribution of <span class="math notranslate nohighlight">\(b_1\)</span> estimates to center on ~0.3 rather than 0.5 as in the true data generation process. By misspecifying the model, we are systematically wrong on the estimation of <span class="math notranslate nohighlight">\(\beta_1\)</span> and thus making consistently wrong guesses about the effect of x on y. If we were to take a model estimate at face value without investigating whether the data should actually be fit with a linear model, we’d make incorrect conclusions about the true effect size. This is an example of model bias.</p>
</section>
<section id="assumption-2-homogeneity-of-variance">
<h2>19.5 Assumption 2: Homogeneity of variance<a class="headerlink" href="#assumption-2-homogeneity-of-variance" title="Permalink to this heading">#</a></h2>
<p>The second assumption of the GLM is that there is constant residual variance at each level of model prediction. The best way to understand this is visually. We will make a plot where, as a predictor x increases, the error in the model increases as well:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">runif</span><span class="p">(</span><span class="m">10000</span><span class="p">,</span><span class="m">0</span><span class="p">,</span><span class="m">5</span><span class="p">)</span><span class="w">             </span><span class="c1">#defining a random variable</span>
<span class="n">e_het</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">x</span><span class="o">*</span><span class="nf">rnorm</span><span class="p">(</span><span class="m">10000</span><span class="p">,</span><span class="m">0</span><span class="p">,</span><span class="m">1</span><span class="p">)</span><span class="w">    </span><span class="c1">#error gets wider as a function of predictor</span>
<span class="n">e_hom</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rnorm</span><span class="p">(</span><span class="m">10000</span><span class="p">,</span><span class="m">0</span><span class="p">,</span><span class="m">1</span><span class="p">)</span>
<span class="n">y_het</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0.5</span><span class="o">*</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">e_het</span>
<span class="n">y_hom</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0.5</span><span class="o">*</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">e_hom</span>
<span class="n">sim_df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y_het</span><span class="p">,</span><span class="w"> </span><span class="n">y_hom</span><span class="p">)</span>

<span class="n">subsample</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sample_n</span><span class="p">(</span><span class="n">sim_df</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="o">=</span><span class="m">100</span><span class="p">,</span><span class="w"> </span><span class="n">replace</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span>
<span class="n">sub_model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">y_het</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">subsample</span><span class="p">)</span>
<span class="n">subsample</span><span class="o">$</span><span class="n">resid</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">subsample</span><span class="o">$</span><span class="n">y_het</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="n">sub_model</span><span class="p">,</span><span class="w"> </span><span class="n">subsample</span><span class="p">)</span>
<span class="nf">gf_point</span><span class="p">(</span><span class="n">resid</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="o">=</span><span class="n">subsample</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>In this plot we are showing model residuals as they vary with a predictor x. When the assumption of homogeneity of variance is met, this plot should look like a fairly consistent cloud where the range of residuals is about the same for every level of x. If there is instead a clear cone shape like in this plot, this means the residuals are more variable at certain levels of x than others and the assumption is violated. Other words you might hear that refer to this assumption is <strong>homoscedasticity</strong> (when residual variance is homogenous) and <strong>heteroscedasticity</strong> (when residual variance changes as a function of a predictor).</p>
<p>This situation will occur if measurement error is correlated with values of the predictor. Let’s run another simulation and see what happens when this assumption is violated:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1">#sampling distribution of b1 with homoscedastic errors</span>
<span class="n">nobias_b1s</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">vector</span><span class="p">(</span><span class="n">length</span><span class="o">=</span><span class="m">1000</span><span class="p">)</span>
<span class="nf">for </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="n">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">1000</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">sim_sample</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sample_n</span><span class="p">(</span><span class="n">sim_df</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="o">=</span><span class="m">100</span><span class="p">,</span><span class="w"> </span><span class="n">replace</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span><span class="w"> </span>
<span class="w">  </span><span class="n">sim_model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">y_hom</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sim_sample</span><span class="p">)</span><span class="w">  </span><span class="c1">#fitting a model with homoscedastic errors</span>
<span class="w">  </span><span class="n">nobias_b1s</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sim_model</span><span class="o">$</span><span class="n">coefficients</span><span class="p">[[</span><span class="m">2</span><span class="p">]]</span>
<span class="p">}</span>

<span class="c1">#sampling distribution of b1 with heteroscedastic errors</span>
<span class="n">bias_b1s</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">vector</span><span class="p">(</span><span class="n">length</span><span class="o">=</span><span class="m">1000</span><span class="p">)</span>
<span class="nf">for </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="n">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">1000</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">sim_sample</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sample_n</span><span class="p">(</span><span class="n">sim_df</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="o">=</span><span class="m">100</span><span class="p">,</span><span class="w"> </span><span class="n">replace</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span><span class="w"> </span>
<span class="w">  </span><span class="n">sim_model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">y_het</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sim_sample</span><span class="p">)</span><span class="w">  </span><span class="c1">#fitting a model with heteroscedastic errors</span>
<span class="w">  </span><span class="n">bias_b1s</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sim_model</span><span class="o">$</span><span class="n">coefficients</span><span class="p">[[</span><span class="m">2</span><span class="p">]]</span>
<span class="p">}</span>

<span class="c1">#red = unbiased sampling distribution</span>
<span class="c1">#blue = biased sampling distribution</span>
<span class="n">nobias_b1s_df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span><span class="n">nobias_b1s</span><span class="p">)</span>
<span class="n">bias_b1s_df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span><span class="n">bias_b1s</span><span class="p">)</span>
<span class="nf">gf_histogram</span><span class="p">(</span><span class="o">~</span><span class="w"> </span><span class="n">nobias_b1s</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">nobias_b1s_df</span><span class="p">,</span><span class="w"> </span><span class="n">fill</span><span class="o">=</span><span class="s">&quot;red&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="m">0.5</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span>
<span class="w">    </span><span class="nf">gf_histogram</span><span class="p">(</span><span class="o">~</span><span class="w"> </span><span class="n">bias_b1s</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">bias_b1s_df</span><span class="p">,</span><span class="w"> </span><span class="n">fill</span><span class="o">=</span><span class="s">&quot;blue&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="m">0.5</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">    </span><span class="nf">gf_vline</span><span class="p">(</span><span class="n">.</span><span class="p">,</span><span class="w"> </span><span class="n">xintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">)</span><span class="w"> </span><span class="c1">#true b1 is 0.5</span>
</pre></div>
</div>
</div>
</div>
<p>In the data generation process we specified, <span class="math notranslate nohighlight">\(\beta_1\)</span> is 0.5. In samples with homoscedastic errors, the sampling distribution (red) is correctly centered on this value. In samples with heteroscedastic errors, the sampling distribution (blue) is also centered on this value. So what’s the problem? The difference here is that the sampling distribution is <em>wider</em>, despite having the same sample size. It isn’t the model coefficient that is biased in this case, but the <em>standard error</em> is biased to be too big. On average we will detect the right effect, but it will be harder to get an accurate picture of it. Our p-values will be wrong.</p>
<img src="images/ch19-heteroscedasticity.gif" width="800">
<p><em><a class="reference external" href="https://sites.google.com/view/robertostling/home/teaching">gif source</a></em></p>
</section>
<section id="assumption-3-low-leverage">
<h2>19.6 Assumption 3: Low leverage<a class="headerlink" href="#assumption-3-low-leverage" title="Permalink to this heading">#</a></h2>
<p>We’ve discussed outliers before. In review, these are data points that are far outside the other values of a distribution. In a simple histogram, one outlier can change our estimate of the mean (median and mode are more robust to outliers, as you recall). In a general linear model, a value can be an outlier on a predictor variable, the outcome, or both.</p>
<p>Outliers have the potential to bias statistical estimates in GLMs like they do the mean in a histogram, but this isn’t guaranteed. Consider the below simple regression plots, showing a 0.5 linear correlation between an x and y variable with and without an outlier included:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">set.seed</span><span class="p">(</span><span class="m">7</span><span class="p">)</span>
<span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rnorm</span><span class="p">(</span><span class="m">100</span><span class="p">,</span><span class="n">mean</span><span class="o">=</span><span class="m">0</span><span class="p">,</span><span class="n">sd</span><span class="o">=</span><span class="m">1</span><span class="p">)</span><span class="w">    </span><span class="c1">#defining a random predictor</span>
<span class="n">ex</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rnorm</span><span class="p">(</span><span class="m">100</span><span class="p">,</span><span class="n">mean</span><span class="o">=</span><span class="m">0</span><span class="p">,</span><span class="n">sd</span><span class="o">=</span><span class="m">1</span><span class="p">)</span><span class="w">   </span><span class="c1">#some unexplained error</span>
<span class="n">y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0.5</span><span class="o">*</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">ex</span><span class="w">             </span>
<span class="n">sim_df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">)</span>

<span class="c1">#without outlier</span>
<span class="nf">summary</span><span class="p">(</span><span class="nf">lm</span><span class="p">(</span><span class="n">y</span><span class="o">~</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sim_df</span><span class="p">))</span>
<span class="nf">gf_point</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sim_df</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="nf">gf_lm</span><span class="p">(</span><span class="n">interval</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;confidence&quot;</span><span class="p">)</span>

<span class="c1">#with an outlier added</span>
<span class="n">sim_df_outlier</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">add_row</span><span class="p">(</span><span class="n">sim_df</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="o">=</span><span class="m">7</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="o">=</span><span class="m">4</span><span class="p">)</span>
<span class="nf">summary</span><span class="p">(</span><span class="nf">lm</span><span class="p">(</span><span class="n">y</span><span class="o">~</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sim_df_outlier</span><span class="p">))</span>
<span class="nf">gf_point</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sim_df_outlier</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="o">=</span><span class="s">&#39;darkred&#39;</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="nf">gf_lm</span><span class="p">(</span><span class="n">interval</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;confidence&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>In the plot with red dots, the outlier at x=7 is far outside the other x values. But notice that the <span class="math notranslate nohighlight">\(b_1\)</span> estimate in this case (0.52) is not that much different than the initial estimate without an outlier (0.51).</p>
<p>Now consider this plot:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1">#another outlier</span>
<span class="n">sim_df_outlier</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">add_row</span><span class="p">(</span><span class="n">sim_df</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="o">=</span><span class="m">7</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="o">=</span><span class="m">-2</span><span class="p">)</span>
<span class="nf">summary</span><span class="p">(</span><span class="nf">lm</span><span class="p">(</span><span class="n">y</span><span class="o">~</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sim_df_outlier</span><span class="p">))</span>
<span class="nf">gf_point</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sim_df_outlier</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="o">=</span><span class="s">&#39;darkgreen&#39;</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="nf">gf_lm</span><span class="p">(</span><span class="n">interval</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;confidence&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We have another example with an outlier that is extreme on x, but this time the <span class="math notranslate nohighlight">\(b_1\)</span> estimate is 0.23. That’s less than half the size of the correlation estimate without this outlier. What happened?</p>
<p>The answer is something called <strong>leverage</strong>. An outlier has leverage if its presence meaningfully changes the effect estimate in a sample. This would happen if the relationship between the x and y values for that data point are very different than expected; i.e. it has a huge residual. You can see this in the green plot above, where the outlier is far below the regression line. Since the regression line is trying to balance the amount of error above and below, a huge residual for one data point means the line is going to tip towards that outlier to compensate. This is why the outlier in the red plot didn’t have much leverage - its values were extreme on x and y, but it still fell close to the initial regression line so it didn’t change the slope estimate by much.</p>
<p>Here is a simulation of the effect of adding one outlier to a sample of data:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1">#sampling many estimates of unbiased b1</span>
<span class="n">nobias_b1s</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">vector</span><span class="p">(</span><span class="n">length</span><span class="o">=</span><span class="m">1000</span><span class="p">)</span>
<span class="nf">for </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="n">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">1000</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">sim_sample</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">slice_sample</span><span class="p">(</span><span class="n">sim_df</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="o">=</span><span class="m">100</span><span class="p">,</span><span class="w"> </span><span class="n">replace</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span><span class="w"> </span>
<span class="w">    </span><span class="n">sim_model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sim_sample</span><span class="p">)</span><span class="w">  </span>
<span class="w">    </span><span class="n">nobias_b1s</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sim_model</span><span class="o">$</span><span class="n">coefficients</span><span class="p">[[</span><span class="m">2</span><span class="p">]]</span>
<span class="p">}</span>

<span class="c1">#sampling many estimates of biased b1</span>
<span class="n">bias_b1s</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">vector</span><span class="p">(</span><span class="n">length</span><span class="o">=</span><span class="m">1000</span><span class="p">)</span>
<span class="nf">for </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="n">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">1000</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">sim_sample</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">slice_sample</span><span class="p">(</span><span class="n">sim_df</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="o">=</span><span class="m">100</span><span class="p">,</span><span class="w"> </span><span class="n">replace</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span>
<span class="w">    </span><span class="n">outlier_sample</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">add_row</span><span class="p">(</span><span class="n">sim_sample</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="o">=</span><span class="nf">rnorm</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">0</span><span class="p">,</span><span class="m">5</span><span class="p">),</span><span class="w"> </span><span class="n">y</span><span class="o">=</span><span class="nf">rnorm</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">0</span><span class="p">,</span><span class="m">5</span><span class="p">))</span><span class="w"> </span>
<span class="w">    </span><span class="n">sim_model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">outlier_sample</span><span class="p">)</span><span class="w">  </span><span class="c1">#fitting a linear model instead of nonlinear</span>
<span class="w">    </span><span class="n">bias_b1s</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sim_model</span><span class="o">$</span><span class="n">coefficients</span><span class="p">[[</span><span class="m">2</span><span class="p">]]</span>
<span class="p">}</span>

<span class="c1">#red = unbiased sampling distribution</span>
<span class="c1">#blue = biased sampling distribution</span>
<span class="n">nobias_b1s_df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span><span class="n">nobias_b1s</span><span class="p">)</span>
<span class="n">bias_b1s_df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span><span class="n">bias_b1s</span><span class="p">)</span>
<span class="nf">gf_histogram</span><span class="p">(</span><span class="o">~</span><span class="w"> </span><span class="n">nobias_b1s</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">nobias_b1s_df</span><span class="p">,</span><span class="w"> </span><span class="n">fill</span><span class="o">=</span><span class="s">&quot;red&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="m">0.5</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span>
<span class="w">    </span><span class="nf">gf_histogram</span><span class="p">(</span><span class="o">~</span><span class="w"> </span><span class="n">bias_b1s</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">bias_b1s_df</span><span class="p">,</span><span class="w"> </span><span class="n">fill</span><span class="o">=</span><span class="s">&quot;blue&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="m">0.5</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">    </span><span class="nf">gf_vline</span><span class="p">(</span><span class="n">.</span><span class="p">,</span><span class="w"> </span><span class="n">xintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">)</span><span class="w"> </span><span class="c1">#true b1 is 0.5</span>
</pre></div>
</div>
</div>
</div>
<p>There’s a bit of bias to this blue distribution (it’s not perfectly normal), because more often “noise” like an outlier added to a variable will make statistical associations weaker instead of stronger. The biased sampling distribution is also wider, so we have a problem with the standard error estimate again. In situations with leverage, our <span class="math notranslate nohighlight">\(b_1\)</span> estimates are likely to be biased downwards <em>and</em> our p-values will be wrong.</p>
</section>
<section id="assumption-4-normality-of-residuals">
<h2>19.7 Assumption 4: Normality of residuals<a class="headerlink" href="#assumption-4-normality-of-residuals" title="Permalink to this heading">#</a></h2>
<p>A related situation is when there isn’t one particular data point with a lot of leverage, but the overall error distribution is highly skewed. Here’s an example of what non-normal residuals might look like:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">runif</span><span class="p">(</span><span class="m">10000</span><span class="p">,</span><span class="m">0</span><span class="p">,</span><span class="m">5</span><span class="p">)</span><span class="w">           </span><span class="c1">#defining a random variable</span>
<span class="n">e_norm</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">runif</span><span class="p">(</span><span class="m">10000</span><span class="p">,</span><span class="m">0</span><span class="p">,</span><span class="m">1</span><span class="p">)</span>
<span class="n">e_skew</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">log</span><span class="p">(</span><span class="nf">runif</span><span class="p">(</span><span class="m">10000</span><span class="p">,</span><span class="m">0</span><span class="p">,</span><span class="m">1</span><span class="p">))</span><span class="w"> </span><span class="c1">#error is skewed, not normal</span>
<span class="n">e_skew</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">e_skew</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">e_skew</span><span class="p">)</span><span class="w"> </span><span class="c1">#mean centering the error term</span>
<span class="nf">gf_histogram</span><span class="p">(</span><span class="o">~</span><span class="w"> </span><span class="n">e_skew</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>This distribution means most of our residuals are small, but the ones that aren’t are all in the same direction.</p>
<p>Now we simulate what such an error distribution does to our model estimations:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">y_norm</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0.5</span><span class="o">*</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">e_norm</span>
<span class="n">y_skew</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0.5</span><span class="o">*</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">e_skew</span>
<span class="n">sim_df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y_skew</span><span class="p">,</span><span class="w"> </span><span class="n">y_norm</span><span class="p">)</span>

<span class="c1">#sampling distribution of b1 with normal errors</span>
<span class="n">nobias_b1s</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">vector</span><span class="p">(</span><span class="n">length</span><span class="o">=</span><span class="m">1000</span><span class="p">)</span>
<span class="nf">for </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="n">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">1000</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">sim_sample</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sample_n</span><span class="p">(</span><span class="n">sim_df</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="o">=</span><span class="m">100</span><span class="p">,</span><span class="w"> </span><span class="n">replace</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span><span class="w"> </span>
<span class="w">  </span><span class="n">sim_model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">y_norm</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sim_sample</span><span class="p">)</span><span class="w">  </span>
<span class="w">  </span><span class="n">nobias_b1s</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sim_model</span><span class="o">$</span><span class="n">coefficients</span><span class="p">[[</span><span class="m">2</span><span class="p">]]</span>
<span class="p">}</span>

<span class="c1">#sampling distribution of b1 with skewed errors</span>
<span class="n">bias_b1s</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">vector</span><span class="p">(</span><span class="n">length</span><span class="o">=</span><span class="m">1000</span><span class="p">)</span>
<span class="nf">for </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="n">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">1000</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">sim_sample</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sample_n</span><span class="p">(</span><span class="n">sim_df</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="o">=</span><span class="m">100</span><span class="p">,</span><span class="w"> </span><span class="n">replace</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span><span class="w"> </span>
<span class="w">  </span><span class="n">sim_model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">y_skew</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sim_sample</span><span class="p">)</span><span class="w">  </span>
<span class="w">  </span><span class="n">bias_b1s</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sim_model</span><span class="o">$</span><span class="n">coefficients</span><span class="p">[[</span><span class="m">2</span><span class="p">]]</span>
<span class="p">}</span>

<span class="c1">#red = unbiased sampling distribution</span>
<span class="c1">#blue = biased sampling distribution</span>
<span class="n">nobias_b1s_df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span><span class="n">nobias_b1s</span><span class="p">)</span>
<span class="n">bias_b1s_df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span><span class="n">bias_b1s</span><span class="p">)</span>
<span class="nf">gf_histogram</span><span class="p">(</span><span class="o">~</span><span class="w"> </span><span class="n">nobias_b1s</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">nobias_b1s_df</span><span class="p">,</span><span class="w"> </span><span class="n">fill</span><span class="o">=</span><span class="s">&quot;red&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="m">0.5</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span>
<span class="w">    </span><span class="nf">gf_histogram</span><span class="p">(</span><span class="o">~</span><span class="w"> </span><span class="n">bias_b1s</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">bias_b1s_df</span><span class="p">,</span><span class="w"> </span><span class="n">fill</span><span class="o">=</span><span class="s">&quot;blue&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="m">0.5</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">    </span><span class="nf">gf_vline</span><span class="p">(</span><span class="n">.</span><span class="p">,</span><span class="w"> </span><span class="n">xintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">)</span><span class="w"> </span><span class="c1">#true b1 is 0.5</span>
</pre></div>
</div>
</div>
</div>
<p>In this case, the sampling distribution is not really biased but the standard error will be wrong. Our p-values will be off if we don’t stop to consider and fix this situation.</p>
<p>Note that this assumption is about the normality of the distribution of <em>residuals</em> in a model, not the distribution of the <em>raw variables</em>. That is a common misconception. A highly non-normal predictor or outcome can still produce normally-distributed errors in the model in many situations. To assess this assumption you need to check the error distribution specifically.</p>
</section>
<section id="assumption-5-no-multicollinearity">
<h2>19.8 Assumption 5: No multicollinearity<a class="headerlink" href="#assumption-5-no-multicollinearity" title="Permalink to this heading">#</a></h2>
<p>The last GLM assumption that you can check for in the data has to do with how closely related predictors are in a model if you have more than one. As we learned in chapter 13, if both x1 and x2 are both possible explanatory variables of y, you should include them both in a general linear model. However, it can be problematic to make conclusions about the model estimates if the predictors are highly correlated with each other. If the variation in y explained by the predictors is almost entirely overlapping, that means there is almost no unique variation attributable to either one. In that case, minute differences in the values of each variable can result in huge swings and instability in the model estimates from sample to sample. This situation is called <strong>multicollinearity</strong>.</p>
<p>Here’s an example of what multicollinearity can do to model estimates. We’ll first generate predictor variables that are closely related to eachother:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">x1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">runif</span><span class="p">(</span><span class="m">10000</span><span class="p">,</span><span class="m">0</span><span class="p">,</span><span class="m">5</span><span class="p">)</span><span class="w">    </span><span class="c1">#defining a random variable</span>
<span class="n">ex</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rnorm</span><span class="p">(</span><span class="m">10000</span><span class="p">,</span><span class="m">0</span><span class="p">,</span><span class="m">0.5</span><span class="p">)</span><span class="w">  </span><span class="c1">#small amount of unexplained error between predictors</span>
<span class="n">x2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">x1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">ex</span><span class="w">             </span><span class="c1">#another, highly related predictor variable</span>
<span class="n">ey</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rnorm</span><span class="p">(</span><span class="m">10000</span><span class="p">,</span><span class="m">0</span><span class="p">,</span><span class="m">1</span><span class="p">)</span><span class="w">    </span><span class="c1">#some unexplained error in the model</span>
<span class="n">y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0.5</span><span class="o">*</span><span class="n">x1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">ey</span><span class="w">          </span><span class="c1">#true data generation process only involves x1</span>
<span class="n">sim_df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span><span class="w"> </span><span class="n">x2</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>In this data generation process, the true effect of x1 should be 0.5 and x2 is not a part of it. If we repeatedly sample and estimate the effect of x1 in a multivariable model when there is multicollinearity:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1">#sampling many estimates of unbiased b1</span>
<span class="n">nobias_b1s</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">vector</span><span class="p">(</span><span class="n">length</span><span class="o">=</span><span class="m">1000</span><span class="p">)</span>
<span class="nf">for </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="n">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">1000</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">sim_sample</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sample_n</span><span class="p">(</span><span class="n">sim_df</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="o">=</span><span class="m">100</span><span class="p">,</span><span class="w"> </span><span class="n">replace</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span><span class="w"> </span>
<span class="w">  </span><span class="n">sim_model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">x1</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sim_sample</span><span class="p">)</span><span class="w"> </span>
<span class="w">  </span><span class="n">nobias_b1s</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sim_model</span><span class="o">$</span><span class="n">coefficients</span><span class="p">[[</span><span class="m">2</span><span class="p">]]</span>
<span class="p">}</span>

<span class="c1">#sampling many estimates of biased b1</span>
<span class="n">bias_b1s</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">vector</span><span class="p">(</span><span class="n">length</span><span class="o">=</span><span class="m">1000</span><span class="p">)</span>
<span class="nf">for </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="n">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">1000</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">sim_sample</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sample_n</span><span class="p">(</span><span class="n">sim_df</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="o">=</span><span class="m">100</span><span class="p">,</span><span class="w"> </span><span class="n">replace</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span><span class="w"> </span>
<span class="w">  </span><span class="n">sim_model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">x1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">x2</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sim_sample</span><span class="p">)</span><span class="w"> </span>
<span class="w">  </span><span class="n">bias_b1s</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sim_model</span><span class="o">$</span><span class="n">coefficients</span><span class="p">[[</span><span class="m">2</span><span class="p">]]</span>
<span class="p">}</span>

<span class="c1">#red = unbiased sampling distribution</span>
<span class="c1">#blue = biased sampling distribution</span>
<span class="n">nobias_b1s_df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span><span class="n">nobias_b1s</span><span class="p">)</span>
<span class="n">bias_b1s_df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span><span class="n">bias_b1s</span><span class="p">)</span>
<span class="nf">gf_histogram</span><span class="p">(</span><span class="o">~</span><span class="w"> </span><span class="n">nobias_b1s</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">nobias_b1s_df</span><span class="p">,</span><span class="w"> </span><span class="n">fill</span><span class="o">=</span><span class="s">&quot;red&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="m">0.5</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span>
<span class="w">    </span><span class="nf">gf_histogram</span><span class="p">(</span><span class="o">~</span><span class="w"> </span><span class="n">bias_b1s</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">bias_b1s_df</span><span class="p">,</span><span class="w"> </span><span class="n">fill</span><span class="o">=</span><span class="s">&quot;blue&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="m">0.5</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">    </span><span class="nf">gf_vline</span><span class="p">(</span><span class="n">.</span><span class="p">,</span><span class="w"> </span><span class="n">xintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">)</span><span class="w"> </span><span class="c1">#true b1 is 0.5</span>
</pre></div>
</div>
</div>
</div>
<p>We don’t get much bias for the <span class="math notranslate nohighlight">\(b_1\)</span> estimate, but the standard error is wrong (width of sampling distribution). This has an unfortunate effect on the p-values of <em>both</em> x1 and x2 in the model. There’s an inflated Type I error risk for x2 (the non-causal predictor) and Type II error risk for x1 (the real predictor). A model with multicollinearity is both more likely to find the wrong predictor as significant and more likely to miss which predictor is actually important.</p>
</section>
<section id="checking-for-violations-of-model-assumptions">
<h2>19.9 Checking for violations of model assumptions<a class="headerlink" href="#checking-for-violations-of-model-assumptions" title="Permalink to this heading">#</a></h2>
<p>These assumptions we’ve discussed so far (linearity, homogeneity of variance, low leverage, normality of residuals, and no multicollinearity) are problems with the error distribution that comes out of a model. Thus, by plotting and examining the error distribution in certain ways, we can investigate if the assumptions are violated or if we can trust our general linear modeling procedure.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">performance</span></code> package has a really easy method of checking all these assumptions at once, in the <code class="docutils literal notranslate"><span class="pre">check_model()</span></code> function. For example, let’s check how a multiple regression model example from the GSS dataset performs on these assumption checks.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">GSS</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">read.csv</span><span class="p">(</span><span class="s">&quot;https://raw.githubusercontent.com/smburns47/Psyc158/main/GSS.csv&quot;</span><span class="p">)</span>
<span class="nf">set.seed</span><span class="p">(</span><span class="m">10</span><span class="p">)</span>
<span class="n">GSS_subset</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">slice_sample</span><span class="p">(</span><span class="n">GSS</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="o">=</span><span class="m">100</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span>
<span class="w">    </span><span class="nf">select</span><span class="p">(</span><span class="n">.</span><span class="p">,</span><span class="w"> </span><span class="n">highest_year_of_school_completed</span><span class="p">,</span><span class="w"> </span><span class="n">born_in_us</span><span class="p">,</span><span class="w"> </span><span class="n">highest_year_school_completed_father</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">    </span><span class="nf">na.omit</span><span class="p">(</span><span class="n">.</span><span class="p">)</span>

<span class="n">m</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">highest_year_of_school_completed</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">highest_year_school_completed_father</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">born_in_us</span><span class="p">,</span><span class="w"> </span>
<span class="w">        </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GSS_subset</span><span class="p">)</span>
<span class="nf">check_model</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Walking through these panels one by one, let’s first consider the top left. This shows a bunch of predicted outcome variable distributions (blue lines) our model form would make in a simulated resampling procedure. The thick green line is a smoothed version of the actual data distribution. While this panel doesn’t check any model assumptions directly, it can let you see if the predicted distributions of the outcome variable generally resemble the actual distribution. In this example, it looks like our predicted distributions on average aren’t too far off. But there could be subtle assumption violations still, so let’s move on to the next panel.</p>
<p>The top right panel checks the linearity assumption. If the relationship between predictors and outcome is linear, then residuals should be randomly distributed at all values of predictions. However if the relationship is nonlinear, a linear model will systematically underpredict some data points at one end of the outcome range and overpredict some data points at the other end of the outcome range. Thus in this scatterplot between a predicted outcome value and accompanying residual, you want the best fitting line to be approximately flat. If it’s not, then that indicates the linearity assumption is violated. In this example, it looks like the best-fitting line is mostly flat, except for one point at the left side of the plot.</p>
<p>Moving to the middle left plot, this investigates homogeneity of variance. This plots the variance of the residuals this time, as a function of predicted values. Remember that this assumption says there is constant variance at all levels of the variable - thus, we want this plot to have a mostly flat horizontal line. If it’s notably lifted on either side, we have a situation of heteroscedasticity. In this example plot, looks again like there’s one data point that’s driving some heteroscedasticity on the left side of the plot.</p>
<p>The middle right plot investigates leverage. This plots amount of outlierness h (expressed as metric called <a class="reference external" href="https://en.wikipedia.org/wiki/Cook%27s_distance">Cook’s Distance</a>) against the size of that data point’s residual. The more a datapoint is an outlier, the smaller its residual needs to be to have high leverage on the model estimate. For this reason there is a cone in the plot to designate zones of leverage. Inside the cone are data points with low leverage, outside the cone are data points with high leverage. If a point has high leverage, it will also be colored red in this plot. In this way, we can see there is a datapoint that has been identified as high leverage - observation 48 in the dataset on which the model was fit. This data point is also probably the reason for the non-flat lines in the linearity and homogeneity of variance plots.</p>
<p>The bottom left panel assesses multicollinearity using a metric called <a class="reference external" href="https://en.wikipedia.org/wiki/Variance_inflation_factor">Variance Inflation Factor (VIF)</a>. We want a low VIF, meaning that the predictors in the model aren’t highly related to each other and thus there is low multicollinearity. This plot defines a cutoff VIF of 5 as being the point at which parameter estimates become uncertain to a problematic degree. The VIF for each of the predictors in our example is far below the cutoff, so we don’t violate the assumption of multicollinearity in this example.</p>
<p>Finally, the bottom right panel assesses normality of residuals. This assesses the proportion of the error distribution that should fall in each quantile (if it follows a standard normal distribution), vs. the proportion of the error distribution that is actually in each quantile in this sample. Dots should fall mostly along the flat line at 0. If many of these dots vear far off the 0 line, the assumption of normal residuals is violated.</p>
<p>The key to interpreting this plot is to know that assumption violation is a spectrum, not a yes/no quality. While we can come up with some har cutoffs (like VIF = 5 or the leverage zone), some datasets will violate assumptions much more strongly than others. Thus you need to use your judgment to decide if a little bit of violation, and thus a little bit of bias, is ok or not.</p>
</section>
<section id="what-to-do-about-model-assumption-violations">
<h2>19.10 What to do about model assumption violations<a class="headerlink" href="#what-to-do-about-model-assumption-violations" title="Permalink to this heading">#</a></h2>
<p>If the <code class="docutils literal notranslate"><span class="pre">check_model()</span></code> plot tells you no assumptions are seriously violated, then you are good to use the GLM to test your hypotheses about your data. However, if any of these assumptions are violated, then you shouldn’t trust the effect estimates or statistical significance given by the GLM. Instead, depending on what these assumption violations are, there are some alternative approaches you can use. These are advanced approaches beyond the scope of this intro class, but below are common options that you can read more about if you’d like:</p>
<ul class="simple">
<li><p>Non-linear modeling: if the assumption of linearity is violated, this implies that a straight line is not the best relationship between a predictor and outcome. Other forms may better describe this relationship that you can capture by transforming a predictor variable (e.g., by log transforming X or making it into a quadratic term). Alternatively you can use tools that make more general assumptions, such as “when X goes up some amount Y goes up some amount” (i.e. <a class="reference external" href="https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient">Spearman Rank Correlation</a>) or “uncertainty in Y is reduced by knowing X” (i.e. <a class="reference external" href="https://en.wikipedia.org/wiki/Mutual_information">Mutual Information</a>).</p></li>
<li><p>Dimensionality reduction: The simplest way to deal with multicollinearity is to remove less important variables from your model, as this may be happening because one variable is essentially the same construct as another. However if it’s not clear what variable should just be removed, there are more advanced tools that search for the amount of shared variation between the multicollinear predictors and make new variable(s) just out of that. Such tools include <a class="reference external" href="https://towardsdatascience.com/exploratory-factor-analysis-in-r-e31b0015f224">factor analysis</a>, <a class="reference external" href="https://www.r-bloggers.com/2021/05/principal-component-analysis-pca-in-r/">principle component analysis</a>, and <a class="reference external" href="https://www.statology.org/ridge-regression-in-r/">ridge regression</a>.</p></li>
<li><p>Robust estimation: The simplest way to try and deal with leverage, non-normal residuals, and heteroscedasticity is to remove specific outliers that are the reason for the problem. But if the problem isn’t due to specific outliers that you can find, or if your power is so low that removing data points is a problem, there are other modeling options such as <a class="reference external" href="https://stats.oarc.ucla.edu/r/dae/robust-regression/">robust regression</a>, which weights the contribution of data points to the model fit by their leverage. This means that high leverage points or non-normal residuals have less influence on the final parameter estimates. This preserves more degrees of freedom and thus statistical power than simply removing a bunch of data points.</p></li>
</ul>
</section>
<section id="other-sources-of-bias">
<h2>19.11 Other sources of bias<a class="headerlink" href="#other-sources-of-bias" title="Permalink to this heading">#</a></h2>
<p>The five assumptions above have to do with the way a model form fits a set of data. If these assumptions are violated you want to change your approach to modeling, but luckily you can make that change at the analysis step.</p>
<p>However there are other sources of bias in data that occur because of the way data was collected. This is harder to detect post-hoc and might not be able to be fixed after data collection. For this reason, you should consider these sources when you are first designing a study and recruiting subjects so that you don’t create serious limitations in your research.</p>
<section id="non-representative-samples">
<h3>Non-representative samples<a class="headerlink" href="#non-representative-samples" title="Permalink to this heading">#</a></h3>
<p>We’ve discussed before what it means to have a representative sample - the distribution of data in the sample closely resembles the distribution of data in the population. When your data sample is representative, the statistical estimates you make in that sample have the best chance of resembling the true population parameter. A difference between your estimate and the population parameter can happen just by bad luck during random sampling: we just happen to draw a particularly strange sample by chance. But over many samples, random sampling will insure that on the whole our samples are representative and our estimates unbiased.</p>
<p>If there’s any reason our sampling process is not representative, those estimates might be biased even across many samples. For example, there is a famous saying that “money does not buy happiness”. If you were to test this statistically, you might look for a significant relationship between how much money people make and their happiness levels. But if you were to conduct this research only with college graduates (who make on average 80% higher salaries than non-grads), you would only be investigating the relationship between money and happiness in people with more money, not across all income brackets. No matter what sample you drew, if it was not representative of the wider population, you might get a biased estimate (and you might miss the fact that <a class="reference external" href="http://content.time.com/time/magazine/article/0,9171,2019628,00.html">money is indeed correlated with happiness</a> at lower income levels where financial security is threatened). If your estimate is biased due to nonrepresentative sampling, it might apply to this specific subset of the population, but not **generalize to other populations of people.</p>
<p>One way a sample can be unrepresentative is if you don’t have values from the full range of population values on your outcome. When your data is missing the full range of the outcome variable, there’s less variation present that would be explained by the predictor. Noise now has a bigger proportional presence, and the predictor can’t reliably explain noise, so it estimates a weaker effect.</p>
<img src="images/ch20-selectiony.gif" width="500">
<p><em><a class="reference external" href="https://sites.google.com/view/robertostling/home/teaching">gif source</a></em></p>
<p>Interestingly, the same is not true for truncating the x variable. On average, the sampling distribution will still cluster around the true effect for x. The difference here is that the estimate is more variable, which affects standard errors.</p>
<img src="images/ch20-selectionx.gif" width="500">
<p><em><a class="reference external" href="https://sites.google.com/view/robertostling/home/teaching">gif source</a></em></p>
<p>A nonrepresentative sample doesn’t <em>guarantee</em> that your estimates will be biased. Estimates will only be biased if your sample is non-representative on variables that are involved in the data generation process you are investigating. If you are investigating the relationship between money and happiness but only have a sample of right-handed people, there’s a pretty good argument to make that being right or left handed doesn’t influence how happy money makes you. So the assumption of representativeness only applies to variables that are involved in the particular data generation process you are investigating.</p>
</section>
<section id="omitted-variable-bias">
<h3>Omitted variable bias<a class="headerlink" href="#omitted-variable-bias" title="Permalink to this heading">#</a></h3>
<p>In doing research and building theory, we are trying to create a model that closely approximates the data generation process. This means we hope to identify the predictor variables that are important for creating the outcome variable, with the right relationships between them. If we leave out important parts of the data generation process, especially variables that confound other predictors or are involved in interactions with other predictors, this will create bias in the parameter estimates for the predictors we do have. Such bias is called <strong>omitted variable bias</strong>. Omitted variable bias is responsible for erroneous conclusions in psychology, such as the notion that <a class="reference external" href="https://www.washingtonpost.com/science/2024/08/29/research-bias-cognitive-studies-executive-function-marshmallow-test/">the marshmellow test predicts self-control ability</a> or that <a class="reference external" href="https://www.scientificamerican.com/article/darwin-was-wrong-your-facial-expressions-do-not-reveal-your-emotions/">AI can accurately read people’s emotions through their facial expressions</a>, or that <a class="reference external" href="https://www.vox.com/2014/8/14/5999119/polygraphs-lie-detectors-do-they-work">you can detect lies with a polygraph test</a>. In all these cases, important other variables like cultural background or basic physiological processes better explain or moderate the initial effect.</p>
<p>To avoid omitted variable bias, we need to think hard about what is known of the true data generation process of an outcome variable, not just one predictor we are interested in. This means staying up to date with the latest research literature on your topic of interest and plotting out conceptual models with as much detail as one can. We should then collect these other important variables in our study and incorporate them into our modeling procedure.</p>
</section>
<section id="qualitative-outcome-variable">
<h3>Qualitative outcome variable<a class="headerlink" href="#qualitative-outcome-variable" title="Permalink to this heading">#</a></h3>
<p>Many of the model assumptions discussed earlier end up violated in cases when there are not a lot of unique values in the outcome variable - e.g. when it is ordinal or categorical. Consider an example where you are predicting what political party someone will join as a function of their SES. With the form of the GLM that we have learned in this course, we could predict something quantitative like position on a liberal/conservative spectrum. But if the outcome variable has instead been recorded as “Democrat” and “Republican”, this is categorical information. There’s no “increase in Y” we can predict in this case because there aren’t quantitative values to this variable.</p>
<p>For this reason, the problems with dichotomizing a predictor variable persist when dichotomizing an outcome variable. If at all possible, one should avoid dichotomization/binning at the time of data collection.</p>
<p>However, some variables in the world truly are categorical - e.g. whether or not someone dies from an illness, what state they live in, etc. If we try to make <em>these</em> variables into quantitative data by labeling them with numbers, we’d be making another error. This would be assuming that there’s sortability to these categories, and that values between whole numbers are possible to predict.</p>
<p>The solution in this case is to use a more advanced type of modeling procedure. For binary categorical data, use <a class="reference external" href="https://stats.oarc.ucla.edu/r/dae/logit-regression/">logistic regression</a>. For more categories or ordinal outcome data, use <a class="reference external" href="https://stats.oarc.ucla.edu/r/dae/ordinal-logistic-regression/">ordinal regression</a>.</p>
</section>
<section id="repeated-measures">
<h3>Repeated measures<a class="headerlink" href="#repeated-measures" title="Permalink to this heading">#</a></h3>
<p>When we collect data, sample size matters in a lot of ways. Things like p-values and error scores are calculating using degrees of freedom. This is because we assume with each new data point, we have more information about the population. Another way of saying this is that we assume data points are <em>independent</em> of each other. If you know the data value for one observation, you’re not able to predict what the next data point will be.</p>
<p>However, data points might not always be independent. Consider a situation where you are interested in a new test anxiety intervention, so you give some students the intervention and others you leave alone as a control group. Throughout the semester, you measure the students’ test scores (on 3 separate exams) so that you have 3*N observations in your dataset - one score per test, per student. You want to see if there’s a difference between the group averages.</p>
<p>If every student took three exams during the semester, do you think those three exam scores are independent of each other? If you knew student A’s score on exam 1, would it be easier to guess their score on exam 2 than for an entirely different student?</p>
<p>This is an example of what is called <strong>repeated measures</strong>. We took measurements from the same source (one person), and those measurements are probably not the same. But they are likely similar, such that there is more similarity between scores from the same person than there is between scores of different people. We are repeatedly measuring information from the same source, so we don’t have completely new information each time. Who these scores come from affects the scores.</p>
<img src="images/ch19-repeatedmeasures.png" width="800">
<p>If you run a GLM analysis on these data, you are implicitly assuming that there is more information (and more degrees of freedom) in your dataset than is actually available. This will bias standard error estimates downwards, as you think your sample size is bigger than it effectively is.</p>
<p>To avoid this issue, we should consider whether there is any shared source that multiple data points in a study are coming from - the same person, same dyad of people, same school, etc. We shouldn’t get rid of these repeated measures though by averaging within the source or only taking one data point per person. Oftentimes repeated measures can be a helpful way to get extra statistical power in a study. What we should do instead is use different statistical tools that don’t assume independent data. These include the <a class="reference external" href="https://www.r-bloggers.com/2021/10/paired-sample-t-test-using-r/">paired samples t-test</a> when there is a pre and post score per person; <a class="reference external" href="https://www.datanovia.com/en/lessons/repeated-measures-anova-in-r/">repeated measures ANOVA</a> when doing a within-subjects design with subjects exposed to multiple conditions; or <a class="reference external" href="https://m-clark.github.io/mixed-models-with-R/random_intercepts.html">mixed-effects modeling</a> as a more general approach to dealing with repeated measures.</p>
</section>
</section>
<section id="chapter-summary">
<h2>Chapter Summary<a class="headerlink" href="#chapter-summary" title="Permalink to this heading">#</a></h2>
<p>After reading this chapter, you should be able to:</p>
<ul class="simple">
<li><p>Explain the difference between error and bias</p></li>
<li><p>Explain the difference between biased and unbiased estimators</p></li>
<li><p>Describe the assumptions of the general linear model where violations lead to model bias</p></li>
<li><p>Check for these assumptions in a dataset</p></li>
<li><p>Consider other sources of bias introduced at the time of data collection</p></li>
</ul>
</section>
<section id="new-concepts">
<h2>New concepts<a class="headerlink" href="#new-concepts" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p><strong>bias</strong>: In contrast to error (when predictions or estimates don’t match the true values), bias occurs when these predictions/estimates are wrong in a systematic way.</p></li>
<li><p><strong>homoscedasticity</strong>: When the variance in model residuals is consisent for the whole range of model prediction values.</p></li>
<li><p><strong>heteroscedasticity</strong>: When the variance in model residuals varies as a function of the model predicted value. Results in unstable effect estimates in the model.</p></li>
<li><p><strong>leverage</strong>: A data point has high leverage on a model estimate when it’s inclusion/exclusion heavily influences what the model estimate is.</p></li>
<li><p><strong>multicollinearity</strong>: A situation when two or more predictors in a model are highly related to each other, and thus not much unique variation can be explained by either. Results in unstable effect estimates for these predictors.</p></li>
<li><p><strong>omitted variable bias</strong>: When bad statistical conclusions are made because some important component of the data generation process was left out of modeling.</p></li>
<li><p><strong>repeated measures</strong>: Multiple datapoints that are collected from the same “source” and thus are not wholly independent from each other.</p></li>
</ul>
</section>
<section id="new-r-functionality">
<h2>New R functionality<a class="headerlink" href="#new-r-functionality" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://easystats.github.io/performance/reference/check_model.html">performance::check_model()</a></p></li>
</ul>
<p><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-20.ipynb">Next: Chapter 20 - Alternate Approaches - Traditional Statistical Tools</a></p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "smburns47/Psyc158",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "r"
        },
        kernelOptions: {
            name: "ir",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'ir'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#error-vs-bias">19.1 Error vs. bias</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#out-of-sample-predictions">19.2 Out-of-sample predictions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#biased-and-unbiased-estimates">19.3 Biased and unbiased estimates</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#assumption-1-linearity">19.4 Assumption 1: Linearity</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#assumption-2-homogeneity-of-variance">19.5 Assumption 2: Homogeneity of variance</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#assumption-3-low-leverage">19.6 Assumption 3: Low leverage</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#assumption-4-normality-of-residuals">19.7 Assumption 4: Normality of residuals</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#assumption-5-no-multicollinearity">19.8 Assumption 5: No multicollinearity</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#checking-for-violations-of-model-assumptions">19.9 Checking for violations of model assumptions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-to-do-about-model-assumption-violations">19.10 What to do about model assumption violations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#other-sources-of-bias">19.11 Other sources of bias</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#non-representative-samples">Non-representative samples</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#omitted-variable-bias">Omitted variable bias</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#qualitative-outcome-variable">Qualitative outcome variable</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#repeated-measures">Repeated measures</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#chapter-summary">Chapter Summary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#new-concepts">New concepts</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#new-r-functionality">New R functionality</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Shannon Burns
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>