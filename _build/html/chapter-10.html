

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Chapter 10 - Quantifying Model Error &#8212; Pomona Psych 158 Online Textbook</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapter-10';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Pomona College Psych 158 Online Textbook
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Unit 1 Describing Data</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-1.ipynb">Chapter 1 - Intro to Doing Statistics</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-2.ipynb">Chapter 2 - Statistical Reasoning</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-3.ipynb">Chapter 3 - What are Data</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-4.ipynb">Chapter 4 - Organizing Data</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-5.ipynb">Chapter 5 - Describing Data</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-6.ipynb">Chapter 6 - Variation in Multiple Variables</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-7.ipynb">Chapter 7 - Principles of Data Visualization</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Unit 2 - Modeling Data</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-8.ipynb">Chapter 8 - Where Data Come From</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-9.ipynb">Chapter 9 - Modeling the Data Generation Process</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-10.ipynb">Chapter 10 - Quantifying Model Error</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-11.ipynb">Chapter 11 - Adding an Explanatory Variable</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-12.ipynb">Chapter 12 - Quantitative Predictor Models</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-13.ipynb">Chapter 13 - Multivariable Models</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-14.ipynb">Chapter 14 - Nonlinear Models</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-15.ipynb">Chapter 15 - Models with Categorical Outcomes</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Unit 3 - Evaluating Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-16.ipynb">Chapter 16 - Estimating Populations</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-17.ipynb">Chapter 17 - Significance Testing</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-18.ipynb">Chapter 18 - Significance Testing Whole Models</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-19.ipynb">Chapter 19 - Effect Sizes &amp; Power</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-20.ipynb">Chapter 20 - Alternate Approaches - Traditional Inference Methods</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-21.ipynb">Chapter 21 - Alternate Approaches - Bayesian Statistics</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-22.ipynb">Chapter 22 - Bias due to Improper Model Building</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-23.ipynb">Chapter 23 - Bias due to Improper Model Selection</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/smburns47/Psyc158/main?urlpath=tree/chapter-10.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onBinder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="initThebeSBT()"
  class="btn btn-sm btn-launch-thebe dropdown-item"
  title="Launch Thebe"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="btn__text-container">Live Code</span>
</button>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/smburns47/Psyc158" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/smburns47/Psyc158/issues/new?title=Issue%20on%20page%20%2Fchapter-10.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/chapter-10.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Chapter 10 - Quantifying Model Error</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#error-in-a-model">10.1 Error in a model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#error-distributions">10.2 Error distributions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#central-tendency-of-error">10.3 Central tendency of error</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#spread-of-error">10.4 Spread of error</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sum-of-squares">Sum of squares</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mean-squared-error">Mean squared error</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#root-mean-squared-error">Root mean squared error</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#shape-of-the-error-distribution">10.5 Shape of the error distribution</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#estimates-vs-parameters-of-error">10.6 Estimates vs. parameters of error</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sources-of-error">10.7 Sources of error</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#z-scores">10.8 Z-Scores</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#chapter-summary">Chapter summary</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <p><a class="reference external" href="https://www.shannonmburns.com/Psyc158/intro.html">Back to Table of Contents</a></p>
<p><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-9.ipynb">Previous: Chapter 9 - Statistical Models</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># This chapter uses packages that takes a few minutes to download on Google Colab. </span>
<span class="c1"># Run this first so it&#39;s ready by the time you need it</span>
<span class="nf">install.packages</span><span class="p">(</span><span class="s">&quot;ggformula&quot;</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">ggformula</span><span class="p">)</span>

<span class="n">studentdata</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">read.csv</span><span class="p">(</span><span class="s">&quot;https://raw.githubusercontent.com/smburns47/Psyc158/main/studentdata.csv&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section class="tex2jax_ignore mathjax_ignore" id="chapter-10-quantifying-model-error">
<h1>Chapter 10 - Quantifying Model Error<a class="headerlink" href="#chapter-10-quantifying-model-error" title="Permalink to this heading">#</a></h1>
<section id="error-in-a-model">
<h2>10.1 Error in a model<a class="headerlink" href="#error-in-a-model" title="Permalink to this heading">#</a></h2>
<p>Up to now we have developed the idea that a statistical model can be thought of as a number, a predicted value for the outcome variable. We are trying to model the data generation process, but because we can’t see the data generation process directly, we fit a model to our data and estimate parameters.</p>
<p>Sometimes we have a pretty good model - our predicted values closely match those in a sample of data taken from the population. But sometimes our model is pretty poor, and our predicted values are way off.</p>
<p>Using the DATA = MODEL + ERROR framework, we have defined error as the residual that is left after we account for the variance in our data that the model can explain. In the case of our simple model for a quantitative outcome variable, the model is the mean, and the error (or residual) is the deviation of each score above or below the mean.</p>
<p>We represent the simple model like this using the notation of the General Linear Model:</p>
<div class="math notranslate nohighlight">
\[ Y_i = b_0 + e_i \]</div>
<p>This equation represents each score in our data as the sum of two components: the mean of the distribution (represented by b<sub>0</sub>), and the deviation of that score above or below the mean (represented as e<sub>i</sub>). In other words, DATA = MODEL + ERROR.</p>
<p>In this chapter, we will dig deeper into the ERROR part of our DATA = MODEL + ERROR framework. In particular, we will develop methods for quantifying the total amount of error around a model. At the outset, it is worth remembering what the whole statistical enterprise is about: explaining variation. Once we have created a model, we can think about explaining variation in a new way, as reducing error around the model.</p>
<p>We have noted before that the mean is a better model of a quantitative outcome variable when the spread of the distribution is smaller than when it is larger. When the spread is smaller, the collection of residuals from the model are smaller. Quantifying the total error around a model will help us to know how good our models are, and which models are better than others.</p>
</section>
<section id="error-distributions">
<h2>10.2 Error distributions<a class="headerlink" href="#error-distributions" title="Permalink to this heading">#</a></h2>
<p>Let’s again consider the situation where we are modeling the length of people’s thumbs in the dataset <code class="docutils literal notranslate"><span class="pre">fingers</span></code> using the mean of that variable. First, generate an linear model using the <code class="docutils literal notranslate"><span class="pre">lm()</span></code> function, and then make a new variable to hold the residuals:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">thumb_model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w">   </span><span class="c1">#use lm() here with the variable &quot;Thumb&quot; in dataset &quot;fingers&quot;</span>
<span class="n">fingers</span><span class="o">$</span><span class="n">Thumb_residuals</span><span class="w"> </span><span class="o">&lt;-</span><span class="w">  </span><span class="c1">#use resid() here on the generated model</span>
<span class="nf">head</span><span class="p">(</span><span class="n">fingers</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The residuals of a model are the differences between what the model predicts for each person’s thumb length, and what their thumb length actually is: Y<sub>i</sub> - Y^<sub>i</sub>. We now have the residuals for each person stored in the variable <code class="docutils literal notranslate"><span class="pre">Thumb_residuals</span></code>. Much like it is useful to plot a histogram of a variable to begin to understand it, we can also plot a histogram of these residuals. This is called the <strong>error distribution</strong>. Describing the center, spread, and shape of the error distribution of a statistical model helps us evaluate how good the model is.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">gf_histogram</span><span class="p">(</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">Thumb_residuals</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fingers</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span>
<span class="w">  </span><span class="nf">gf_vline</span><span class="p">(</span><span class="n">.</span><span class="p">,</span><span class="w"> </span><span class="n">xintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">fingers</span><span class="o">$</span><span class="n">Thumb_residuals</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="central-tendency-of-error">
<h2>10.3 Central tendency of error<a class="headerlink" href="#central-tendency-of-error" title="Permalink to this heading">#</a></h2>
<p>The first thing to note about an error distribution is where it is centered. When we base a statistical model on the mean of an outcome variable, like <code class="docutils literal notranslate"><span class="pre">lm()</span></code> always does, the mean of the residuals is always centered on zero. This highlights why the mean is a great starting place for building a model. It turns out that no number other than the mean will perfectly balance the deviations above the mean with those below the mean. Every value gets taken into account when calculating the mean. The mean is pulled in both directions (larger and smaller) at once and settles right in the middle. The mean is the number that balances the amount of deviation above and below it, yielding the same amount of error above it as below it. As it turns out, in the absence of other information about the objects being studied, the mean of our sample is the best single estimate we have of what data from the population looks like. It is equally likely to be too high as it is too low, making it an <em>unbiased</em> estimator of the parameter.</p>
<p>Because it is our best guess of what the population parameter is, it is the best predictor we have of the value of a subsequent observation. While it will almost certainly be wrong, the mean will do a better job than any other individual number.</p>
<p>If we were to pick a different number than the mean to use as the model, our residuals would no longer center on zero and on average we would make worse predictions. Check it out below:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">not_the_mean</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">55</span>

<span class="n">fingers</span><span class="o">$</span><span class="n">Thumb_bad_residuals</span><span class="w"> </span><span class="o">&lt;-</span><span class="w">  </span><span class="n">fingers</span><span class="o">$</span><span class="n">Thumb</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">not_the_mean</span>
<span class="nf">gf_histogram</span><span class="p">(</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">Thumb_bad_residuals</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fingers</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span>
<span class="w">  </span><span class="nf">gf_vline</span><span class="p">(</span><span class="n">.</span><span class="p">,</span><span class="w"> </span><span class="n">xintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">fingers</span><span class="o">$</span><span class="n">Thumb_residuals</span><span class="p">))</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">  </span><span class="nf">gf_vline</span><span class="p">(</span><span class="n">.</span><span class="p">,</span><span class="w"> </span><span class="n">xintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">fingers</span><span class="o">$</span><span class="n">Thumb_bad_residuals</span><span class="p">),</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;red&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>This alternative error distribution has a red line to indicate the mean of the residuals. Since a residual means deviation between a prediction and a real value, we can see that using this bad model (e.g., an individual number below the mean) will result in fewer predictions that are too large. This is because we’re now always guessing 55 instead of 60. But this also means there are more predictions that are too small, and in general our predictions are off by a greater amount.</p>
</section>
<section id="spread-of-error">
<h2>10.4 Spread of error<a class="headerlink" href="#spread-of-error" title="Permalink to this heading">#</a></h2>
<p>We have noted before that the mean is a better model of a quantitative outcome variable when the spread of the distribution is smaller than when it is larger. When the spread of a variable is smaller, the spread of the residuals from the model are smaller. Quantifying the total error around a model involves describing this spread, and will help us to know how good our models are.</p>
<p>To make this concrete, look again at the distribution of error from using the mean as a model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">gf_histogram</span><span class="p">(</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">Thumb_residuals</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fingers</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span>
<span class="w">  </span><span class="nf">gf_vline</span><span class="p">(</span><span class="n">.</span><span class="p">,</span><span class="w"> </span><span class="n">xintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">fingers</span><span class="o">$</span><span class="n">Thumb_residuals</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>A worse model means predictions are farther away from the true data points. So if we want to quantify total error, would we just add up all the residuals? If worse models have more error, the sum of all the errors should represent the “total” error, right?</p>
<p>Let’s do that, using one of the first R functions you learned, <code class="docutils literal notranslate"><span class="pre">sum()</span></code>. The following code will add up all the residuals calculated by  <code class="docutils literal notranslate"><span class="pre">thumb_model</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">sum</span><span class="p">(</span><span class="n">fingers</span><span class="o">$</span><span class="n">Thumb_residuals</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The sum of all error in this model is actually 0 (or a number so tiny it’s practically zero and is just a rounding error in the computer).</p>
<p>Although we might at first think that the sum of the residuals would be a good indicator of total error, we’ve discovered a fatal flaw in that approach: the sum of the residuals around the mean is equal to 0! If this were our measure of total error, all data sets would be equally well modeled by the mean, because the residuals around the mean would always sum to 0. A data set widely spread out around the mean, and one tightly clustered around the mean, would have the same amount of error around this simple model. Clearly we need a different approach.</p>
<p>We can return back to the measures of spread in a distribution that we learned in chapter 5 and apply them to describing total error in a statistical model. Because several of those measures involve talking about spread as deviations away from the middle of a distribution, we can also use them to talk about deviations in a model based on the mean (i.e., spread in an error distribution).</p>
<section id="sum-of-squares">
<h3>Sum of squares<a class="headerlink" href="#sum-of-squares" title="Permalink to this heading">#</a></h3>
<p>First we’ll use a type of spread measure we didn’t directly work with yet - <strong>sum of squares</strong>. As we talked about in chapter 5, one way to get around the issue of positive and negative deviations adding up to zero is to square all those numbers first before adding them together. That’s all sum of squares is: the sum of all the squared residuals after fitting a model to data. Mathematically, this is written as:</p>
<div class="math notranslate nohighlight">
\[ SS = \sum_{i=1}^{N}(Y_i-\hat{Y}_i)^2\]</div>
<p>Where Y-hat<sub>i</sub> is the prediction our model makes for the value of Y<sub>i</sub>. In the case of an empty model, that’s just the mean of variable Y, or Y-bar. Since we already have the column <code class="docutils literal notranslate"><span class="pre">Thumb_residuals</span></code> in <code class="docutils literal notranslate"><span class="pre">fingers</span></code>, we can easily create a column of squared residuals. Adding those together will create the overall sum of squares for our model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">sum</span><span class="p">(</span><span class="n">fingers</span><span class="o">$</span><span class="n">Thumb_residuals</span><span class="o">**</span><span class="m">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>There may be some rounding errors going on again, but you can see the sum of squares (or SS for short) is about 1180.21, and not 0 this time. In addition, SS helps us distinguish better-fitting models from worse ones because it is a measure of total error that is minimized exactly at the mean. Since our goal in statistical modeling is to reduce error, this is a good thing. In any distribution of a quantitative variable, the mean is the point in the distribution at which SS is lowest.</p>
<div class="alert alert-block alert-info">
<b>Note</b>: It is worth pointing out that the advantage of SS is only there if our model is the mean. If we were to choose another number, such as the median, as our model of a distribution, we would probably choose a different measure of error. But our focus in this course is primarily on the mean.
</div>
<p>R also has a handy way of finding the sum of squares in a model automatically generated with <code class="docutils literal notranslate"><span class="pre">lm()</span></code>. Once we have a model object, we can use a function called <code class="docutils literal notranslate"><span class="pre">supernova()</span></code> from the <code class="docutils literal notranslate"><span class="pre">supernova</span></code> package to create an <strong>ANOVA table</strong> that allows us to look at the error from this model. ANOVA stands for ANalysis Of VAriance. Analysis means “to break down”, and later we will use this function to break down the variation into parts. But for now, we will use <code class="docutils literal notranslate"><span class="pre">supernova()</span></code> just to figure out how much error there is around the model, measured in sum of squares.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">install.packages</span><span class="p">(</span><span class="s">&quot;supernova&quot;</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">supernova</span><span class="p">)</span>

<span class="n">thumb_model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">Thumb</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="kc">NULL</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fingers</span><span class="p">)</span>

<span class="nf">supernova</span><span class="p">(</span><span class="n">thumb_model</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>There are a bunch of other things in this output that we will talk about in later chapters. For now, focus your attention on the row labeled “Total (empty model)” and the column labeled “SS”. This stands for the sum of squares around the empty model (e.g., sum of squared deviations from the mean). We see the same value (1180.21) that we previously calculated with the longer sequence of R commands in which we calculated the residuals, squared them, and then summed the squared residuals.</p>
</section>
<section id="mean-squared-error">
<h3>Mean squared error<a class="headerlink" href="#mean-squared-error" title="Permalink to this heading">#</a></h3>
<p>Sum of squares is a good measure of <em>total</em> variation if we are using the mean as a model. But, it does have one important disadvantage. To see it, compare these two distributions:</p>
<img src="images/ch10-ss.png" width="650">
<p>The one on top is clearly less spread out than the distribution on the bottom, so we would expect that if we used the mean to model that distribution, there’d be less error. However, because there are more data points in that distribution, there are just more error values to add up. The sum of squares becomes larger than that for the more spread out distribution.</p>
<p>This problem is solved by using mean squared error instead. For an empty model this is represented by the equation:</p>
<div class="math notranslate nohighlight">
\[ MSE = \frac{1}{N-1}\sum_{i=1}^{N}(Y_i-\hat{Y}_i)^2 \]</div>
<p>The equation above takes the total error (the sum of squares we just computed - can you find that quantity in the equation above?) but then divides by the sample size to end up with a measure of <em>average</em> error around the mean — the average of the squared deviations. Does this equation seem familiar? Let’s copy and paste the equation for variance from chapter 5 and see if you notice any similarities:</p>
<div class="math notranslate nohighlight">
\[ s^2 = \frac{1}{N-1}\sum_{i=1}^{N}(Y_i-\bar{Y})^2 \]</div>
<p>Almost exactly the same! The only difference is that variance calculates the mean square deviation of data points from the mean of a distribution (Y - Y-bar), and MSE calculates the mean square deviation between data points and what a statistical model predicts them to be (Y - Y-hat). In fact, in the case where our model is just the mean of variable Y, the MSE and variance of data on Y is exactly the same (since an empty model predicts every data point will equal the mean). However, when we get to more complex models, MSE will differ from variance on the outcome variable. Try to remember it instead as variance in the <em>residuals</em>.</p>
<p>Because it is an average, MSE is not impacted by sample size, and thus, can be used to compare the amount of error across two samples of different sizes.</p>
<div class="alert alert-block alert-info">
<b>Note</b>: Note that we're not actually dividing by the total sample size, but N - 1. As we mentioned in chapter 5, there are some complex reasons for this that we'll get to later in the course. 
</div>
<p>And how do we calculate MSE in R? You know this one already! We can use <code class="docutils literal notranslate"><span class="pre">var()</span></code> on the residuals variable.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">var</span><span class="p">(</span><span class="n">fingers</span><span class="o">$</span><span class="n">Thumb_residuals</span><span class="p">)</span>

<span class="c1">#same as dividing the sum of squares by N-1</span>
<span class="nf">sum</span><span class="p">(</span><span class="n">fingers</span><span class="o">$</span><span class="n">Thumb_residuals</span><span class="o">^</span><span class="m">2</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="nf">length</span><span class="p">(</span><span class="n">fingers</span><span class="o">$</span><span class="n">Thumb</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="m">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>You can also find MSE with <code class="docutils literal notranslate"><span class="pre">supernova()</span></code> whether or not your model is the mean. Use it now to recreate an ANOVA table for <code class="docutils literal notranslate"><span class="pre">thumb_model</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">supernova</span><span class="p">(</span><span class="c1">#YOUR CODE HERE)</span>
</pre></div>
</div>
</div>
</div>
<p>If your code worked okay, you should see a table with values on the “Total (empty model)” line corresponding to “SS”, “df”, and “MS”. We already know what “SS” is. Now, we can guess that “MS” stands for “mean squared”. And as expected, since our model is the mean, the number at that spot in the table matches what we calculated with <code class="docutils literal notranslate"><span class="pre">var()</span></code>. The number under <code class="docutils literal notranslate"><span class="pre">df</span></code>, 156, is the “N-1” component of the MSE equation. With this, we can verify that SS/df = MS.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="m">11880.211</span><span class="o">/</span><span class="m">156</span>

<span class="c1">#same as the variance in the residuals, just with rounding error </span>
<span class="nf">var</span><span class="p">(</span><span class="n">fingers</span><span class="o">$</span><span class="n">Thumb_residuals</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="root-mean-squared-error">
<h3>Root mean squared error<a class="headerlink" href="#root-mean-squared-error" title="Permalink to this heading">#</a></h3>
<p>The root mean squared error (abbreviated as RMSE) is simply the square root of the MSE. This is related in the same way that standard deviation is related to variance. We generally prefer thinking about model error in terms of root mean squared error because it yields a number that makes sense using the original scale of measurement. So, for example, if you were modeling weight in pounds, MSE would express the error in squared pounds (not something we are used to thinking about), whereas RMSE would express the error in pounds. RMSE is how big the residual is expected to be, on average, for any particular data point. This is written as:</p>
<div class="math notranslate nohighlight">
\[RMSE = \sqrt{\frac{1}{N-1}\sum_{i=1}^{N}(Y_i-\hat{Y}_i)^2}\]</div>
<p>Again, in the special case of the empty model where we predict every data point to be equal to the mean, RMSE is just the standard deviation of the variable we are making predictions about. In the general case, it is the standard deviation of the residuals.</p>
<p>See if you can find both the MSE component, and the sum of squares component in that equation. We take several mathematical steps to compute this, but if you can find the prior step in the equation, it’s not that hard to see how each measure of error relates to each other.</p>
<p>Of course to calculate standard deviation in R, we use <code class="docutils literal notranslate"><span class="pre">sd()</span></code> on <code class="docutils literal notranslate"><span class="pre">Thumb_residuals</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">sd</span><span class="p">(</span><span class="n">fingers</span><span class="o">$</span><span class="n">Thumb_residuals</span><span class="p">)</span>

<span class="c1">#same as taking the square root of variance</span>
<span class="nf">sqrt</span><span class="p">(</span><span class="nf">var</span><span class="p">(</span><span class="n">fingers</span><span class="o">$</span><span class="n">Thumb_residuals</span><span class="p">))</span>

<span class="c1">#same as dividing the sum of squares by N-1 and then taking the square root</span>
<span class="nf">sqrt</span><span class="p">(</span><span class="nf">sum</span><span class="p">(</span><span class="n">fingers</span><span class="o">$</span><span class="n">Thumb_residuals</span><span class="o">^</span><span class="m">2</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="nf">length</span><span class="p">(</span><span class="n">fingers</span><span class="o">$</span><span class="n">Thumb</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="m">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>There isn’t a spot for RMSE in the ANOVA table generated by <code class="docutils literal notranslate"><span class="pre">supernova()</span></code>, but it’s easy enough to calculate if we remember how it relates to mean squared error (“MS” in the ANOVA table print out).</p>
<p>We have discussed three ways of quantifying error around our model. All start with residuals, but they aggregate those residuals in different ways to summarize total error.</p>
<p>All of them are minimized at the mean, and so all are useful when the mean is the model for a quantitative variable. If you wanted to use a different single number as a model, like the median or mode, we’d have to use different measures of error (e.g., mean absolute error for median, instead of mean squared error).</p>
<p>To keep things simple in this class (well, simpl<em><strong>er</strong></em>), from here on out we’re going to stick to using the mean as a basic statistical model and its associated measures of error sum of squares, MSE, and RMSE. The majority of data analysis projects also rely on the mean. Don’t forget about median and mode! We just won’t build models with them in this course.</p>
</section>
</section>
<section id="shape-of-the-error-distribution">
<h2>10.5 Shape of the error distribution<a class="headerlink" href="#shape-of-the-error-distribution" title="Permalink to this heading">#</a></h2>
<p>The final thing to notice about the distribution of residuals is how it is shaped. Check out the shape below:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">gf_histogram</span><span class="p">(</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">Thumb_residuals</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fingers</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span>
<span class="w">  </span><span class="nf">gf_vline</span><span class="p">(</span><span class="n">.</span><span class="p">,</span><span class="w"> </span><span class="n">xintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">fingers</span><span class="o">$</span><span class="n">Thumb_residuals</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>How would you describe it in terms of modality and skew? Does it look roughly normal, or strongly distorted in any way?</p>
<p>Again, when talking about shapes of distributions, we always keep in mind the qualifier “roughly.” Even though this distribution is spikey, it roughly resembles a normal distribution. We’re not going to do anything with this information just yet (hang on until chapter 20). But in general, you can remember for now that the General Linear Model, the approach to building statistical models and making predictions about data that we are using in this class, works better when residuals are normally distributed. If they’re strongly not normal, that is cause for concern in evaluating what the model means and what you should do next.</p>
</section>
<section id="estimates-vs-parameters-of-error">
<h2>10.6 Estimates vs. parameters of error<a class="headerlink" href="#estimates-vs-parameters-of-error" title="Permalink to this heading">#</a></h2>
<p>Recall from last chapter our discussion of <em>estimates</em> (summaries computed from data samples) and <em>parameters</em> (summaries of the underlying population we are trying to guess at). We used Latin vs. Greek letters to separate our estimate of the mean, <em>M</em>, from the unknown population mean parameter, <em>μ</em>.</p>
<p>We’ve also now estimated error in a sample (general error <em>e</em>, or the special case of variance <em>s<sup>2</sup></em> and standard deviation <em>s</em>). It follows then, that there’s a true error out there that characterizes how all values in a population vary from <em>μ</em>. We don’t know this parameter, but we try to estimate it. The Greek letters for the error parameters are <em><strong>ε</strong></em> for general error (pronounced “epsilon”), <em><strong>σ<sup>2</sup></strong></em> for variance (pronounced “sigma squared”), and just <em><strong>σ</strong></em> for standard deviation (“sigma”). Here is a table of the estimates and parameters we’ve learned so far, to help keep them straight:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Concept</p></th>
<th class="head text-center"><p>Sample Estimate</p></th>
<th class="head text-center"><p>Population Parameter</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p>Mean</p></td>
<td class="text-center"><p><em>Y¯</em> (“Y-bar”)</p></td>
<td class="text-center"><p><em>μ</em> (“mu”)</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>Model error</p></td>
<td class="text-center"><p><em>e</em>  (“e”)</p></td>
<td class="text-center"><p><em>ε</em> (“epsilon”)</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>Variance</p></td>
<td class="text-center"><p><em>s<sup>2</sup></em> (“s squared”)</p></td>
<td class="text-center"><p><em>σ<sup>2</sup></em> (“sigma squared”)</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>Standard deviation</p></td>
<td class="text-center"><p><em>s</em> (“s”)</p></td>
<td class="text-center"><p><em>σ</em> (“sigma”)</p></td>
</tr>
</tbody>
</table>
</section>
<section id="sources-of-error">
<h2>10.7 Sources of error<a class="headerlink" href="#sources-of-error" title="Permalink to this heading">#</a></h2>
<p>This is a good time to think a little more about where variation in data even comes from. Why are our models making inaccurate predictions? We already have talked about the data generation process — the process that generates variation in the population from which we collected our sample of data. With our statistical models, we are trying to approximately describe that process. But using just the mean as a model is usually poor - the data generation process includes a lot of different components that, working together, produce the variation we see in an outcome variable. What are these sources of variation?</p>
<p>There are three important points we want to make about sources of variation. First, variation can be either explained or unexplained.</p>
<img src="images/ch10-var1.png" width="400">
<p>In the word equation we presented before, DATA = MODEL + ERROR, explained variation is the portion of the total variation in DATA we are able to explain with MODEL. Unexplained variation is everything included in the ERROR part of the equation. It’s useful to think of total variation as the sum of explained + unexplained variation.</p>
<p>Second, unexplained variation can be a real characteristic of the system we are studying, or it can be variation that is induced by our data collection procedures.</p>
<img src="images/ch10-var2.png" width="650">
<p>If the variation is real, that means we can probably figure out how to explain it if we measure the right explanatory variables; this variation could be thought of as not explained yet.</p>
<p>Variation induced by data collection comes in three buckets: measurement error (e.g., the small random variation that creeps into our measures); sampling error (i.e., the variation that occurs from sample to sample due to the fact that no individual sample is a perfect representation of the population); and measurement mistakes (e.g., that some students had measured their thumbs in centimeters instead of millimeters).</p>
<img src="images/ch10-var3.png" width="900">
<p>The third and final point we want to make is this: even though unexplained variation could be explained if we knew enough, statisticians tend to model unexplained variation, whether real or induced by data collection, as though it were generated by a random process. That’s why we expect the shape of the error distribution to be normal.</p>
</section>
<section id="z-scores">
<h2>10.8 Z-Scores<a class="headerlink" href="#z-scores" title="Permalink to this heading">#</a></h2>
<p>We have looked at the mean as a model, and we have learned some ways to quantify total error around the mean, as well as some good reasons for doing so. But there is another reason to look at both mean and error together. Sometimes, by putting the two ideas together it can give us a better way of understanding where a particular score falls in a distribution.</p>
<p>A student (let’s call her Zelda) has a thumb length of 64mm. Good for her, but what does this mean? Is that a particularly long thumb? How can we know? By now you may be getting the idea that just knowing the length of one thumb doesn’t tell you very much.</p>
<p>To interpret the meaning of a single score, it helps to know something about the distribution the score came from. Specifically, we need to know something about its shape, center and spread.</p>
<p>Let’s consider Zelda’s thumb length and the mean of <code class="docutils literal notranslate"><span class="pre">Thumb</span></code> in the full <code class="docutils literal notranslate"><span class="pre">fingers</span></code> dataset, 60.1. By comparing these two values, we know that Zelda’s thumb is about 3.9mm longer than the average. That helps us get a little closer to understanding what this one data point means. But because we have no idea about the spread of the distribution, we still don’t have a clear answer. Is a 3.9mm distance still pretty close to the mean, or is it far away? It’s hard to tell without knowing what the spread of thumb lengths looks like as well.</p>
<p>Error, and standard deviation in particular, is really useful for this. We know that Zelda’s thumb is about 3.9mm longer than the average thumb. But now we also know that, on average, thumbs are 8.7mm away from the mean, both above and below. Although Zelda’s thumb is above average in length, it is definitely not one of the longest thumbs in the distribution, or even that atypical - it is only 0.45 of a standard deviation away from the mean. Check out the histogram below to see this visualized (blue line is the distribution average, red line is Zelda’s thumb length).</p>
<img src="images/ch10-zeldathumb.png" width="600">
<p>Consider another example. Your friend tells you they just hit a new high score of 37,000 on a video game. Is that a big deal? Here are two possible distributions of high scores other people get on this game, with your friend’s score marked by the red line:</p>
<img src="images/ch10-videogame.png" width="700">
<p>Clearly your friend would be an outstanding player if distribution 1 were true. But if distribution 2 were true, they would be just slightly above average.</p>
<p>It’s more useful to say something about a particular data point if we can also communicate about the mean and standard deviation of a distribution. In order to make this easier, so that we don’t have to report several numbers at once, we can treat standard deviation as a new <em>unit</em> on which to measure our data. Let’s convert the value of <code class="docutils literal notranslate"><span class="pre">Thumb</span></code> to be a data points deviation from the mean, divided by the standard deviation:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">fingers</span><span class="o">$</span><span class="n">Thumb_scaled</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="p">(</span><span class="n">fingers</span><span class="o">$</span><span class="n">Thumb</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">fingers</span><span class="o">$</span><span class="n">Thumb</span><span class="p">))</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nf">sd</span><span class="p">(</span><span class="n">fingers</span><span class="o">$</span><span class="n">Thumb</span><span class="p">)</span>
<span class="n">fingers</span><span class="o">$</span><span class="n">Thumb</span><span class="p">[</span><span class="m">2</span><span class="p">]</span><span class="w"> </span><span class="c1"># value of Zelda&#39;s thumb length, in original units</span>
<span class="n">fingers</span><span class="o">$</span><span class="n">Thumb_scaled</span><span class="p">[</span><span class="m">2</span><span class="p">]</span><span class="w"> </span><span class="c1"># new value of Zelda&#39;s thumb length, in new units</span>
</pre></div>
</div>
</div>
</div>
<p>This new unit tells us how much of a standard deviation any score is from the mean. This can be positive (above the mean), or negative (below the mean), like this other person’s thumb:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">fingers</span><span class="o">$</span><span class="n">Thumb</span><span class="p">[</span><span class="m">3</span><span class="p">]</span><span class="w"> </span>
<span class="n">fingers</span><span class="o">$</span><span class="n">Thumb_scaled</span><span class="p">[</span><span class="m">3</span><span class="p">]</span><span class="w"> </span>
</pre></div>
</div>
</div>
</div>
<p>This unit is called the <strong>z-score</strong>. It is a transformation of a variable so that the middle point of a distribution equals 0, and a value of 1 means one standard deviation above the middle (while -1 is one standard deviation below the middle). To calculate it:</p>
<div class="math notranslate nohighlight">
\[ Z_i = \frac{(Y_i - \bar{Y})}{s} \]</div>
<p>where <em>s</em> is the standard deviation of Y. You can implement this equation in R (watch out for order of operations!), or you can also use the function <code class="docutils literal notranslate"><span class="pre">scale()</span></code>.</p>
<p>The “z” in “z-score” comes from the fact that the standard normal distribution (a normal distribution with a mean of zero and a standard deviation of 1) used to be called the “Z” distribution. So, what this transformation does is it actually morphs our data into being a sample from a normal distribution. It also forces the newly-transformed scores to exactly match what the residuals would be if we fit a linear model to the transformed scores:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">z_model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">Thumb_scaled</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="kc">NULL</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fingers</span><span class="p">)</span>
<span class="n">fingers</span><span class="o">$</span><span class="n">z_residuals</span><span class="w"> </span><span class="o">&lt;-</span><span class="w">  </span><span class="nf">resid</span><span class="p">(</span><span class="n">z_model</span><span class="p">)</span>
<span class="nf">head</span><span class="p">(</span><span class="n">fingers</span><span class="p">[,</span><span class="nf">c</span><span class="p">(</span><span class="s">&quot;Thumb_scaled&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;z_residuals&quot;</span><span class="p">)])</span>
</pre></div>
</div>
</div>
</div>
<p>This all means we can use the standard normal distribution to help us understand what specific z-scores tell us about where a data point sits with respect to the rest of the distribution.</p>
<img src="images/ch10-zscores.png" width="650">
<p>68% of all the data, no matter what scale it was in previously, is within 1 standard deviation of the mean (that’s how we define what a standard deviation is). Thus, once we convert to a z-score, 68% of z-scores are between -1 and 1. 95% of z-scores are between -2 and 2.</p>
<p>A score of 37,000 on a game doesn’t mean much to someone who doesn’t play that game. But this way it’s easy to understand a z-score of 0.2 (a little above average, not too strange) or 3 (way above average, very unusual).</p>
<p>This leads us to the second value of the z-score - we can compare scores from different distributions. Whether you’re measuring thumb length, game score, etc., you can always tell what a more typical vs. more exceptional value is based on its z-score. As we talk about statistical models more, you will see why the z-score is so useful.</p>
</section>
<section id="chapter-summary">
<h2>Chapter summary<a class="headerlink" href="#chapter-summary" title="Permalink to this heading">#</a></h2>
<p>After reading this chapter, you should be able to:</p>
<ul class="simple">
<li><p>Create a distribution of model errors</p></li>
<li><p>Explain what value this distribution will be centered on</p></li>
<li><p>Define and compare sum of squares, mean squared error, and root mean squared error</p></li>
<li><p>Calculate SS, MSE, and RMSE in a dataset</p></li>
<li><p>Explain the difference between estimates and parameters of error</p></li>
<li><p>Describe different sources of error in a model</p></li>
<li><p>Calculate the z-score of a variable</p></li>
</ul>
<p><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-11.ipynb">Next: Chapter 11 - Adding an Explanatory Variable</a></p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "smburns47/Psyc158",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "r"
        },
        kernelOptions: {
            name: "ir",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'ir'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#error-in-a-model">10.1 Error in a model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#error-distributions">10.2 Error distributions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#central-tendency-of-error">10.3 Central tendency of error</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#spread-of-error">10.4 Spread of error</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sum-of-squares">Sum of squares</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mean-squared-error">Mean squared error</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#root-mean-squared-error">Root mean squared error</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#shape-of-the-error-distribution">10.5 Shape of the error distribution</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#estimates-vs-parameters-of-error">10.6 Estimates vs. parameters of error</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sources-of-error">10.7 Sources of error</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#z-scores">10.8 Z-Scores</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#chapter-summary">Chapter summary</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Shannon Burns
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>