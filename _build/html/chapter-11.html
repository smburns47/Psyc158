

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Chapter 11 - Adding an Explanatory Variable &#8212; Pomona Psych 158 Online Textbook</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapter-11';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Pomona College Psych 158 Online Textbook
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Unit 1 Describing Data</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-1.ipynb">Chapter 1 - Intro to Doing Statistics</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-2.ipynb">Chapter 2 - Statistical Reasoning</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-3.ipynb">Chapter 3 - What are Data</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-4.ipynb">Chapter 4 - Organizing Data</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-5.ipynb">Chapter 5 - Describing Data</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-6.ipynb">Chapter 6 - Variation in Multiple Variables</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-7.ipynb">Chapter 7 - Principles of Data Visualization</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Unit 2 - Modeling Data</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-8.ipynb">Chapter 8 - Where Data Come From</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-9.ipynb">Chapter 9 - Modeling the Data Generation Process</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-10.ipynb">Chapter 10 - Quantifying Model Error</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-11.ipynb">Chapter 11 - Adding an Explanatory Variable</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-12.ipynb">Chapter 12 - Quantitative Predictor Models</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-13.ipynb">Chapter 13 - Multivariable Models</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-14.ipynb">Chapter 14 - Nonlinear Models</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-15.ipynb">Chapter 15 - Models with Categorical Outcomes</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Unit 3 - Evaluating Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-16.ipynb">Chapter 16 - Estimating Populations</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-17.ipynb">Chapter 17 - Significance Testing</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-18.ipynb">Chapter 18 - Significance Testing Whole Models</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-19.ipynb">Chapter 19 - Effect Sizes &amp; Power</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-20.ipynb">Chapter 20 - Alternate Approaches - Traditional Inference Methods</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-21.ipynb">Chapter 21 - Alternate Approaches - Bayesian Statistics</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-22.ipynb">Chapter 22 - Bias due to Improper Model Building</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-23.ipynb">Chapter 23 - Bias due to Improper Model Selection</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/smburns47/Psyc158/main?urlpath=tree/chapter-11.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onBinder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="initThebeSBT()"
  class="btn btn-sm btn-launch-thebe dropdown-item"
  title="Launch Thebe"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="btn__text-container">Live Code</span>
</button>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/smburns47/Psyc158" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/smburns47/Psyc158/issues/new?title=Issue%20on%20page%20%2Fchapter-11.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/chapter-11.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Chapter 11 - Adding an Explanatory Variable</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#explaining-variation">11.1 Explaining variation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#adding-an-explanatory-variable-to-the-model">11.2 Adding an explanatory variable to the model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#specifying-the-model-form">11.3 Specifying the model form</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fitting-the-one-variable-model">11.4 Fitting the one-variable model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generating-predictions-from-the-model">11.5 Generating predictions from the model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#quantifying-model-fit">11.6 Quantifying model fit</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#improvement-over-empty-model">11.8 Improvement over empty model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-historical-note-the-t-test">11.9 A historical note - the t-test</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#one-sample-t-test">One-sample t-test</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#independent-samples-t-test">Independent samples t-test</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#chapter-summary">Chapter summary</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <p><a class="reference external" href="https://www.shannonmburns.com/Psyc158/intro.html">Back to Table of Contents</a></p>
<p><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-10.ipynb">Previous: Chapter 10 - Quantifying Model Error</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Run this first so it&#39;s ready by the time you need it</span>
<span class="nf">install.packages</span><span class="p">(</span><span class="s">&quot;readr&quot;</span><span class="p">)</span>
<span class="nf">install.packages</span><span class="p">(</span><span class="s">&quot;supernova&quot;</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">readr</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">supernova</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section class="tex2jax_ignore mathjax_ignore" id="chapter-11-adding-an-explanatory-variable">
<h1>Chapter 11 - Adding an Explanatory Variable<a class="headerlink" href="#chapter-11-adding-an-explanatory-variable" title="Permalink to this heading">#</a></h1>
<p>As we discussed previously, in the absence of other information about the objects being studied, the mean of our sample is the best single-number estimate we have of the actual mean of the population. It is equally likely to be too high as it is too low for any one data point (the typical variation around the mean is the same on the left side as it is on the right). Because it is our best guess of what the population parameter is, it is the best predictor we have of the value of a subsequent observation. While it will almost certainly be wrong, the mean will do a better job than any other single number.</p>
<p>However, we don’t have to be limited to <em>just</em> a single number. In this chapter we’ll learn how to add more pieces to a statistical model to do a better job.</p>
<section id="explaining-variation">
<h2>11.1 Explaining variation<a class="headerlink" href="#explaining-variation" title="Permalink to this heading">#</a></h2>
<p>We started with the empty model in order to get some important ideas across, but certainly that’s not where we want to end up. It is time we start building models that include explanatory variables. We will still use the empty model, but only as a reference point.</p>
<p>Let’s quickly review what we mean by explaining variation. Earlier in the course, we developed an intuitive idea of explanation by comparing the distribution of one variable across two different groups. So, for example, we looked at the distribution of thumb length broken down by sex, which we can see in the two density histograms below.</p>
<img src="images/ch11-variation.png" width="650">
<p>You can clearly see that sex explains some of the variation in thumb length <em>in our data</em>. (This may not be true in the population, of course. It’s always possible that we are being fooled by a sample that doesn’t accurately represent what’s true in the population.) When we break up thumb length by sex it looks like two separate, though overlapping distributions. In general, males have longer thumbs than females in our data.</p>
<p>If we assume that this relationship (between sex and thumb length) exists in the population, and not just in our data, we can use it to help us make a better prediction about a future observation. If you know that someone is male, you would make a different prediction of their thumb length than if you knew they were female.</p>
<p>It seems, then, that if we were to use a statistical model to make predictions about a person’s thumb length, somehow incorporating information about their sex would be helpful - our predictions would be more accurate on average, and there would be less overall error in the model.</p>
</section>
<section id="adding-an-explanatory-variable-to-the-model">
<h2>11.2 Adding an explanatory variable to the model<a class="headerlink" href="#adding-an-explanatory-variable-to-the-model" title="Permalink to this heading">#</a></h2>
<p>In the previous chapters we introduced the idea of a statistical model as an equation that is meant to represent our best guess of the data generation process. This model generates a predicted score for each observation. We developed what we called the empty model, in which we use the mean as the predicted score for each observation.</p>
<p>We represented this model in General Linear Model (GLM) notation like this:</p>
<div class="math notranslate nohighlight">
\[ Y_i = b_0 + e_i \]</div>
<p>where b<sub>0</sub> represents the mean of the outcome variable in the sample. When we use the notation of the GLM, we must define the meaning of each symbol in context. Y<sub>i</sub>, for example, could mean lots of different things, depending on what our outcome variable is. But we will always use it to represent the outcome variable.</p>
<p>It is also important to remember that b<sub>0</sub> is just an estimate of the true mean in the population. To distinguish the true mean, which is unknown, from the estimate of the true mean we construct from our data, we use the Greek letter β<sub>0</sub> and write the empty model like this:</p>
<div class="math notranslate nohighlight">
\[ Y_i = \beta_0 + \epsilon_i \]</div>
<p>The empty model is called a one parameter model because we only need to estimate one parameter (β<sub>0</sub>) in order to generate a predicted score for each observation.</p>
<p>In the case of thumb length, this model states that the DATA (each data point, represented as Y<sub>i</sub>, which is each person’s measured thumb length), can be thought of as being generated by the combination of two inputs: the MODEL, represented as b<sub>0</sub> (which is the mean thumb length for everyone, usually called the Grand Mean); plus ERROR, which is each person’s residual from the model, represented by e<sub>i</sub>.</p>
<div class="alert alert-block alert-info">
<b>Note</b>: We use the term Grand Mean to refer to the mean of the entire sample in order to distinguish it clearly from other means, such as the mean for subgroups within the sample.
</div>
<p>It’s useful to illustrate the empty model (and what we’re about to do to it) with our <code class="docutils literal notranslate"><span class="pre">tiny_fingers</span></code> dataset. <code class="docutils literal notranslate"><span class="pre">tiny_fingers</span></code>, you will recall, contains six people’s thumb lengths randomly selected from our complete <code class="docutils literal notranslate"><span class="pre">fingers</span></code> dataset. This time, we’ll also include their value on the <code class="docutils literal notranslate"><span class="pre">Sex</span></code> variable as well.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">student_ID</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="m">4</span><span class="p">,</span><span class="w"> </span><span class="m">5</span><span class="p">,</span><span class="w"> </span><span class="m">6</span><span class="p">)</span>
<span class="n">Thumb</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">56</span><span class="p">,</span><span class="w"> </span><span class="m">60</span><span class="p">,</span><span class="w"> </span><span class="m">61</span><span class="p">,</span><span class="w"> </span><span class="m">63</span><span class="p">,</span><span class="w"> </span><span class="m">64</span><span class="p">,</span><span class="w"> </span><span class="m">68</span><span class="p">)</span>
<span class="n">Sex</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s">&quot;female&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;female&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;female&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;male&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;male&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;male&quot;</span><span class="p">)</span>

<span class="n">tiny_fingers</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span><span class="n">student_ID</span><span class="p">,</span><span class="w"> </span><span class="n">Thumb</span><span class="p">,</span><span class="w"> </span><span class="n">Sex</span><span class="p">)</span>
<span class="n">tiny_fingers</span>
</pre></div>
</div>
</div>
</div>
<p>We can put this data into a basic scatter plot with <code class="docutils literal notranslate"><span class="pre">Sex</span></code> on the x-axis and <code class="docutils literal notranslate"><span class="pre">Thumb</span></code> on the y-axis in order to visualize how <code class="docutils literal notranslate"><span class="pre">Sex</span></code> might explain <code class="docutils literal notranslate"><span class="pre">Thumb</span></code>.</p>
<img src="images/ch11-nullmodel.png" width="750">
<p>In the above plot, we drew a blue horizontal line in order to mark where the Grand Mean of the whole <code class="docutils literal notranslate"><span class="pre">tiny_fingers</span></code> dataset is. This is the same value as b<sub>0</sub> - in other words, this is what we would predict everyone’s thumb length to be if we were using the empty or null model. But there is plenty of error to this prediction - no data point is on this line, and we could calculate the RMSE to find out how large the residuals are in general.</p>
<p>So let’s try to take into account the effect of <code class="docutils literal notranslate"><span class="pre">Sex</span></code> and improve our prediction. One thing we could do is, instead of using the Grand Mean of <code class="docutils literal notranslate"><span class="pre">Thumb</span></code> to predict everyone’s thumb length, we could first consider whether or not the prediction we want to make is for a male or female. Then, we could use the mean of <em>just that group</em> in order to make our prediction.</p>
<img src="images/ch11-sexpredictor.png" width="750">
<p>A model that takes <code class="docutils literal notranslate"><span class="pre">Sex</span></code> into account generates a different prediction for a male than it does for a female. Error is still measured the same way, as the deviation of each person’s measured thumb length from their predicted thumb length. But this time, the error is calculated from each person’s group mean (male or female) instead of from the Grand Mean.</p>
</section>
<section id="specifying-the-model-form">
<h2>11.3 Specifying the model form<a class="headerlink" href="#specifying-the-model-form" title="Permalink to this heading">#</a></h2>
<p>Whereas the empty model was a one-parameter model (we only had to estimate one parameter, the Grand Mean), the <code class="docutils literal notranslate"><span class="pre">Sex</span></code>  model is a two-parameter model. One of the parameters helps us find the mean for males, the other helps us find the mean for females. By using the model as an equation for predicting the value of <code class="docutils literal notranslate"><span class="pre">Thumb</span></code>, we should be able to use one or the other mean depending on the value of <code class="docutils literal notranslate"><span class="pre">Sex</span></code>.</p>
<p>One way to do this is to use the mean of one group (say, females) as β<sub>0</sub>, and then add an extra amount to that value if someone is actually male. In other words, we could specify another parameter, β<sub>1</sub>, as the <em>difference</em> between male and female mean thumb lengths. But this should only be added if someone is male, so let’s multiply this parameter by 1 if <code class="docutils literal notranslate"><span class="pre">Sex</span></code> is “male”, and by 0 if <code class="docutils literal notranslate"><span class="pre">Sex</span></code> if “female” and we should ignore this addition.</p>
<p>Here is how to write this in GLM form:</p>
<div class="math notranslate nohighlight">
\[ Y_i = \beta_0 + \beta_1X_i + \epsilon_i \]</div>
<p>In this equation, β<sub>0</sub> is the group mean for “female” and β<sub>1</sub> is the difference between the group mean of male and female. X<sub>i</sub> is a variable, in this case <code class="docutils literal notranslate"><span class="pre">Sex</span></code> (which can take the value of either 0 for female or 1 for male).</p>
<p>Of course we’re making an estimate of the population and not measuring it directly, so the estimate form of this equation would be:</p>
<div class="math notranslate nohighlight">
\[ Y_i = b_0 + b_1X_i + e_i \]</div>
<p>We’re still using the DATA = MODEL + ERROR framework for this. Except this time, our MODEL takes into account the value of <code class="docutils literal notranslate"><span class="pre">Sex</span></code> and has multiple components (b<sub>0</sub> + b<sub>1</sub>X<sub>i</sub>) instead of one component (b<sub>0</sub>). b<sub>0</sub> also no longer stands for the Grand Mean of this sample, but the <em>group</em> mean of whatever group we assigned to be 0 in the Boolean variable <code class="docutils literal notranslate"><span class="pre">Sex</span></code>. To calculate our prediction of each person’s thumb, we’d fill in the parameters with the group mean of female (59) and the difference between the group means of male and female (65 - 59 = 6):</p>
<div class="math notranslate nohighlight">
\[ \hat{Y}_i = 59 + 6X_i \]</div>
<p>This equation would make one prediction (59) when the value of X<sub>i</sub> is 0 (female), and a different prediction (65) when the value of X<sub>i</sub> is 1 (male).</p>
</section>
<section id="fitting-the-one-variable-model">
<h2>11.4 Fitting the one-variable model<a class="headerlink" href="#fitting-the-one-variable-model" title="Permalink to this heading">#</a></h2>
<p>Now that you have learned how to specify a model with an explanatory variable (also frequently called a <em>predictor</em>), let’s learn how to fit the model using R.</p>
<p>Fitting a model, as a reminder, simply means automatically calculating the parameter estimates. We use the word “fitting” because we want to calculate the best estimate, the one that will result in the least amount of error and best “fit” our data. For the tiny data set, we could calculate the parameter estimates in our head — it’s just a matter of calculating the mean for males and the mean for females. But when the data set is larger, it is much easier to use R.</p>
<p>Using R, we will first fit the Sex model to the tiny dataset, just so you can see that R gives you the same parameter estimates you got before. After that we will fit it to the complete data set.</p>
<p>Here’s the model we are going to fit:</p>
<div class="math notranslate nohighlight">
\[ Y_i = b_0 + b_1X_i + e_i \]</div>
<p>Note that the parts that are going to have different values for each observation (X<sub>i</sub> and Y<sub>i</sub>) are called variables (because they vary)! e<sub>i</sub> also varies, but we typically reserve the label “variable” for outcome and explanatory variables. The parts that are going to have the same value for each observation (b<sub>0</sub> and b<sub>1</sub>) are called parameter estimates.</p>
<p>We do not need to estimate the variables. Each student in the dataset already has a score for the outcome variable (Y<sub>i</sub>) and the explanatory variable (X<sub>i</sub>), and these scores vary across students. Notice that the subscript <em>i</em> is attached to the parts that are different for each person.</p>
<p>We do need to estimate the parameters because, as discussed previously, they are features of the population, and thus are unknown. The parameter estimates we calculate are those that best fit our particular sample of data. But we would have probably gotten different estimates if we had a different sample. Thus, it is important to keep in mind that these estimates are only that, and they are undoubtedly a bit off. Calling them estimates keeps us humble!</p>
<p>Parameter estimates don’t vary from person to person, so they don’t carry the subscript <em>i</em>.</p>
<p>To fit the Sex model we use <code class="docutils literal notranslate"><span class="pre">lm()</span></code> again. This time, instead of the left side of the formula being <code class="docutils literal notranslate"><span class="pre">NULL</span></code>, we have a variable to put there. Thus, the formula argument of <code class="docutils literal notranslate"><span class="pre">lm()</span></code> is <code class="docutils literal notranslate"><span class="pre">Thumb</span> <span class="pre">~</span> <span class="pre">Sex</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">lm</span><span class="p">(</span><span class="n">Thumb</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">Sex</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tiny_fingers</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Notice that the estimates are exactly what you should have expected: the first estimate, for b<sub>0</sub>, is 59 (the mean for females); the second, b<sub>1</sub>, is 6, which is the number of millimeters you need to add to the female average thumb length to get average male thumb length.</p>
<p>Notice also that the estimate for b<sub>0</sub> is labeled “intercept” in the output. You have encountered the concept of intercept before, when you studied the concept of a line in algebra. Remember that <code class="docutils literal notranslate"><span class="pre">y</span> <span class="pre">=</span> <span class="pre">mx</span> <span class="pre">+</span> <span class="pre">b</span></code> is the equation for a line? <em>m</em> represents the slope of the line, and <em>b</em> represents the y-intercept. The General Linear Model notation is similar to this, though it includes error, whereas the equation for a line does not.</p>
<p>The reason the estimate for b<sub>0</sub> is called “Intercept” is because it is the estimate for thumb length when <em>X</em> is equal to 0. In other words, when sex is female. The estimate that R called “Sexmale,” by this line of reasoning, is kind of like the slope of a line. It is the increment in thumb length for a unit increase in <em>X</em>.</p>
<p>If you want — and it’s a good idea — you can save the results of this model fit in an R object. Here’s the code to save the model fit in an object called <code class="docutils literal notranslate"><span class="pre">tiny_sex_model</span></code>. Once you’ve saved the model, If you want to see what the model estimates are, you can just type the name of the model and you will get the same output as above.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">tiny_sex_model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">Thumb</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">Sex</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tiny_fingers</span><span class="p">)</span>

<span class="c1">#type the name of the saved model below to print out its output</span>
</pre></div>
</div>
</div>
</div>
<p>Now that we have estimates for the two parameters, we can put them in our model statement to yield: Y<sub>i</sub> = 59 = 6X<sub>i</sub>.</p>
<p>You may have noticed that the values of <code class="docutils literal notranslate"><span class="pre">Sex</span></code> in <code class="docutils literal notranslate"><span class="pre">tiny_fingers</span></code> are the categorical strings <code class="docutils literal notranslate"><span class="pre">female</span></code> or <code class="docutils literal notranslate"><span class="pre">male</span></code>, and not 1 or 0. We were able to run <code class="docutils literal notranslate"><span class="pre">lm()</span></code> anyway, so it seems like R is able to handle converting categorical data to Boolean data. But how does R know which level of <code class="docutils literal notranslate"><span class="pre">Sex</span></code> should be 0 and which should be 1? The answer to this question is, R doesn’t really know. If <code class="docutils literal notranslate"><span class="pre">Sex</span></code> is character data, it’s just taking whatever group comes first alphabetically (in this case,  <code class="docutils literal notranslate"><span class="pre">female</span></code>) and making it the <strong>reference group</strong>. If <code class="docutils literal notranslate"><span class="pre">Sex</span></code> is a factor variable, the reference group is whichever level of the variable was specified to be the first one (by appearing first in the vector passed to <code class="docutils literal notranslate"><span class="pre">levels</span> <span class="pre">=</span> </code> in the <code class="docutils literal notranslate"><span class="pre">factor()</span></code> function). The mean of the reference group is the first parameter estimate (b<sub>0</sub> or the Intercept in the <code class="docutils literal notranslate"><span class="pre">lm()</span></code> output). R then takes the second group (in this case, <code class="docutils literal notranslate"><span class="pre">male</span></code>) and represents it with b<sub>1</sub>.</p>
<p>Let’s say, just for fun, that you changed the code for <code class="docutils literal notranslate"><span class="pre">female</span></code> into <code class="docutils literal notranslate"><span class="pre">woman</span></code> in the data frame. Because <code class="docutils literal notranslate"><span class="pre">male</span></code> now comes first in the alphabet, <code class="docutils literal notranslate"><span class="pre">male</span></code> becomes the reference group, and its mean is now the estimate for the intercept (b<sub>0</sub>).</p>
<p>Converting it to a Boolean variable is also called making a <strong>dummy variable</strong> for the model prediction equation (this does not get saved to your data frame - it’s just a temporary computation R makes under the hood). You could supply a Sex variable as a Boolean of 0s and 1s already, but if not R will translate a categorical variable into a dummy variable do build the model with.</p>
<p>Now that you have looked in detail at the tiny set of data, find the best estimates for our bigger set of data (in the data frame called <code class="docutils literal notranslate"><span class="pre">fingers</span></code>) by modifying the code below. What would be b<sub>0</sub> and what would be b<sub>1</sub>?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">fingers</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">read_csv</span><span class="p">(</span><span class="s">&quot;https://raw.githubusercontent.com/smburns47/Psyc158/main/fingers.csv&quot;</span><span class="p">)</span>

<span class="c1"># store the model where Sex predicts Thumb</span>
<span class="n">sex_model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span>

<span class="c1"># this prints out the model estimates</span>
<span class="n">sex_model</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="generating-predictions-from-the-model">
<h2>11.5 Generating predictions from the model<a class="headerlink" href="#generating-predictions-from-the-model" title="Permalink to this heading">#</a></h2>
<p>Now that you have fit the Sex model, you can use your estimates to make predictions about future observations. Doing this requires you to use your model as an equation. In this case, you will put in a value (e.g., “female”) for your explanatory variable (<code class="docutils literal notranslate"><span class="pre">Sex</span></code>), and get out a predicted thumb length.</p>
<p>Recall that our model looks like this:</p>
<div class="math notranslate nohighlight">
\[ Y_i = b_0 + b_1X_i + e_i \]</div>
<p>Once fit, we can print out the coefficients of the model, and then replace b<sub>0</sub> with the Intercept value, and replace b<sub>1</sub> with the other coefficient. Then, in order to make a prediction about the value of <code class="docutils literal notranslate"><span class="pre">Thumb</span></code> for any one person, we remove the error term. If our goal is to model the variation, we want the error term there. But if our goal is to predict, we are going to ignore error and just do our best! We also change the Y<sub>i</sub> to Y^<sub>i</sub>, which indicates a predicted score for person <em>i</em>. Our prediction equation, then, looks like this:</p>
<div class="math notranslate nohighlight">
\[ \hat{Y}_i = 58.256 + 6.447*X_i\]</div>
<p>We leave out the error term because every person will have a different error term. If we knew their error, we could predict their score exactly. But since we don’t when making a new prediction, all we can do is predict their score based on their sex.</p>
<p>This prediction equation is straightforward to use. If we want to predict what the next observed thumb length will be, we can see that if the next student sampled is female, their predicted thumb length is 58.256. If they are male, the prediction is 58.256 + 6.447, or 64.703.</p>
<p>If you want to produce each coefficient by itself with code, you can also use commands below:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">sex_model</span><span class="o">$</span><span class="n">coefficients</span><span class="p">[[</span><span class="m">1</span><span class="p">]]</span><span class="w"> </span><span class="c1">#this will print out the first coefficient, b0</span>
<span class="n">sex_model</span><span class="o">$</span><span class="n">coefficients</span><span class="p">[[</span><span class="m">2</span><span class="p">]]</span><span class="w"> </span><span class="c1">#this will print out the second coefficient, b1</span>
</pre></div>
</div>
</div>
</div>
<p>You can use the <code class="docutils literal notranslate"><span class="pre">$</span></code> operator here even though <code class="docutils literal notranslate"><span class="pre">sex_model</span></code> isn’t a data frame because it works with multiple types of complex objects. In a data frame, it accesses a column by name. In a model object, it accesses outputs of the model by name. The <code class="docutils literal notranslate"><span class="pre">coefficients</span></code> output comes to us a special kind of vector called a <em>named vector</em>, meaning each item in it is paired with a name. This set of coefficients has two items in it, so you can use indexing like <code class="docutils literal notranslate"><span class="pre">[1]</span></code> or <code class="docutils literal notranslate"><span class="pre">[2]</span></code> to access the first or the second coefficient. If you want to strip away the names and get just the number, use double brackets like <code class="docutils literal notranslate"><span class="pre">[[1]]</span></code>.</p>
<p>As we did in chapter 9, we also will want to generate model predictions for our sample data. It seems odd to predict values when we already know the actual values. But it’s actually very useful to do so, because then we can calculate residuals from the model predictions.</p>
<p>To get predicted values from the <code class="docutils literal notranslate"><span class="pre">sex_model</span></code>, we use the <code class="docutils literal notranslate"><span class="pre">predict()</span></code> function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">predict</span><span class="p">(</span><span class="n">sex_model</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>This is a big output, but the results are just what we’ve already done - for each observation, their predicted thumb length is the mean of female students if their value on <code class="docutils literal notranslate"><span class="pre">Sex</span></code> is <code class="docutils literal notranslate"><span class="pre">female</span></code> (58.256), or will be the mean of male students if their value on <code class="docutils literal notranslate"><span class="pre">Sex</span></code> is <code class="docutils literal notranslate"><span class="pre">male</span></code> (64.703).</p>
<p>Let’s say you want to save these predicted values for each person as a variable called <code class="docutils literal notranslate"><span class="pre">Sex_predicted</span></code> (in the <code class="docutils literal notranslate"><span class="pre">fingers</span></code> data frame). See if you can complete the R code to do this.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">fingers</span><span class="o">$</span><span class="n">Sex_predicted</span><span class="w"> </span><span class="o">&lt;-</span>

<span class="c1"># this prints the first few lines of the fingers data frame, to check if your variable saved successfully</span>
<span class="nf">head</span><span class="p">(</span><span class="n">fingers</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="quantifying-model-fit">
<h2>11.6 Quantifying model fit<a class="headerlink" href="#quantifying-model-fit" title="Permalink to this heading">#</a></h2>
<p>Why should we take <code class="docutils literal notranslate"><span class="pre">Sex</span></code> into account in the first place? Using two parameters in our model instead of one makes it more complex, or less <strong>parsimonious</strong>. We’ll talk more later about the importance of parsimony, but for now we should just know that it’s harder to work with a more complex model than a simpler one. Thus, there should be a good reason for making it more complex - it should reduce the error in our model predictions.</p>
<p>Let’s try it out. We’ll add columns of predictions to <code class="docutils literal notranslate"><span class="pre">tiny_fingers</span></code>, calculate the residuals, and then calculate the RMSE.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">tiny_fingers</span><span class="o">$</span><span class="n">GrandMean</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">62</span><span class="p">,</span><span class="w"> </span><span class="m">62</span><span class="p">,</span><span class="w"> </span><span class="m">62</span><span class="p">,</span><span class="w"> </span><span class="m">62</span><span class="p">,</span><span class="w"> </span><span class="m">62</span><span class="p">,</span><span class="w"> </span><span class="m">62</span><span class="p">)</span><span class="w"> </span><span class="c1">#predictions using grand mean</span>
<span class="n">tiny_fingers</span><span class="o">$</span><span class="n">GroupMeans</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">59</span><span class="p">,</span><span class="w"> </span><span class="m">59</span><span class="p">,</span><span class="w"> </span><span class="m">59</span><span class="p">,</span><span class="w"> </span><span class="m">65</span><span class="p">,</span><span class="w"> </span><span class="m">65</span><span class="p">,</span><span class="w"> </span><span class="m">65</span><span class="p">)</span><span class="w"> </span><span class="c1">#predictions using group means</span>
<span class="n">tiny_fingers</span><span class="o">$</span><span class="n">GrandResid</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">tiny_fingers</span><span class="o">$</span><span class="n">Thumb</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">tiny_fingers</span><span class="o">$</span><span class="n">GrandMean</span><span class="w"> </span><span class="c1">#grand mean prediction residuals</span>
<span class="n">tiny_fingers</span><span class="o">$</span><span class="n">GroupResid</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">tiny_fingers</span><span class="o">$</span><span class="n">Thumb</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">tiny_fingers</span><span class="o">$</span><span class="n">GroupMeans</span><span class="w"> </span><span class="c1">#group mean prediction residuals</span>

<span class="w"> </span><span class="c1">#equation for RMSE in one-parameter case </span>
<span class="nf">sqrt</span><span class="p">(</span><span class="nf">sum</span><span class="p">(</span><span class="n">tiny_fingers</span><span class="o">$</span><span class="n">GrandResid</span><span class="o">^</span><span class="m">2</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="nf">length</span><span class="p">(</span><span class="n">tiny_fingers</span><span class="o">$</span><span class="n">GrandResid</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="m">1</span><span class="p">))</span>
<span class="w"> </span><span class="c1">#equation for RMSE in two-parameter case </span>
<span class="nf">sqrt</span><span class="p">(</span><span class="nf">sum</span><span class="p">(</span><span class="n">tiny_fingers</span><span class="o">$</span><span class="n">GroupResid</span><span class="o">^</span><span class="m">2</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="nf">length</span><span class="p">(</span><span class="n">tiny_fingers</span><span class="o">$</span><span class="n">GroupResid</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="m">2</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Success! If we make predictions about people’s thumb lengths using the Grand Mean, on average we’re about 4.05mm off. But if we take into account each person’s sex for making the prediction, we’re only about 2.65mm off. Not perfect, but we almost halved our error!</p>
<p>You may have noticed that, in order to calculate RMSE for the empty and one-variable models above, we used slightly different equations. Specifically, in the null model it was calculated as:</p>
<div class="math notranslate nohighlight">
\[RMSE_{null} = \sqrt{\frac{1}{N-1}\sum_{i=1}^{N}(Y_i-\hat{Y}_{i-empty})^2}\]</div>
<p>and in the one-variable model it was calculated as:</p>
<div class="math notranslate nohighlight">
\[RMSE_{sex} = \sqrt{\frac{1}{N-2}\sum_{i=1}^{N}(Y_i-\hat{Y}_{i-sex})^2}\]</div>
<p>The difference is that we divided the sum of squares in the null model by N - 1, and in the one-variable model we divided by N - 2. We’ve already talked about how, if this measure should be the root <em>mean</em> squared error, it’s weird that we’re not actually <em>calculating the mean of the error</em> (which would be found by dividing by N only). Now, we can learn more about why that is.</p>
<p>If we were to only divide by N, that would actually be fine for finding the RMSE <em>of this specific sample</em>. It would be the root of the mean squared error, exactly as it sounds. However, remember again that our ultimate goal is not to make a model <em>for this sample</em>, but to <em>estimate the data generation process for the whole population</em>. As it turns out, if we divide by only N for finding the RMSE of a sample, we will systematically underestimate how much error our model would have in the population. We’ll demonstrate this in more detail in a later chapter.</p>
<p>In order for us to correct for this underestimation, we need to divide by a slightly smaller number than N: N - 1 in the empty model, or N - 2 in the one-variable model. This replacement term is called the <strong>degrees of freedom</strong> in the model.</p>
<p>What are degrees of freedom? In essense, they are the number of unique pieces of information in a dataset, or the number of ways the dataset can vary. You might think that, if a dataset has 6 items (N=6), then there should be 6 unique pieces of information there, right? Each observation can vary in its own way? That would be true, until you bring a parameter estimate of that data into play. Once we have an estimate about the dataset as a whole (say, the mean as b<sub>0</sub> in the empty model), that actually takes away one way the dataset can vary - it takes away one degree of freedom.</p>
<p>Let’s demonstrate this with our tiny dataset. We have a set of thumb lengths, [56, 60, 61, 63, 64, 68]. If we were missing one (our set looked like [56, 60, 61, 63, 64, ?]), we wouldn’t have any way of knowing what that sixth item should be - it is free to vary. But if we have the 5 known items, <em>and</em> we have an estimate of the mean of the sample (grand mean = 62), the missing 6th item can <em>only</em> be 68 in order to keep that grand mean estimate at 62. It is not free to vary. Thus, when we have an estimate of the mean of a sample, the degrees of freedom are N - 1. We only need to know 5 of the items in the sample in order to know the whole sample.</p>
<p>When we extend to the one-variable model, we have two parameter estimates - b<sub>0</sub> and b<sub>1</sub>. We could be missing one value from each sex subgroup (2 datapoints total), and still solve for all the values in the dataset since we have each group mean. Thus, the degrees of freedom for a one-variable model is N - 2. To generalize this, the degrees of freedom of any model is <em>sample size - number of parameters</em>, or <em>N - k</em> for short.</p>
<p>When calculating error in a model, dividing by degrees instead of sample size keeps us from underestimating the error in the population.</p>
<p>You can also use <code class="docutils literal notranslate"><span class="pre">supernova()</span></code> to get an ANOVA table for models with a predictor variable, not just empty models. This way we can find RMSE without a big long line of code and math. We loaded this library already, so write some code below that will run the function on the model object the same way we did last chapter.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># ANOVA table of an empty model</span>
<span class="n">empty_model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">Thumb</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="kc">NULL</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fingers</span><span class="p">)</span>
<span class="nf">supernova</span><span class="p">(</span><span class="n">empty_model</span><span class="p">)</span>

<span class="c1"># write code to use supernova() on the sex_model object instead</span>
</pre></div>
</div>
</div>
</div>
<p>How do the two ANOVA tables compare? It looks like the table for <code class="docutils literal notranslate"><span class="pre">sex_model</span></code> has the same information from the empty model, but with a lot of new numbers added also. Let’s break this down.</p>
<p>As you will recall from last chapter, the sum of squares (SS in the table) is the sum of squared residuals from our model. We will refer to it as SS<sub>total</sub> to diferentiate it from the values on other lines. In both tables, this appears on the line “Total (empty model)” in order to give you a comparison for how much the sum of squares is when just using the Grand Mean to make predictions.</p>
<p>df on the same line stands for degrees of freedom, which you now know the meaning of - there are 157 people in the sample with valid thumb measurements, and we’re estimating one parameter in the empty model, so degrees of freedom are 157 - 1 = 156.</p>
<p>Mean squared error (MS) on the same line is the sum of squares divided by the degrees of freedom. To get root mean squared error (RMSE), we’d take the square root of this value.</p>
<p>Now, for the new lines of numbers. The line “Error (from model)” was filled out because we now have a model that is not empty - there’s an explanatory variable in it. SS, df, and MS mean the same thing for this model as they did in the empty model: they reflect the amount of error that is unexplained by the model, and how many degrees of freedom are left after estimating the model parameters (157 observations - 2 parameters = 155 df). This SS value is known as SS<sub>error</sub>. We calculate SS<sub>error</sub> in much the same way we calculate SS<sub>total</sub>, except this time we use residuals from the Sex model predictions instead of from the empty model.</p>
<p>The key thing to look for is whether or not error in the one-variable model is less than in the empty model. If so, that means it was valuable to add our variable! It helped explain extra variance in the outcome variable, enabling us to make better predictions and produce smaller residuals. This difference between the empty model and the full model is on the top line. SS<sub>model</sub> refers to how much of the error from the empty model was accounted for by adding a variable in the full model. To calculate SS<sub>model</sub>, we simply need to subtract SS<sub>error</sub> (error from the Sex model predictions) from SS<sub>total</sub> (error around the mean, or the empty model). Thus:</p>
<div class="math notranslate nohighlight">
\[ SS_{model} = SS_{total} - SS_{error} \]</div>
</section>
<section id="improvement-over-empty-model">
<h2>11.8 Improvement over empty model<a class="headerlink" href="#improvement-over-empty-model" title="Permalink to this heading">#</a></h2>
<p>Statistical modeling is all about explaining variation. SS<sub>total</sub> tells us how much total variation there is to be explained in an outcome variable. When we fit a model (as we have done with the Sex model), that model explains some of the total variation, and leaves some of that variation still unexplained.</p>
<p>These relationships are visualized in the diagram below: Total SS can be seen as the sum of the Model SS (the amount of variation explained by a more complex model) and SS Error, which is the amount left unexplained after fitting the model. Just as DATA = MODEL + ERROR, SS Total = SS Model + SS Error.</p>
<img src="images/ch11-explainedvar.png" width="750">
<p>We can see this in the ANOVA table: the two rows associated with the Sex model (Model and Error) add up to the Total SS (the empty model). So, 1334.203 + 10546.008 = 11880.211.</p>
<p>We have now quantified how much variation from SS<sub>total</sub> has been explained by, or “soaked up” our model: SS<sub>model</sub>, or in our specific case with <code class="docutils literal notranslate"><span class="pre">Sex</span></code> predicting <code class="docutils literal notranslate"><span class="pre">Thumb</span></code> in <code class="docutils literal notranslate"><span class="pre">fingers</span></code>, 1334.203 square millimeters. Is that good? Is that a lot of explained variation? It would be easier to understand if we knew the proportion of total error that has been reduced rather than the raw amount of error reduced measured in mm<sup>2</sup>.</p>
<p>If you take another look back at the ANOVA table produced above, you will see another column labelled PRE. PRE stands for <strong>Proportional Reduction in Error.</strong></p>
<p>PRE is calculated using the sums of squares. It is simply SS<sub>model</sub> (i.e., the sum of squares reduced by the model) divided by SS<sub>total</sub> (the total sum of squares in the outcome variable under the empty model). We can represent this in a formula:</p>
<div class="math notranslate nohighlight">
\[ PRE = \frac{SS_{model}}{SS_{total}} \]</div>
<p>Based on this formula, PRE can be interpreted as the proportion of total variation in the outcome variable that is explained by the explanatory variable. It tells us something about the overall strength of our statistical model. Because PRE in the ANOVA table is 0.1123, that means <code class="docutils literal notranslate"><span class="pre">Sex</span></code> explained 11.23% of the variance in <code class="docutils literal notranslate"><span class="pre">Thumb</span></code>. Most of the original variance is still there (we didn’t explain it perfectly), but we made a reduction in error.</p>
<p>It is important to remember that SS<sub>model</sub> in the numerator of the formula above represents the <em>reduction</em> in error when going from the empty model to the more complex model, which includes an explanatory variable. To make this clearer we can re-write the above formula like this:</p>
<div class="math notranslate nohighlight">
\[ PRE = \frac{SS_{total} - SS_{error}}{SS_{total}} \]</div>
<p>The numerator of this formula starts with the error from the empty model (SS<sub>total</sub>), and then subtracts the error from the full model (SS<sub>error</sub>) to get the error reduced by the full model (SS<sub>model</sub>). Dividing this reduction in error by the SS<sub>total</sub> yields the proportion of total error in the empty model that has been reduced by the complex model.</p>
<p>Although right now we’re using PRE to compare a model with one predictor to the empty model, the comparison doesn’t need to be to the empty model. In fact, PRE can be used to compare any two models of an outcome variable as long as one is simpler than the other.</p>
<div class="alert alert-block alert-info">
<b>Note</b>: We're calling the comparison of a more complex model to the empty model PRE since that's what supernova() calls it, but it goes by other names as well. In more traditional statistics it is referred to as &eta;<sup>2</sup>, or eta squared. In a later chapter we will introduce the same concept in the context of regression, where it is called R<sup>2</sup>. For now all you need to know is: these are different terms used to refer to the same thing - reduction of error by a more complex model.
</div>  
<p>What would be the case where a more complex model doesn’t reduce error? This is worth thinking about, because it’s exactly what differentiates the one-variable model from the empty model. Let’s compare the two:</p>
<p>One-variable model: Y<sub>i</sub> = b<sub>0</sub> + b<sub>1</sub>X<sub>i</sub> + e<sub>i</sub></p>
<p>Empty model: Y<sub>i</sub> = b<sub>0</sub> + e<sub>i</sub></p>
<p>In the one variable model, if b<sub>1</sub> = 0, then b<sub>1</sub>X<sub>i</sub> effectively drops out of the equation - it has no effect since any value of X multiplied by 0 is just 0. Since b<sub>1</sub> refers to the difference in group means, this would be the case where the means of female and male thumbs lengths are the same. In other words, Sex does NOT explain Thumb. In the ANOVA table, this would look like SS<sub>model</sub> of 0 (or close to it) - there is effectively no difference in the error between the empty model and the full model. In practice, SS<sub>model</sub> is almost never 0. Adding an explanatory variable almost always explains some amount of variance. In a later chapter we will explore the question of how <em>much</em> error reduction is enough for us to care about.</p>
</section>
<section id="a-historical-note-the-t-test">
<h2>11.9 A historical note - the t-test<a class="headerlink" href="#a-historical-note-the-t-test" title="Permalink to this heading">#</a></h2>
<p>In this course we are relying on the general linear model framework to build our understanding of the data generation process. The main logic of the general linear model is that we can create a (most likely simplified) statistical model that is an estimate of the true data generation process, and see whether predictions using that model are more accurate than predictions made using a null model.</p>
<p>This is not the only approach to statistics, however. Indeed until recently, it was not the most common. The traditional approach to statistics was to develop a separate tool for each kind of dataset. In addition, the goal wasn’t about improving accuracy of data predictions, but describing the distinguishability of data from different groups. In this course it is your professor’s opinion that this is not the best way to teach statistics, since it relies on more complex understanding of data from the get-go, and using separate tests makes it harder to remember the logic of all of them. But because so many researchers learned statistics with these tools, they are often still found in research publications. This it would be good for you to at least know what they are, and what version of the general linear model they map onto.</p>
<section id="one-sample-t-test">
<h3>One-sample t-test<a class="headerlink" href="#one-sample-t-test" title="Permalink to this heading">#</a></h3>
<p>The one-sample t-test is a tool to evaluate whether the mean of one sample is <em>significantly different</em> than a particular number. We have not covered the logic of <em>statistical significance</em> yet - we will get to it later in the course. But a quick understanding of it right now for the purpose of the t-test is that this tool is asking whether a distribution of data in a sample was likely generated by a particular value as the data generation process, or whether it likely came from a different data generation process.</p>
<p>A T-test outputs a coefficient, known as a <em>t-value</em>. This coefficient can be calculated as:</p>
<div class="math notranslate nohighlight">
\[ t_{one} = \frac{\bar{X} - \mu}{\frac{s}{\sqrt{n}}} \]</div>
<p>Where X-bar is the mean of our data sample, <em>μ</em> is some number value, <em>s</em> is the standard deviation of the sample, and n is the sample size. <em>μ</em> is a <em>hypothesized population mean</em>, hence why it is written with the Greek letter <em>μ</em>. Typically, this is specifically a <em>null hypothesis</em> - that <em>μ</em> equals 0. The t-test thus measures how far away the mean of our sample is from 0, and whether that’s exceptional or not considering the spread of the distribution. The bigger the t-value, the more certain we are that a population with mean 0 did not create our sample, and some other process did.</p>
<p>A t-value isn’t the same thing as any value in our general linear model, but you can use b<sub>0</sub> of the null model for a similar purpose. In the general linear model, we could ask whether b<sub>0</sub> being the mean of our sample makes better predictions than b<sub>0</sub> being 0. Thus if you encounter one-sample t-tests in the wild, just think of using the null form of the general linear model for the same purpose.</p>
</section>
<section id="independent-samples-t-test">
<h3>Independent samples t-test<a class="headerlink" href="#independent-samples-t-test" title="Permalink to this heading">#</a></h3>
<p>A related type of t-test compares the means of two samples to each other to ask whether we think the same underlying population created them, or not. The computation for an independent-sample t-value is:</p>
<div class="math notranslate nohighlight">
\[ t_{independent} = \frac{\bar{X}_1 - \bar{X}_2}{s_p\sqrt{\frac{1}{n_1} + \frac{1}{n_2}}} \]</div>
<p>where s<sub>p</sub> stands for the <em>pooled</em> standard deviation, a way of combining the standard deviations of two samples:</p>
<div class="math notranslate nohighlight">
\[s_p = \sqrt{\frac{(n_1 - 1)s^2_1 + (n_2 - 1)s^2_2}{n_1 + n_2 + 2}} \]</div>
<p>The independent samples t-test asks whether two samples are probably different from each other. These two samples are usually split based on an explanatory variable - e.g., the thumb lengths of females in our study would be one sample, and the thumb lengths of males would be another one. Once separated conceptually, those distributions are compared to each other.</p>
<p>In the general linear model, we can achieve a similar goal by looking at the value of b<sub>1</sub> in a two-parameter model. If it is large, that means there is a large difference between female and male group means - we’d make substantially different predictions for someone who is female compared to someone who is male. If b<sub>1</sub> is small, there is not much difference between the two groups (and perhaps the small difference is only there by random chance).</p>
<p>In this course you will not need to remember how to calculate t-values, but you will need to remember what the comparable general linear model approach is for each type of t-value you see in the wild.</p>
</section>
</section>
<section id="chapter-summary">
<h2>Chapter summary<a class="headerlink" href="#chapter-summary" title="Permalink to this heading">#</a></h2>
<p>After reading this chapter, you should be able to:</p>
<ul class="simple">
<li><p>Understand the difference between an empty model and a one-variable model</p></li>
<li><p>Explain what b<sub>0</sub> and b<sub>1</sub> mean in a one-variable model</p></li>
<li><p>Write the equation form of the one-variable statistical equation</p></li>
<li><p>Fit a one-variable model in R with lm()</p></li>
<li><p>Explain what degrees of freedom are</p></li>
<li><p>Identify the various error components in an ANOVA table of the one-variable model</p></li>
<li><p>Define what proportional reduction in error means</p></li>
<li><p>Calculate proportional reduction in error from SS</p></li>
<li><p>Know what general linear model specification maps onto one-sample and independent t-tests</p></li>
</ul>
<p><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-12.ipynb">Next: Chapter 12 - Quantitative Predictor Models</a></p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "smburns47/Psyc158",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "r"
        },
        kernelOptions: {
            name: "ir",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'ir'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#explaining-variation">11.1 Explaining variation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#adding-an-explanatory-variable-to-the-model">11.2 Adding an explanatory variable to the model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#specifying-the-model-form">11.3 Specifying the model form</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fitting-the-one-variable-model">11.4 Fitting the one-variable model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generating-predictions-from-the-model">11.5 Generating predictions from the model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#quantifying-model-fit">11.6 Quantifying model fit</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#improvement-over-empty-model">11.8 Improvement over empty model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-historical-note-the-t-test">11.9 A historical note - the t-test</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#one-sample-t-test">One-sample t-test</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#independent-samples-t-test">Independent samples t-test</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#chapter-summary">Chapter summary</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Shannon Burns
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>