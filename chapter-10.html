

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Chapter 10 - Quantifying Model Error &#8212; Pomona Psych 158 Online Textbook</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapter-10';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Pomona College Psych 158 Online Textbook
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Unit 1 Describing Data</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-1.ipynb">Chapter 1 - Introduction to Statistical Thinking</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-2.ipynb">Chapter 2 - What are Data</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-3.ipynb">Chapter 3 - Organizing Data</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-4.ipynb">Chapter 4 - Cleaning Data</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-5.ipynb">Chapter 5 - Describing Data</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-6.ipynb">Chapter 6 - Variation in Multiple Variables</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-7.ipynb">Chapter 7 - Principles of Data Visualization</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Unit 2 - Modeling Data</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-8.ipynb">Chapter 8 - Where Data Come From</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-9.ipynb">Chapter 9 - Modeling the Data Generation Process</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-10.ipynb">Chapter 10 - Quantifying Model Error</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-11.ipynb">Chapter 11 - Adding an Explanatory Variable</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-12.ipynb">Chapter 12 - Quantitative Predictor Models</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-13.ipynb">Chapter 13 - Multivariable Models</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-14.ipynb">Chapter 14 - Models with Moderation</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Unit 3 - Evaluating Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-15.ipynb">Chapter 15 - Estimating Populations</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-16.ipynb">Chapter 16 - Significance Testing</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-17.ipynb">Chapter 17 - Significance Testing Whole Models</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-18.ipynb">Chapter 18 - Effect Sizes &amp; Statistical Power</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-19.ipynb">Chapter 19 - Model Bias</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-20.ipynb">Chapter 20 - Alternate Approaches - Traditional Statistical Tools</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-21.ipynb">Chapter 21 - Lying with Statistics</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/smburns47/Psyc158/main?urlpath=tree/chapter-10.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onBinder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="initThebeSBT()"
  class="btn btn-sm btn-launch-thebe dropdown-item"
  title="Launch Thebe"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="btn__text-container">Live Code</span>
</button>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/smburns47/Psyc158" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/smburns47/Psyc158/issues/new?title=Issue%20on%20page%20%2Fchapter-10.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/chapter-10.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Chapter 10 - Quantifying Model Error</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#error-distributions">10.1 Error distributions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#central-tendency-of-the-error-distribution">10.2 Central tendency of the error distribution</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#spread-of-the-error-distribution">10.3 Spread of the error distribution</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sum-of-squares">Sum of squares</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mean-squared-error">Mean squared error</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#root-mean-squared-error">Root mean squared error</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#shape-of-the-error-distribution">10.4 Shape of the error distribution</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#estimates-vs-parameters-of-error">10.5 Estimates vs. parameters of error</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sources-of-error">10.6 Sources of error</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#z-scores">10.7 Z-Scores</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#chapter-summary">Chapter summary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#new-concepts">New concepts</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#new-r-functionality">New R functionality</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <p><a class="reference external" href="https://www.shannonmburns.com/Psyc158/intro.html">Back to Table of Contents</a></p>
<p><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-9.ipynb">Previous: Chapter 9 - Statistical Models</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># This chapter uses packages that takes a few minutes to download on Google Colab. </span>
<span class="c1"># Run this first so it&#39;s ready by the time you need it</span>
<span class="nf">install.packages</span><span class="p">(</span><span class="s">&quot;ggformula&quot;</span><span class="p">)</span>
<span class="nf">install.packages</span><span class="p">(</span><span class="s">&quot;dplyr&quot;</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">ggformula</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">dplyr</span><span class="p">)</span>

<span class="n">studentdata</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">read.csv</span><span class="p">(</span><span class="s">&quot;https://raw.githubusercontent.com/smburns47/Psyc158/main/studentdata.csv&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section class="tex2jax_ignore mathjax_ignore" id="chapter-10-quantifying-model-error">
<h1>Chapter 10 - Quantifying Model Error<a class="headerlink" href="#chapter-10-quantifying-model-error" title="Permalink to this heading">#</a></h1>
<p>So far we have developed the idea that a statistical model is an attempt to turn a conceptual model into a deterministic one by fitting it to patterns in data. If we have some idea of the data generation process for a variable of interest, we are trying to make an equation that can capture that process and make accurate predictions about new data.</p>
<p>However, in social and life sciences likely we don’t know a whole lot about the true data generation process. Our equation will be a simplistic approximation of it. And we don’t know the full population of our outcome variable, so we have to fit a model to a sample of data and estimate the population parameters.</p>
<p>Sometimes after this process we have a pretty good model - the values our model predicts closely match the real values in the data sample. But sometimes our model is poor, and our predicted values are way off.</p>
<p>Using the DATA = MODEL + ERROR framework, we have defined error as the residual between a model prediction and a real data value. In the case of a null model for a quantitative outcome variable, the model is the mean of the variable and the error/residual is the deviation of each score above or below the mean.</p>
<p>We represent the simple model like this using the notation of the General Linear Model:</p>
<div class="math notranslate nohighlight">
\[ Y_i = b_0 + e_i \]</div>
<p>This equation represents each outcome score in our data (<span class="math notranslate nohighlight">\(Y_i\)</span>) as the sum of two components: the mean of the outcome distribution (<span class="math notranslate nohighlight">\(b_0\)</span>), and the deviation of that score above or below the mean (<span class="math notranslate nohighlight">\(e_i\)</span>). In other words, DATA = MODEL + ERROR.</p>
<p>In this chapter, we will dig deeper into the ERROR part of our DATA = MODEL + ERROR framework. In particular, we will develop methods for quantifying the total amount of error around a model. This helps us identify when we’ve built a good model of the data generation process. It also helps us compare different versions of models, to see which is better at explaining a sample of data.</p>
<section id="error-distributions">
<h2>10.1 Error distributions<a class="headerlink" href="#error-distributions" title="Permalink to this heading">#</a></h2>
<p>Let’s again consider the situation where we are modeling the length of people’s thumbs in the dataset <code class="docutils literal notranslate"><span class="pre">studentdata</span></code> using the mean of that variable. First, generate a null model using the <code class="docutils literal notranslate"><span class="pre">lm()</span></code> function, and then make a new variable to hold the residuals:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">thumb_model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="c1">#use lm() here with the variable &quot;Thumb&quot; in dataset &quot;studentdata&quot;</span>
<span class="n">studentdata</span><span class="o">$</span><span class="n">Thumb_residuals</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="c1">#use resid() or thumb_model$residuals here </span>
<span class="nf">head</span><span class="p">(</span><span class="n">studentdata</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The residuals of a model are the differences between each person’s real thumb length, and what the model predicts for them:</p>
<div class="math notranslate nohighlight">
\[Y_i - \hat{Y}_i\]</div>
<p>We now have the residuals for each person stored in the variable <code class="docutils literal notranslate"><span class="pre">Thumb_residuals</span></code>. Notice that everyone has a different residual - for some people the model makes a pretty close guess, but for other people the guess is way off. All of the residuals together is called the <strong>error distribution</strong> of the model.</p>
<p>Much like it is useful to plot a histogram of a variable to begin to understand it, we can also plot a histogram of the error distribution. Describing the center, spread, and shape of the error distribution of a statistical model helps us evaluate how good the model is.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">gf_histogram</span><span class="p">(</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">Thumb_residuals</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">studentdata</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span>
<span class="w">  </span><span class="nf">gf_vline</span><span class="p">(</span><span class="n">.</span><span class="p">,</span><span class="w"> </span><span class="n">xintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">studentdata</span><span class="o">$</span><span class="n">Thumb_residuals</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="central-tendency-of-the-error-distribution">
<h2>10.2 Central tendency of the error distribution<a class="headerlink" href="#central-tendency-of-the-error-distribution" title="Permalink to this heading">#</a></h2>
<p>The first thing to note about an error distribution is where it is centered. When we base a statistical model on the mean of an outcome variable, like <code class="docutils literal notranslate"><span class="pre">lm()</span></code> does, the mean of the error distribution is always centered on zero.</p>
<p>This highlights why the mean is a great starting place for building a model. It turns out that no number other than the mean will perfectly balance the deviations above the prediction with those below the prediction. The mean is the number that balances the amount of deviation above and below it, yielding the same amount of error above it as below it. This means that, in the absence of other information about the outcome variable being studied, the mean of our sample is the best single estimate we have of what data from the population looks like. It is equally likely to be too high of a guess as it is to be too low of one for any new data point.</p>
<p>Because it is our best guess of what the population parameter is, it is the best predictor we have of the value of a subsequent observation. While it will almost certainly be wrong, the mean will do a better job than any other individual number.</p>
<p>If we were to pick a different number than the mean to use as the model, our residuals would no longer center on zero and on average we would make worse predictions. Check it out below:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">not_the_mean</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">50</span>

<span class="n">studentdata</span><span class="o">$</span><span class="n">Thumb_bad_residuals</span><span class="w"> </span><span class="o">&lt;-</span><span class="w">  </span><span class="n">studentdata</span><span class="o">$</span><span class="n">Thumb</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">not_the_mean</span>
<span class="nf">gf_histogram</span><span class="p">(</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">Thumb_bad_residuals</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">studentdata</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span>
<span class="w">  </span><span class="nf">gf_vline</span><span class="p">(</span><span class="n">.</span><span class="p">,</span><span class="w"> </span><span class="n">xintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">studentdata</span><span class="o">$</span><span class="n">Thumb_bad_residuals</span><span class="p">),</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;red&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>This alternative error distribution has a red line to indicate the central tendency of <code class="docutils literal notranslate"><span class="pre">Thumb_bad_residuals</span></code>. Since a residual means deviation between a real value and a prediction, we can see that using this bad model will result in fewer predictions that are too high (negative residuals). This is because we’re now always guessing 50 instead of 60. But this also means there are more predictions that are too low, and in general our predictions are off by a greater amount. More often than not, the bad model’s guess of thumb lengths will be too low.</p>
</section>
<section id="spread-of-the-error-distribution">
<h2>10.3 Spread of the error distribution<a class="headerlink" href="#spread-of-the-error-distribution" title="Permalink to this heading">#</a></h2>
<p>While the mean is the best single number to use as a model for a variable, most of the time the null model’s predictions will be wrong. However, we have noted before that the null model of a quantitative outcome variable is <em>less wrong</em> when the spread of the outcome variable’s distribution is smaller than when it is larger. When the spread of a variable is smaller, the magnitude of the average residual will be smaller. Thus the spread of the residuals from the model are smaller. Quantifying the total error in a model involves describing this spread, and will help us to know how good our models are.</p>
<p>To make this concrete, look again at the distribution of error from using the mean as a model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">gf_histogram</span><span class="p">(</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">Thumb_residuals</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">studentdata</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span>
<span class="w">  </span><span class="nf">gf_vline</span><span class="p">(</span><span class="n">.</span><span class="p">,</span><span class="w"> </span><span class="n">xintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">studentdata</span><span class="o">$</span><span class="n">Thumb_residuals</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>A worse model means predictions are farther away from the true data points - bigger magnitude of residuals. So if we want to quantify total error, would we just add up all the residuals? If worse models have more error, the sum of all the errors should represent the “total” error, right?</p>
<p>Let’s do that, using one of the first R functions you learned, <code class="docutils literal notranslate"><span class="pre">sum()</span></code>. The following code will add up all the residuals calculated by  <code class="docutils literal notranslate"><span class="pre">thumb_model</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">sum</span><span class="p">(</span><span class="n">studentdata</span><span class="o">$</span><span class="n">Thumb_residuals</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The sum of all error in this model is actually 0 (or a number so tiny it’s practically zero and is just a rounding error in the computer).</p>
<p>Although we might at first think that the sum of the residuals would be a good indicator of total error, we’ve discovered a fatal flaw in that approach: the sum of the residuals around the mean is equal to 0! This is because some residuals are negative and some are positive. If the sum of residuals were our measure of total error, all data sets would be equally well modeled by the mean, because the residuals around the mean would always sum to 0. A data set widely spread out around the mean, and one tightly clustered around the mean, would have the same amount of error around this simple model. Clearly we need a different approach.</p>
<p>We can return back to the measures of spread in a distribution that we learned in chapter 5 and apply them to describing total error in a statistical model. Because several of those measures involve talking about spread as deviations away from the middle of a distribution, we can also use them to talk about residuals (the deviations between real data and model predictions).</p>
<section id="sum-of-squares">
<h3>Sum of squares<a class="headerlink" href="#sum-of-squares" title="Permalink to this heading">#</a></h3>
<p>Recall when we discussed sum of squares as an option for describing spread. In that discussion, we saw that one way to get around the issue of positive and negative deviations adding up to zero is to square all those numbers first before adding them together. That’s all sum of squares is: the sum of all the squared residuals after fitting a model to data. To review, mathematically this is written as:</p>
<div class="math notranslate nohighlight">
\[ SS = \sum_{i=1}^{N}(Y_i-\hat{Y}_i)^2\]</div>
<p>Where <span class="math notranslate nohighlight">\(\hat{Y}_i\)</span> is the prediction our model makes for the value of <span class="math notranslate nohighlight">\(Y_i\)</span>. In the case of an empty model, that’s just the mean of variable Y, or <span class="math notranslate nohighlight">\(\bar{Y}\)</span>. Since we already have the column <code class="docutils literal notranslate"><span class="pre">Thumb_residuals</span></code> in <code class="docutils literal notranslate"><span class="pre">studentdata</span></code>, we can easily use vector math to square all the values. Summing those will create the overall sum of squares for our model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">sum</span><span class="p">(</span><span class="n">studentdata</span><span class="o">$</span><span class="n">Thumb_residuals</span><span class="o">^</span><span class="m">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>From this you can see the sum of squares (or SS for short) is about 12970.485, not 0 this time. SS helps us distinguish better-fitting models from worse ones because it is a measure of total error that is minimized when residuals are closer to 0. Since our goal in statistical modeling is to reduce error, this is a good thing.</p>
<div class="alert alert-block alert-info">
<b>Note</b>: It is worth pointing out that the usefulness of SS is only true if our model is the mean. If we were to choose another number, such as the median, as our model of a distribution, we would need to choose a different measure of error. But our focus in this course is primarily on the mean.
</div>
<p>R also has a handy way of finding the sum of squares in a model automatically generated with <code class="docutils literal notranslate"><span class="pre">lm()</span></code>. Once we have a model object, we can use a function called <code class="docutils literal notranslate"><span class="pre">supernova()</span></code> from the <code class="docutils literal notranslate"><span class="pre">supernova</span></code> package to create an <strong>ANOVA table</strong> that allows us to look at the error from this model. ANOVA stands for ANalysis Of VAriance, since we are ultimately analyzing the variance of a dependent variable. With a null model, <code class="docutils literal notranslate"><span class="pre">supernova()</span></code> helps us figure out how much error there is in the model, measured in sum of squares.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">install.packages</span><span class="p">(</span><span class="s">&quot;supernova&quot;</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">supernova</span><span class="p">)</span>

<span class="nf">supernova</span><span class="p">(</span><span class="n">thumb_model</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>There are a bunch of other things in this output that we will talk about in later chapters. For now, focus your attention on the row labeled “Total (empty model)” and the column labeled “SS”. This stands for the sum of squares in the empty model (e.g., sum of squared deviations from the model prediction). We see the same value (12970.485) that we previously calculated with the longer sequence of R commands in which we saved the residuals, squared them, and then summed the squared residuals.</p>
</section>
<section id="mean-squared-error">
<h3>Mean squared error<a class="headerlink" href="#mean-squared-error" title="Permalink to this heading">#</a></h3>
<p>Sum of squares is a good measure of <em>total</em> variation if we are using the mean as a model. But, it does have one important disadvantage. To see it, compare these two distributions:</p>
<img src="images/ch10-ss.png" width="600">
<p>The one on top is clearly less spread out than the distribution on the bottom, so we would expect that if we used the mean to model that distribution, there’d be less error. However, because there are more data points in that distribution, there are just more error values to add up. The sum of squares becomes larger than that for the more spread out, but smaller, distribution.</p>
<p>This problem is solved by using <strong>mean squared error</strong> instead. For a null model this is represented by the equation:</p>
<div class="math notranslate nohighlight">
\[ MSE = \frac{1}{N-1}\sum_{i=1}^{N}(Y_i-\hat{Y}_i)^2 \]</div>
<p>The equation above takes the total error (the sum of squares we just computed - can you find that quantity in the equation above?) but then divides by the sample size minus 1 to end up with a measure of <em>average</em> error around the mean — the average of the squared deviations. Does this equation seem familiar? Let’s copy and paste the equation for variance from chapter 5 and see if you notice any similarities:</p>
<div class="math notranslate nohighlight">
\[ s^2 = \frac{1}{N-1}\sum_{i=1}^{N}(Y_i-\bar{Y})^2 \]</div>
<p>Almost exactly the same! The only difference is that variance calculates the mean square deviation of data points from the mean of a distribution (<span class="math notranslate nohighlight">\(Y - \bar{Y}\)</span>), and MSE calculates the mean square deviation between data points and what a statistical model predicts them to be (<span class="math notranslate nohighlight">\(Y - \hat{Y}\)</span>). In fact, in the case where our model is just the mean of variable Y, the MSE and variance of data on Y is exactly the same (since a null model predicts every data point will equal the mean). However, when we get to more complex models, MSE will differ from variance of the outcome variable. Try to remember it instead as variance of the <em>error distribution</em>.</p>
<p>Because it is an average, MSE is not impacted by sample size, and thus, can be used to compare the amount of error across two samples of different sizes.</p>
<div class="alert alert-block alert-info">
<b>Note</b>: We're not actually dividing by the total sample size, but N - 1. As we mentioned in chapter 5, there are some complex reasons for this that we'll get to later in the course. 
</div>
<p>And how do we calculate MSE in R? You know this one already! We can use <code class="docutils literal notranslate"><span class="pre">var()</span></code> on the residuals variable.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">var</span><span class="p">(</span><span class="n">studentdata</span><span class="o">$</span><span class="n">Thumb_residuals</span><span class="p">)</span>

<span class="c1">#same as dividing the sum of squares by N-1</span>
<span class="nf">sum</span><span class="p">(</span><span class="n">studentdata</span><span class="o">$</span><span class="n">Thumb_residuals</span><span class="o">^</span><span class="m">2</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="nf">length</span><span class="p">(</span><span class="n">studentdata</span><span class="o">$</span><span class="n">Thumb</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="m">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>You can also find MSE with <code class="docutils literal notranslate"><span class="pre">supernova()</span></code> whether or not your model is the mean. Use it now to recreate an ANOVA table for <code class="docutils literal notranslate"><span class="pre">thumb_model</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">supernova</span><span class="p">(</span><span class="c1">#YOUR CODE HERE)</span>
</pre></div>
</div>
</div>
</div>
<p>If your code worked okay, you should see a table with values on the “Total (empty model)” line corresponding to “SS”, “df”, and “MS”. We already know what “SS” is. Now, we can guess that “MS” stands for “mean squared”. The number at that spot in the table matches what we calculated with <code class="docutils literal notranslate"><span class="pre">var()</span></code> applied to the vector of residuals. The number under <code class="docutils literal notranslate"><span class="pre">df</span></code>, 156, is the “N-1” component of the MSE equation. With this, we can verify that SS/df = MS.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="m">12970.4846566879</span><span class="o">/</span><span class="m">156</span>

<span class="c1">#same as the variance in the residuals</span>
<span class="nf">var</span><span class="p">(</span><span class="n">studentdata</span><span class="o">$</span><span class="n">Thumb_residuals</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="root-mean-squared-error">
<h3>Root mean squared error<a class="headerlink" href="#root-mean-squared-error" title="Permalink to this heading">#</a></h3>
<p>The <strong>root mean squared error</strong> (abbreviated as RMSE) is simply the square root of the MSE. This is related in the same way that standard deviation is related to variance. We generally prefer thinking about model error in terms of root mean squared error because it yields a number that makes sense using the original scale of measurement. So, for example, if you were modeling weight in pounds, MSE would express the average prediction error in squared pounds (not something we are used to thinking about), whereas RMSE would express the prediction error in pounds. RMSE is how big the residual will be, on average, for any particular data point; on average, how much your model’s prediction is wrong by. This is written as:</p>
<div class="math notranslate nohighlight">
\[RMSE = \sqrt{\frac{1}{N-1}\sum_{i=1}^{N}(Y_i-\hat{Y}_i)^2}\]</div>
<p>Again, in the special case of the null model where we predict every data point to be equal to the mean, RMSE is just the standard deviation of the variable we are making predictions about. In the general case, it is the standard deviation of the error distribution.</p>
<p>See if you can find both the MSE component and the sum of squares component in that equation. We take several mathematical steps to compute this, but if you can find the prior step in the equation, it’s not that hard to see how each measure of error relates to each other.</p>
<p>Of course to calculate standard deviation in R, we can use <code class="docutils literal notranslate"><span class="pre">sd()</span></code> on <code class="docutils literal notranslate"><span class="pre">Thumb_residuals</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">sd</span><span class="p">(</span><span class="n">studentdata</span><span class="o">$</span><span class="n">Thumb_residuals</span><span class="p">)</span>

<span class="c1">#same as taking the square root of variance</span>
<span class="nf">sqrt</span><span class="p">(</span><span class="nf">var</span><span class="p">(</span><span class="n">studentdata</span><span class="o">$</span><span class="n">Thumb_residuals</span><span class="p">))</span>

<span class="c1">#same as dividing the sum of squares by N-1 and then taking the square root</span>
<span class="nf">sqrt</span><span class="p">(</span><span class="nf">sum</span><span class="p">(</span><span class="n">studentdata</span><span class="o">$</span><span class="n">Thumb_residuals</span><span class="o">^</span><span class="m">2</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="nf">length</span><span class="p">(</span><span class="n">studentdata</span><span class="o">$</span><span class="n">Thumb</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="m">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>There isn’t a spot for RMSE in the ANOVA table generated by <code class="docutils literal notranslate"><span class="pre">supernova()</span></code>, but it’s easy enough to calculate if we remember how it relates to mean squared error (“MS” in the ANOVA table print out).</p>
<p>We have discussed three ways of quantifying error around our model. All start with residuals, but they aggregate those residuals in different ways to summarize total error.</p>
<p>All of them assume that the mean is the best single number for representing a variable. If you wanted to use a different single number as a model, like the median or mode, we’d have to use different measures of error (e.g., mean absolute error for median, instead of mean squared error). To keep things simple in this class (well, simpl<em><strong>er</strong></em>), from here on out we’re going to stick to using the mean as a basic statistical model and its associated measures of error: SS, MSE, and RMSE. The majority of data analysis projects also rely on the mean. Don’t forget about median and mode! We just won’t build models with them in this course.</p>
</section>
</section>
<section id="shape-of-the-error-distribution">
<h2>10.4 Shape of the error distribution<a class="headerlink" href="#shape-of-the-error-distribution" title="Permalink to this heading">#</a></h2>
<p>The final thing to notice about the error distribution is how it is shaped. Check out the shape below:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">gf_histogram</span><span class="p">(</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">Thumb_residuals</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">studentdata</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span>
<span class="w">  </span><span class="nf">gf_vline</span><span class="p">(</span><span class="n">.</span><span class="p">,</span><span class="w"> </span><span class="n">xintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">studentdata</span><span class="o">$</span><span class="n">Thumb_residuals</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>How would you describe it in terms of modality and skew? Does it look roughly normal, or strongly distorted in any way?</p>
<p>Again, when talking about shapes of distributions, we always keep in mind the qualifier “roughly.” Even though this distribution is spikey, it roughly resembles a normal distribution. We’re not going to do anything with this information just yet (hang on until chapter 19). But in general, you can remember for now that the General Linear Model, the approach to building statistical models and making predictions about data that we are using in this class, works better when residuals are normally distributed. If they’re strongly not normal, that is cause for concern over whether this type of model is ok to use for your data.</p>
</section>
<section id="estimates-vs-parameters-of-error">
<h2>10.5 Estimates vs. parameters of error<a class="headerlink" href="#estimates-vs-parameters-of-error" title="Permalink to this heading">#</a></h2>
<p>Recall from last chapter our discussion of <em>estimates</em> (summaries computed from data samples) and <em>parameters</em> (summaries of the underlying population we are trying to guess at). We used Latin vs. Greek letters to separate our estimate of the mean, <span class="math notranslate nohighlight">\(\bar{Y}\)</span>, from the unknown population mean parameter, <span class="math notranslate nohighlight">\(\mu\)</span>.</p>
<p>We’ve also now estimated <em>error</em> in a sample (data variance <span class="math notranslate nohighlight">\(s^2\)</span>, standard deviation <span class="math notranslate nohighlight">\(s\)</span>, and model error <span class="math notranslate nohighlight">\(e\)</span>). It follows then, that there’s a true error out there that characterizes how well a model predicts all values in a population. We don’t know this parameter, but we try to estimate it. The Greek letters for the error parameters are <span class="math notranslate nohighlight">\(\epsilon\)</span> for general error (pronounced “epsilon”), <span class="math notranslate nohighlight">\(\sigma^2\)</span> for variance (pronounced “sigma squared”), and just <span class="math notranslate nohighlight">\(\sigma\)</span> for standard deviation (“sigma”). Here is a table of the estimates and parameters we’ve learned so far, to help keep them straight:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Concept</p></th>
<th class="head text-center"><p>Sample Estimate</p></th>
<th class="head text-center"><p>Population Parameter</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p>Mean</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\bar{Y}\)</span> (“Y-bar”)</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\mu\)</span> (“mu”)</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>Model coefficient</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(b_0\)</span> (“b sub 0”)</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\beta_0\)</span> (“beta sub 0”)</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>Model error</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(e\)</span>  (“e”)</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\epsilon\)</span> (“epsilon”)</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p>Variance</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(s^2\)</span> (“s squared”)</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\sigma^2\)</span> (“sigma squared”)</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p>Standard deviation</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(s\)</span> (“s”)</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\sigma\)</span> (“sigma”)</p></td>
</tr>
</tbody>
</table>
</section>
<section id="sources-of-error">
<h2>10.6 Sources of error<a class="headerlink" href="#sources-of-error" title="Permalink to this heading">#</a></h2>
<p>This is a good time to think again about where data come from. Why is there variation in a sample of data, and why do our models make inaccurate predictions? We have already talked about the data generation process — the process that generates values in the population. The data generation process likely includes a lot of different components that, working together, produce variation in an outcome variable. With our statistical models, we are trying to approximately describe that process.</p>
<p>If our model is good, using it to make predictions will result in better guesses than if we guessed randomly. This means that our model <em>explains</em> some of the variation in the outcome variable, as we had one variable explaining variation in another in chapter 6.</p>
<p>But a model, being a simplification of the data generation process, doesn’t explain all the variation in the outcome variable. There will be error, or some variation the model can’t explain. We’re trying to minimize that model error, but we’re unlikely to make it go away completely like in a deterministic model. There are three important points we want to make about sources of data variation which will help us identify what error we can reduce with a model, and what we can’t.</p>
<p>First, variation can be either <strong>explained</strong> or <strong>unexplained</strong>.</p>
<img src="images/ch10-var1.png" width="400">
<p>In the word equation we presented before, DATA = MODEL + ERROR, explained variation is the portion of the total variation in DATA we are able to explain with MODEL. Unexplained variation is everything included in the ERROR part of the equation. It’s useful to think of total variation as the sum of explained + unexplained variation.</p>
<p>If we want to capture the data generation process well with our model, we want to reduce unexplained variation as much as possible and maximize explained variation. What makes variation be unexplained? There can be two reasons: first, there is real variation unaccounted for that is due to a part of the data generation process that we didn’t include in our model. However, some unexplained variation can also be “fake”, in that it is induced by our data collection procedures and not any part of the data generation process.</p>
<img src="images/ch10-var2.png" width="650">
<p>If the unexplained variation is real, that means we can probably figure out how to explain it if we measure the right explanatory variables; this variation could be thought of as not explained <em>yet</em>.</p>
<p>Variation induced by data collection comes in three buckets: measurement error (the small random variation that creeps into our measures from an imperfect measuring system); sampling error (the variation that occurs from sample to sample due to randomness in the sampling process); and data collection mistakes (e.g., some students measured their thumbs in centimeters instead of millimeters).</p>
<img src="images/ch10-var3.png" width="850">
<p>We have just learned how to quantify how much unexplained variation is leftover after we try to build a model. Later on we’ll learn how to express the proportion of explained to unexplained variation to help determine if our model is a good approximation of the data generation process.</p>
<p>Unfortunately, with just one sample of data we are unable to tell how much of the unexplained variation is real or induced. Because of this, statisticians tend to regard all unexplained variation as one bucket in the statistical model equation, <span class="math notranslate nohighlight">\(e_i\)</span>.</p>
</section>
<section id="z-scores">
<h2>10.7 Z-Scores<a class="headerlink" href="#z-scores" title="Permalink to this heading">#</a></h2>
<p>While we’re on the topic of distributions - let’s learn a method in statistics that helps us talk about where a value is in a distribution relative to other values. So far our practice data has dealt with relatively concrete variables, like thumb length in millimeters. When the residual produced by our null model for a particular data point is -20, we know the size of that deviation in the real world. But what if we got the same residual for a different variable, like light intensity of a light bulb? Do you have any instincts about how much 20 lumens is? And what if you wanted to compare the performance of these models to see which is better?</p>
<p>Interpreting the meaning of a variable, and thus how well a model predicts it, depends on knowing about that variable in real life. It depends on knowing the context of what other values on this variable are typical. While it may seem like a problem for interpretation if we ever need to model something more abstract, there is a way we can translate any variable into the same units so that they’re easier to interpret and compare.</p>
<p>For example, consider a student (let’s call her Zelda) who has a thumb length of 64mm. Good for her, but what does this <em>mean</em>? Is that a particularly long thumb, or pretty normal? How can we know?</p>
<p>Let’s consider Zelda’s thumb length relative to the mean of <code class="docutils literal notranslate"><span class="pre">Thumb</span></code> in the full <code class="docutils literal notranslate"><span class="pre">studentdata</span></code> dataset, 60.36. By comparing these two values, we know that Zelda’s thumb is about 3.6mm longer than the average. That helps us get a little closer to understanding what this one data point means. But because we have no idea about the spread of the distribution, we still don’t have a clear answer. Is a 3.6mm distance still pretty close to the mean, or is it far away? It’s hard to tell without knowing what the spread of thumb lengths looks like as well.</p>
<p>Standard deviation in particular is useful for this. We know the mean of our sample of thumb lengths is 60.36mm. What’s the standard deviation?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># find the standard deviation of studentdata$Thumb</span>

<span class="n">thumb_sd</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span>
</pre></div>
</div>
</div>
</div>
<p>Once we calculate that we also know that, on average, people’s thumbs are 9.11mm away from the mean, both above and below. Although Zelda’s thumb is above average in length, it is definitely not one of the longest thumbs in the distribution, or even that atypical - it is only about 0.4 of a standard deviation away from the mean. Check out the histogram below to see this visualized (blue line is the distribution average, red line is Zelda’s thumb length).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">gf_histogram</span><span class="p">(</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">Thumb</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">studentdata</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span>
<span class="w">  </span><span class="nf">gf_vline</span><span class="p">(</span><span class="n">.</span><span class="p">,</span><span class="w"> </span><span class="n">xintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">studentdata</span><span class="o">$</span><span class="n">Thumb</span><span class="p">),</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&#39;blue&#39;</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">  </span><span class="nf">gf_vline</span><span class="p">(</span><span class="n">.</span><span class="p">,</span><span class="w"> </span><span class="n">xintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">64</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&#39;red&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Consider another example. Your friend tells you they just hit a new high score of 37,000 on a video game. Is that a big deal? Here are two possible distributions of high scores other people get on this game, with your friend’s score marked by the red line:</p>
<img src="images/ch10-videogame.png" width="700">
<p>Clearly your friend would be an outstanding player if distribution 1 were true. But if distribution 2 were true, they would be just slightly above average.</p>
<p>It’s more useful to say something about a particular data point if we can also communicate about the mean and standard deviation of a distribution. In order to make this easier, so that we don’t have to report several numbers at once, we can treat standard deviation as a new <em>unit</em> on which to measure our data. Let’s convert the value of <code class="docutils literal notranslate"><span class="pre">Thumb</span></code> to be a data point’s deviation from the mean, divided by the standard deviation:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">studentdata</span><span class="o">$</span><span class="n">Thumb_rescaled</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="p">(</span><span class="n">studentdata</span><span class="o">$</span><span class="n">Thumb</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">studentdata</span><span class="o">$</span><span class="n">Thumb</span><span class="p">))</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nf">sd</span><span class="p">(</span><span class="n">studentdata</span><span class="o">$</span><span class="n">Thumb</span><span class="p">)</span>
<span class="n">studentdata</span><span class="o">$</span><span class="n">Thumb</span><span class="p">[</span><span class="m">11</span><span class="p">]</span><span class="w"> </span><span class="c1"># value of Zelda&#39;s thumb length, in original units</span>
<span class="n">studentdata</span><span class="o">$</span><span class="n">Thumb_rescaled</span><span class="p">[</span><span class="m">11</span><span class="p">]</span><span class="w"> </span><span class="c1"># new value of Zelda&#39;s thumb length, in new units</span>
</pre></div>
</div>
</div>
</div>
<p>This new unit tells us how much of a standard deviation any score is from the mean. This can be positive (above the mean), or negative (below the mean), like this other person’s thumb:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">studentdata</span><span class="o">$</span><span class="n">Thumb</span><span class="p">[</span><span class="m">3</span><span class="p">]</span><span class="w"> </span>
<span class="n">studentdata</span><span class="o">$</span><span class="n">Thumb_rescaled</span><span class="p">[</span><span class="m">3</span><span class="p">]</span><span class="w"> </span>
</pre></div>
</div>
</div>
</div>
<p>This rescaled unit is called the <strong>z-score</strong>. It is a transformation of a variable so that the middle point of a distribution is always 0, and a value of 1 means one standard deviation above the middle (while -1 is one standard deviation below the middle). To calculate it:</p>
<div class="math notranslate nohighlight">
\[ Z_i = \frac{(Y_i - \bar{Y})}{s} \]</div>
<p>where <em>s</em> is the standard deviation of Y. You can implement this equation in R (watch out for order of operations!), or you can also use the function <code class="docutils literal notranslate"><span class="pre">scale()</span></code>.</p>
<p>The “z” in “z-score” comes from the fact that the standard normal distribution (a normal distribution with a mean of zero and a standard deviation of 1) is also called the “Z” distribution. So, what
this transformation does is it actually morphs our data into being a sample from the standard normal distribution.</p>
<p>This all means we can use the standard normal distribution to help us understand what specific z-scores tell us about where a data point sits with respect to the rest of the distribution.</p>
<img src="images/ch10-zscores.png" width="650">
<p>68% of all the data, no matter what scale it was in previously, is within 1 standard deviation of the mean (that’s how we define what a standard deviation is). Thus, once we convert to a z-score, 68% of z-scores are between -1 and 1. 95% of z-scores are between -2 and 2.</p>
<p>A score of 37,000 on a game doesn’t mean much to someone who doesn’t play that game. But this way it’s easy to understand a z-score of 0.2 (a little above average, not too strange) or 3 (way above average, very unusual).</p>
<p>This leads us to the second value of the z-score - we can compare scores from different distributions. Whether you’re measuring thumb length, game score, etc., you can always tell what a more typical vs. more exceptional value is based on its z-score. As we talk about statistical models more, you will see why the z-score is so useful.</p>
</section>
<section id="chapter-summary">
<h2>Chapter summary<a class="headerlink" href="#chapter-summary" title="Permalink to this heading">#</a></h2>
<p>After reading this chapter, you should be able to:</p>
<ul class="simple">
<li><p>Create a distribution of model errors</p></li>
<li><p>Explain what value the error distribution will be centered on</p></li>
<li><p>Define and compare sum of squares, mean squared error, and root mean squared error</p></li>
<li><p>Calculate SS, MSE, and RMSE in a dataset</p></li>
<li><p>Explain the difference between estimates and parameters of error</p></li>
<li><p>Describe different sources of error in a model</p></li>
<li><p>Calculate the z-score of a variable</p></li>
</ul>
</section>
<section id="new-concepts">
<h2>New concepts<a class="headerlink" href="#new-concepts" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p><strong>error distribution</strong>: A distribution that describes all the residuals of a model when fit to a dataset.</p></li>
<li><p><strong>ANOVA table</strong>: Short for Analysis of Variance, a table that breaks down the sources of explained and unexplained variation in a fitted model.</p></li>
<li><p><strong>mean squared error (MSE)</strong> : Mean of the sum of squared errors in a model.</p></li>
<li><p><strong>root mean squared error (RMSE)</strong>: Square root of MSE; expresses the “average” amount of error expected for any one model prediction and what that data value actually is.</p></li>
<li><p><strong>explained error</strong>: Variation in an outcome variable that a model is able to explain.</p></li>
<li><p><strong>unexplained error</strong>: Variation in an outcome variable that a model is unable to explain.</p></li>
<li><p><strong>z-score</strong>: A standardized unit all quantitative variables can be transformed to; 1 z-score corresponds to 1-SD away from the mean in the original variable units.</p></li>
</ul>
</section>
<section id="new-r-functionality">
<h2>New R functionality<a class="headerlink" href="#new-r-functionality" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://www.rdocumentation.org/packages/supernova/versions/3.0.0/topics/supernova">supernova::supernova()</a></p></li>
<li><p><a class="reference external" href="https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/scale">scale()</a></p></li>
</ul>
<p><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-11.ipynb">Next: Chapter 11 - Adding an Explanatory Variable</a></p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "smburns47/Psyc158",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "r"
        },
        kernelOptions: {
            name: "ir",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'ir'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#error-distributions">10.1 Error distributions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#central-tendency-of-the-error-distribution">10.2 Central tendency of the error distribution</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#spread-of-the-error-distribution">10.3 Spread of the error distribution</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sum-of-squares">Sum of squares</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mean-squared-error">Mean squared error</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#root-mean-squared-error">Root mean squared error</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#shape-of-the-error-distribution">10.4 Shape of the error distribution</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#estimates-vs-parameters-of-error">10.5 Estimates vs. parameters of error</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sources-of-error">10.6 Sources of error</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#z-scores">10.7 Z-Scores</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#chapter-summary">Chapter summary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#new-concepts">New concepts</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#new-r-functionality">New R functionality</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Shannon Burns
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>