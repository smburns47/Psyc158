{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f34789e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The downloaded binary packages are in\n",
      "\t/var/folders/mg/1wy1xcls587_h0tqnj42l5740000gn/T//RtmpUpNniz/downloaded_packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "also installing the dependency ‘vroom’\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  There is a binary version available but the source version is later:\n",
      "      binary source needs_compilation\n",
      "readr  2.1.2  2.1.3              TRUE\n",
      "\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\t/var/folders/mg/1wy1xcls587_h0tqnj42l5740000gn/T//RtmpUpNniz/downloaded_packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "installing the source package ‘readr’\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The downloaded binary packages are in\n",
      "\t/var/folders/mg/1wy1xcls587_h0tqnj42l5740000gn/T//RtmpUpNniz/downloaded_packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: ‘readr’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:scales’:\n",
      "\n",
      "    col_factor\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘supernova’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:scales’:\n",
      "\n",
      "    number\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This chapter uses some packages that take a few minutes to download on Google Colab. \n",
    "# Run this first so it's ready by the time you need it\n",
    "install.packages(\"ggformula\")\n",
    "install.packages(\"readr\")\n",
    "install.packages(\"supernova\")\n",
    "library(ggformula)\n",
    "library(readr)\n",
    "library(supernova)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54700c7",
   "metadata": {},
   "source": [
    "# Chapter 11 - Adding an Explanatory Variable\n",
    "\n",
    "As we discussed previously, in the absence of other information about the objects being studied, the mean of our sample is the best single-number estimate we have of the actual mean of the population. It is equally likely to be too high as it is too low for any one data point (the typical variation around the mean is the same on the left side as it is on the right). Because it is our best guess of what the population parameter is, it is the best predictor we have of the value of a subsequent observation. While it will almost certainly be wrong, the mean will do a better job than any other single number.\n",
    "\n",
    "However, we don't have to be limited to *just* a single number. In this chapter we'll learn how to add more pieces to a statistical model to do a better job. \n",
    "\n",
    "## 11.1 Explaining variation\n",
    "\n",
    "We started with the empty model in order to get some important ideas across, but certainly that’s not where we want to end up. It is time we start building models that include explanatory variables. We will still use the empty model, but only as a reference point.\n",
    "\n",
    "Let’s quickly review what we mean by explaining variation. Earlier in the course, we developed an intuitive idea of explanation by comparing the distribution of one variable across two different groups. So, for example, we looked at the distribution of thumb length broken down by sex, which we can see in the two density histograms below.\n",
    "\n",
    "<img src=\"images/ch11-variation.png\" width=\"650\">\n",
    "\n",
    "You can clearly see that sex explains some of the variation in thumb length *in our data*. (This may not be true in the population, of course. It’s always possible that we are being fooled by a sample that doesn’t accurately represent what’s true in the population.) When we break up thumb length by sex it looks like two separate, though overlapping distributions. In general, males have longer thumbs than females in our data.\n",
    "\n",
    "If we assume that this relationship (between sex and thumb length) exists in the population, and not just in our data, we can use it to help us make a better prediction about a future observation. If you know that someone is male, you would make a different prediction of their thumb length than if you knew they were female.\n",
    "\n",
    "It seems, then, that if we were to use a statistical model to make predictions about a person's thumb length, somehow incorporating information about their sex would be helpful - our predictions would be more accurate on average, and there would be less overall error in the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1752213",
   "metadata": {},
   "source": [
    "## 11.2 Adding an explanatory variable to the model\n",
    "\n",
    "In the previous chapters we introduced the idea of a statistical model as an equation that is meant to represent our best guess of the data generation process. This model generates a predicted score for each observation. We developed what we called the empty model, in which we use the mean as the predicted score for each observation.\n",
    "\n",
    "We represented this model in General Linear Model (GLM) notation like this:\n",
    "\n",
    "$$ Y_i = b_0 + e_i $$\n",
    "\n",
    "where b<sub>0</sub> represents the mean of the outcome variable in the sample. When we use the notation of the GLM, we must define the meaning of each symbol in context. Y<sub>i</sub>, for example, could mean lots of different things, depending on what our outcome variable is. But we will always use it to represent the outcome variable. \n",
    "\n",
    "It is also important to remember that b<sub>0</sub> is just an estimate of the true mean in the population. To distinguish the true mean, which is unknown, from the estimate of the true mean we construct from our data, we use the Greek letter &beta;<sub>0</sub> and write the empty model like this:\n",
    "\n",
    "$$ Y_i = \\beta_0 + \\epsilon_i $$\n",
    "\n",
    "The empty model is called a one parameter model because we only need to estimate one parameter (&beta;<sub>0</sub>) in order to generate a predicted score for each observation.\n",
    "\n",
    "In the case of thumb length, this model states that the DATA (each data point, represented as Y<sub>i</sub>, which is each person’s measured thumb length), can be thought of as being generated by the combination of two inputs: the MODEL, represented as b<sub>0</sub> (which is the mean thumb length for everyone, usually called the Grand Mean); plus ERROR, which is each person’s residual from the model, represented by e<sub>i</sub>.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note</b>: We use the term Grand Mean to refer to the mean of the entire sample in order to distinguish it clearly from other means, such as the mean for subgroups within the sample.\n",
    "</div>\n",
    "\n",
    "It’s useful to illustrate the empty model (and what we're about to do to it) with our ```tiny_fingers``` dataset. ```tiny_fingers```, you will recall, contains six people’s thumb lengths randomly selected from our complete ```fingers``` dataset. This time, we'll also include their value on the ```Sex``` variable as well. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "770d0cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>student_ID</th><th scope=col>Thumb</th><th scope=col>Sex</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>1</td><td>56</td><td>female</td></tr>\n",
       "\t<tr><td>2</td><td>60</td><td>female</td></tr>\n",
       "\t<tr><td>3</td><td>61</td><td>female</td></tr>\n",
       "\t<tr><td>4</td><td>63</td><td>male  </td></tr>\n",
       "\t<tr><td>5</td><td>64</td><td>male  </td></tr>\n",
       "\t<tr><td>6</td><td>68</td><td>male  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 3\n",
       "\\begin{tabular}{lll}\n",
       " student\\_ID & Thumb & Sex\\\\\n",
       " <dbl> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t 1 & 56 & female\\\\\n",
       "\t 2 & 60 & female\\\\\n",
       "\t 3 & 61 & female\\\\\n",
       "\t 4 & 63 & male  \\\\\n",
       "\t 5 & 64 & male  \\\\\n",
       "\t 6 & 68 & male  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 3\n",
       "\n",
       "| student_ID &lt;dbl&gt; | Thumb &lt;dbl&gt; | Sex &lt;chr&gt; |\n",
       "|---|---|---|\n",
       "| 1 | 56 | female |\n",
       "| 2 | 60 | female |\n",
       "| 3 | 61 | female |\n",
       "| 4 | 63 | male   |\n",
       "| 5 | 64 | male   |\n",
       "| 6 | 68 | male   |\n",
       "\n"
      ],
      "text/plain": [
       "  student_ID Thumb Sex   \n",
       "1 1          56    female\n",
       "2 2          60    female\n",
       "3 3          61    female\n",
       "4 4          63    male  \n",
       "5 5          64    male  \n",
       "6 6          68    male  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "student_ID <- c(1, 2, 3, 4, 5, 6)\n",
    "Thumb <- c(56, 60, 61, 63, 64, 68)\n",
    "Sex <- c(\"female\", \"female\", \"female\", \"male\", \"male\", \"male\")\n",
    "\n",
    "tiny_fingers <- data.frame(student_ID, Thumb, Sex)\n",
    "tiny_fingers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985ff187",
   "metadata": {},
   "source": [
    "We can put this data into a basic scatter plot with ```Sex``` on the x-axis and ```Thumb``` on the y-axis in order to visualize how ```Sex``` might explain ```Thumb```. \n",
    "\n",
    "<img src=\"images/ch11-nullmodel.png\" width=\"750\">\n",
    "\n",
    "In the above plot, we drew a blue horizontal line in order to mark where the Grand Mean of the whole ```tiny_fingers``` dataset is. This is the same value as b<sub>0</sub> - in other words, this is what we would predict everyone's thumb length to be if we were using the empty or null model. But there is plenty of error to this prediction - no data point is on this line, and we could calculate the RMSE to find out how large the residuals are in general. \n",
    "\n",
    "So let's try to take into account the effect of ```Sex``` and improve our prediction. One thing we could do is, instead of using the Grand Mean of ```Thumb``` to predict everyone's thumb length, we could first consider whether or not the prediction we want to make is for a male or female. Then, we could use the mean of *just that group* in order to make our prediction. \n",
    "\n",
    "<img src=\"images/ch11-sexpredictor.png\" width=\"750\">\n",
    "\n",
    "A model that takes ```Sex``` into account generates a different prediction for a male than it does for a female. Error is still measured the same way, as the deviation of each person’s measured thumb length from their predicted thumb length. But this time, the error is calculated from each person’s group mean (male or female) instead of from the Grand Mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a60bdc",
   "metadata": {},
   "source": [
    "## 11.3 Specifying the model form\n",
    "\n",
    "Whereas the empty model was a one-parameter model (we only had to estimate one parameter, the Grand Mean), the ```Sex```  model is a two-parameter model. One of the parameters is the mean for males, the other is the mean for females. By using the model as an equation for predicting the value of ```Thumb```, we should be able to use one or the other mean depending on the value of ```Sex```. \n",
    "\n",
    "One way to do this is to use the mean of one group (say, females) as &beta;<sub>0</sub>, and then add an extra amount to that value if someone is actually male. In other words, we could specify another parameter, &beta;<sub>1</sub>, as the *difference* between male and female mean thumb lengths. But this should only be added if someone is male, so let's multiply this parameter by 1 if ```Sex``` is \"male\", and by 0 if ```Sex``` if \"female\" and we should ignore this addition.\n",
    "\n",
    "Here is how to write this in GLM form: \n",
    "\n",
    "$$ Y_i = \\beta_0 + \\beta_1X_i + \\epsilon_i $$\n",
    "\n",
    "In this equation, &beta;<sub>0</sub> is the group mean for \"female\" and &beta;<sub>1</sub> is the difference between the group mean of male and female. X<sub>i</sub> is a variable, in this case ```Sex``` (which can take the value of either 0 for female or 1 for male). \n",
    "\n",
    "Of course we're making an estimate of the population and not measuring it directly, so the estimate form of this equation would be:\n",
    "\n",
    "$$ Y_i = b_0 + b_1X_i + e_i $$\n",
    "\n",
    "We're still using the DATA = MODEL + ERROR framework for this. Except this time, our MODEL takes into account the value of ```Sex``` and has multiple components (b<sub>0</sub> + b<sub>1</sub>X<sub>i</sub>) instead of one component (b<sub>0</sub>). b<sub>0</sub> also no longer stands for the Grand Mean of this sample, but the *group* mean of whatever group we assigned to be 0 in the Boolean variable ```Sex```. To calculate our prediction of each person's thumb, we'd fill in the parameters with the group mean of female (59) and the difference between the group means of male and female (65 - 59 = 6):\n",
    "\n",
    "$$ \\hat{Y}_i = 59 + 6X_i $$\n",
    "\n",
    "This equation would make one prediction (59) when the value of X<sub>i</sub> is 0 (female), and a different prediction (65) when the value of X<sub>i</sub> is 1 (male). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f5a5e7",
   "metadata": {},
   "source": [
    "## 11.4 Error in the one-variable model\n",
    "\n",
    "Why should we take ```Sex``` into account in the first place? Using two parameters in our model instead of one makes it more complex, or less **parsimonious**. We'll talk more later about the importance of parsimony, but for now we should just know that it's harder to work with a more complex model than a simpler one. Thus, there should be a good reason for making it more complex - it should reduce the error in our model predictions. \n",
    "\n",
    "Let's try it out. We'll add columns of predictions to ```tiny_fingers```, calculate the residuals, and then calculate the RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e7f3eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "4.04969134626332"
      ],
      "text/latex": [
       "4.04969134626332"
      ],
      "text/markdown": [
       "4.04969134626332"
      ],
      "text/plain": [
       "[1] 4.049691"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "2.64575131106459"
      ],
      "text/latex": [
       "2.64575131106459"
      ],
      "text/markdown": [
       "2.64575131106459"
      ],
      "text/plain": [
       "[1] 2.645751"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tiny_fingers$GrandMean <- c(62, 62, 62, 62, 62, 62) #predictions using grand mean\n",
    "tiny_fingers$GroupMeans <- c(59, 59, 59, 65, 65, 65) #predictions using group means\n",
    "tiny_fingers$GrandResid <- tiny_fingers$Thumb - tiny_fingers$GrandMean #grand mean prediction residuals\n",
    "tiny_fingers$GroupResid <- tiny_fingers$Thumb - tiny_fingers$GroupMeans #group mean prediction residuals\n",
    "\n",
    " #equation for RMSE in one-parameter case \n",
    "sqrt(sum(tiny_fingers$GrandResid^2) / (length(tiny_fingers$GrandResid) - 1))\n",
    " #equation for RMSE in two-parameter case \n",
    "sqrt(sum(tiny_fingers$GroupResid^2) / (length(tiny_fingers$GroupResid) - 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2cb6fd",
   "metadata": {},
   "source": [
    "Success! If we make predictions about people's thumb lengths using the Grand Mean, on average we're about 4.05mm off. But if we take into account each person's sex for making the prediction, we're only about 2.65mm off. Not perfect, but we almost halved our error! \n",
    "\n",
    "You may have noticed that, in order to calculate RMSE for the empty and one-variable models above, we used slightly different equations. Specifically, in the null model it was calculated as: \n",
    "\n",
    "$$RMSE_{null} = \\sqrt{\\frac{1}{N-1}\\sum_{i=1}^{N}(Y_i-\\hat{Y}_i)^2}$$\n",
    "\n",
    "and in the one-variable model it was calculated as:\n",
    "\n",
    "$$RMSE_{sex} = \\sqrt{\\frac{1}{N-2}\\sum_{i=1}^{N}(Y_i-\\hat{Y}_i)^2}$$\n",
    "\n",
    "The difference is that we divided the sum of squares in the null model by N - 1, and in the one-variable model we divided by N - 2. We've already talked about how, if this measure should be the root *mean* squared error, it's weird that we're not actually *calculating the mean of the error* (which would be found by dividing by N only). Now, we can learn more about why that is. \n",
    "\n",
    "If we were to only divide by N, that would actually be fine for finding the RMSE *of this specific sample*. It would be the root of the mean squared error, exactly as it sounds. However, remember again that our ultimate goal is not to make a model *for this sample*, but to *estimate the data generation process for the whole population*. As it turns out, if we divide by only N for finding the RMSE of a sample, we will systematically underestimate how much error our model would have in the population. We'll demonstrate this in more detail in a later chapter. \n",
    "\n",
    "In order for us to correct for this underestimation, we need to divide by a slightly smaller number than N: N - 1 in the empty model, or N - 2 in the one-variable model. This replacement term is called the **degrees of freedom** in the model.\n",
    "\n",
    "What are degrees of freedom? In essense, they are the number of unique pieces of information in a dataset, or the number of ways the dataset can vary. You might think that, if a dataset has 6 items (N=6), then there should be 6 unique pieces of information there, right? Each observation can vary in its own way? That would be true, until you bring a parameter estimate of that data into play. Once we have an estimate about the dataset as a whole (say, the mean as b<sub>0</sub> in the empty model), that actually takes away one way the dataset can vary - it takes away one degree of freedom.\n",
    "\n",
    "Let's demonstrate this with our tiny dataset. We have a set of thumb lengths, [56, 60, 61, 63, 64, 68]. If we were missing one (our set looked like [56, 60, 61, 63, 64, ?]), we wouldn't have any way of knowing what that sixth item should be - it is free to vary. But if we have the 5 known items, *and* we have an estimate of the mean of the sample (grand mean = 62), the missing 6th item can *only* be 68 in order to keep that grand mean estimate at 62. It is not free to vary. Thus, when we have an estimate of the mean of a sample, the degrees of freedom are N - 1. We only need to know 5 of the items in the sample in order to know the whole sample. \n",
    "\n",
    "When we extend to the one-variable model, we have two parameter estimates - b<sub>0</sub> and b<sub>1</sub>. We could be missing one value from each sex subgroup (2 datapoints total), and still solve for all the values in the dataset since we have each group mean. Thus, the degrees of freedom for a one-variable model is N - 2. To generalize this, the degrees of freedom of any model is *sample size - number of parameters*, or *N - k* for short. \n",
    "\n",
    "When calculating error in a model, dividing by degrees instead of sample size keeps us from underestimating the error in the population. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87786b0a",
   "metadata": {},
   "source": [
    "## 11.5 Fitting the one-variable model\n",
    "\n",
    "Now that you have learned how to specify a model with an explanatory variable (also frequently called a *predictor*), let’s learn how to fit the model using R.\n",
    "\n",
    "Fitting a model, as a reminder, simply means automatically calculating the parameter estimates. We use the word “fitting” because we want to calculate the best estimate, the one that will result in the least amount of error and best \"fit\" our data. For the tiny data set, we could calculate the parameter estimates in our head — it’s just a matter of calculating the mean for males and the mean for females. But when the data set is larger, it is much easier to use R.\n",
    "\n",
    "Using R, we will first fit the Sex model to the tiny dataset, just so you can see that R gives you the same parameter estimates you got before. After that we will fit it to the complete data set.\n",
    "\n",
    "Here's the model we are going to fit:\n",
    "\n",
    "$$ Y_i = b_0 + b_1X_i + e_i $$\n",
    "\n",
    "Note that the parts that are going to have different values for each observation (X<sub>i</sub> and Y<sub>i</sub>) are called variables (because they vary)! e<sub>i</sub> also varies, but we typically reserve the label “variable” for outcome and explanatory variables. The parts that are going to have the same value for each observation (b<sub>0</sub> and b<sub>1</sub>) are called parameter estimates.\n",
    "\n",
    "We do not need to estimate the variables. Each student in the dataset already has a score for the outcome variable (Y<sub>i</sub>) and the explanatory variable (X<sub>i</sub>), and these scores vary across students. Notice that the subscript *i* is attached to the parts that are different for each person.\n",
    "\n",
    "We do need to estimate the parameters because, as discussed previously, they are features of the population, and thus are unknown. The parameter estimates we calculate are those that best fit our particular sample of data. But we would have probably gotten different estimates if we had a different sample. Thus, it is important to keep in mind that these estimates are only that, and they are undoubtedly a bit off. Calling them estimates keeps us humble!\n",
    "\n",
    "Parameter estimates don’t vary from person to person, so they don’t carry the subscript *i*.\n",
    "\n",
    "To fit the Sex model we use ```lm()``` again. This time, instead of the left side of the formula being ```NULL```, we have a variable to put there. Thus, the formula argument of ```lm()``` is ```Thumb ~ Sex```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc280e0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = Thumb ~ Sex, data = tiny_fingers)\n",
       "\n",
       "Coefficients:\n",
       "(Intercept)      Sexmale  \n",
       "         59            6  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm(Thumb ~ Sex, data = tiny_fingers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef96e734",
   "metadata": {},
   "source": [
    "Notice that the estimates are exactly what you should have expected: the first estimate, for b<sub>0</sub>, is 59 (the mean for females); the second, b<sub>1</sub>, is 6, which is the number of millimeters you need to add to the female average thumb length to get average male thumb length.\n",
    "\n",
    "Notice also that the estimate for b<sub>0</sub> is labeled “intercept” in the output. You have encountered the concept of intercept before, when you studied the concept of a line in algebra. Remember that ```y = mx + b``` is the equation for a line? *m* represents the slope of the line, and *b* represents the y-intercept. The General Linear Model notation is similar to this, though it includes error, whereas the equation for a line does not.\n",
    "\n",
    "The reason the estimate for b<sub>0</sub> is called \"Intercept\" is because it is the estimate for thumb length when *X* is equal to 0. In other words, when sex is female. The estimate that R called “Sexmale,” by this line of reasoning, is kind of like the slope of a line. It is the increment in thumb length for a unit increase in *X*.\n",
    "\n",
    "If you want — and it’s a good idea — you can save the results of this model fit in an R object. Here’s the code to save the model fit in an object called ```tiny_sex_model```. Once you’ve saved the model, If you want to see what the model estimates are, you can just type the name of the model and you will get the same output as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6b321d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_sex_model <- lm(Thumb ~ Sex, data = tiny_fingers)\n",
    "\n",
    "#type the name of the saved model below to print out its output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ad35d5",
   "metadata": {},
   "source": [
    "Now that we have estimates for the two parameters, we can put them in our model statement to yield: Y<sub>i</sub> = 59 = 6X<sub>i</sub>.\n",
    "\n",
    "You may have noticed that the values of ```Sex``` in ```tiny_fingers``` are the categorical strings ```female``` or ```male```, and not 1 or 0. We were able to run ```lm()``` anyway, so it seems like R is able to handle converting categorical data to Boolean data. But how does R know which level of ```Sex``` should be 0 and which should be 1? The answer to this question is, R doesn’t know; it’s just taking whatever group comes first alphabetically (in this case,  ```female```) and making it the **reference group**. The mean of the reference group is the first parameter estimate (b<sub>0</sub> or the Intercept in the ```lm()``` output). R then takes the second group (in this case, ```male```) and represents it with b<sub>1</sub>.  \n",
    "\n",
    "Let’s say, just for fun, that you changed the code for ```female``` into ```woman``` in the data frame. Because ```male``` now comes first in the alphabet, ```male``` becomes the reference group, and its mean is now the estimate for the intercept (b<sub>0</sub>).\n",
    "\n",
    "Converting it to a Boolean variable is also called making a **dummy variable** for the model prediction equation (this does not get saved to your data frame - it's just a temporary computation R makes under the hood). You could supply a Sex variable as a Boolean of 0s and 1s already, but if not R will translate a categorical variable into a dummy variable do build the model with. \n",
    "\n",
    "Now that you have looked in detail at the tiny set of data, find the best estimates for our bigger set of data (in the data frame called ```fingers```) by modifying the code below. What would be b<sub>0</sub> and what would be b<sub>1</sub>?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86762beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRows: \u001b[22m\u001b[34m157\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m16\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m  (5): Sex, RaceEthnic, Job, MathAnxious, Interest\n",
      "\u001b[32mdbl\u001b[39m (11): FamilyMembers, SSLast, Year, GradePredict, Thumb, Index, Middle, R...\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = Thumb ~ Sex, data = fingers)\n",
       "\n",
       "Coefficients:\n",
       "(Intercept)      Sexmale  \n",
       "     58.256        6.447  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fingers <- read_csv(\"https://raw.githubusercontent.com/smburns47/Psyc158/main/fingers.csv\")\n",
    "\n",
    "# store the model where Sex predicts Thumb\n",
    "sex_model <- \n",
    "\n",
    "# this prints out the model estimates\n",
    "sex_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9784687b",
   "metadata": {},
   "source": [
    "## 11.6 Generating predictions from the model\n",
    "\n",
    "Now that you have fit the Sex model, you can use your estimates to make predictions about future observations. Doing this requires you to use your model as an equation. In this case, you will put in a value (e.g., “female”) for your explanatory variable (```Sex```), and get out a predicted thumb length.\n",
    "\n",
    "Recall that our model looks like this:\n",
    "\n",
    "$$ Y_i = b_0 + b_1X_i + e_i $$\n",
    "\n",
    "Once fit, we can print out the coefficients of the model, and then replace b<sub>0</sub> with the Intercept value, and replace b<sub>1</sub> with the other coefficient. Then, in order to make a prediction about the value of ```Thumb``` for any one person, we remove the error term. If our goal is to model the variation, we want the error term there. But if our goal is to predict, we are going to ignore error and just do our best! We also change the Y<sub>i</sub> to Y^<sub>i</sub>, which indicates a predicted score for person *i*. Our prediction equation, then, looks like this:\n",
    "\n",
    "$$ \\hat{Y}_i = 58.256 + 6.447*X_i$$\n",
    "\n",
    "We leave out the error term because every person will have a different error term. If we knew their error, we could predict their score exactly. But since we don’t when making a new prediction, all we can do is predict their score based on their sex.\n",
    "\n",
    "This prediction equation is straightforward to use. If we want to predict what the next observed thumb length will be, we can see that if the next student sampled is female, their predicted thumb length is 58.256. If they are male, the prediction is 58.256 + 6.447, or 64.703.\n",
    "\n",
    "If you want to produce each coefficient by itself with code, you can also use commands below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa96689f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>(Intercept):</strong> 58.2558482142857"
      ],
      "text/latex": [
       "\\textbf{(Intercept):} 58.2558482142857"
      ],
      "text/markdown": [
       "**(Intercept):** 58.2558482142857"
      ],
      "text/plain": [
       "(Intercept) \n",
       "   58.25585 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong>Sexmale:</strong> 6.44681845238095"
      ],
      "text/latex": [
       "\\textbf{Sexmale:} 6.44681845238095"
      ],
      "text/markdown": [
       "**Sexmale:** 6.44681845238095"
      ],
      "text/plain": [
       " Sexmale \n",
       "6.446818 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sex_model$coefficients[1] #this will print out the first coefficient, b0\n",
    "sex_model$coefficients[2] #this will print out the second coefficient, b1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da8075a",
   "metadata": {},
   "source": [
    "You can use the ```$``` operator here even though ```sex_model``` isn't a data frame because it works with multiple types of complex objects. In a data frame, it accesses a column by name. In a model object, it accesses outputs of the model by name. The ```coefficients``` output has two items in it, so you can use indexing like ```[1]``` or ```[2]``` to access the first or the second coefficient. \n",
    "\n",
    "As we did in chapter 9, we also will want to generate model predictions for our sample data. It seems odd to predict values when we already know the actual values. But it’s actually very useful to do so, because then we can calculate residuals from the model predictions.\n",
    "\n",
    "To get predicted values from the ```sex_model```, we use the ```predict()``` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "189e8e94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>1</dt><dd>64.7026666666666</dd><dt>2</dt><dd>58.2558482142857</dd><dt>3</dt><dd>58.2558482142857</dd><dt>4</dt><dd>64.7026666666666</dd><dt>5</dt><dd>58.2558482142857</dd><dt>6</dt><dd>58.2558482142857</dd><dt>7</dt><dd>64.7026666666666</dd><dt>8</dt><dd>58.2558482142857</dd><dt>9</dt><dd>58.2558482142857</dd><dt>10</dt><dd>58.2558482142857</dd><dt>11</dt><dd>58.2558482142857</dd><dt>12</dt><dd>64.7026666666666</dd><dt>13</dt><dd>58.2558482142857</dd><dt>14</dt><dd>64.7026666666666</dd><dt>15</dt><dd>58.2558482142857</dd><dt>16</dt><dd>58.2558482142857</dd><dt>17</dt><dd>58.2558482142857</dd><dt>18</dt><dd>64.7026666666666</dd><dt>19</dt><dd>58.2558482142857</dd><dt>20</dt><dd>64.7026666666666</dd><dt>21</dt><dd>58.2558482142857</dd><dt>22</dt><dd>58.2558482142857</dd><dt>23</dt><dd>58.2558482142857</dd><dt>24</dt><dd>64.7026666666666</dd><dt>25</dt><dd>58.2558482142857</dd><dt>26</dt><dd>58.2558482142857</dd><dt>27</dt><dd>58.2558482142857</dd><dt>28</dt><dd>58.2558482142857</dd><dt>29</dt><dd>58.2558482142857</dd><dt>30</dt><dd>64.7026666666666</dd><dt>31</dt><dd>64.7026666666666</dd><dt>32</dt><dd>58.2558482142857</dd><dt>33</dt><dd>58.2558482142857</dd><dt>34</dt><dd>58.2558482142857</dd><dt>35</dt><dd>58.2558482142857</dd><dt>36</dt><dd>58.2558482142857</dd><dt>37</dt><dd>58.2558482142857</dd><dt>38</dt><dd>58.2558482142857</dd><dt>39</dt><dd>58.2558482142857</dd><dt>40</dt><dd>64.7026666666666</dd><dt>41</dt><dd>58.2558482142857</dd><dt>42</dt><dd>58.2558482142857</dd><dt>43</dt><dd>64.7026666666666</dd><dt>44</dt><dd>64.7026666666666</dd><dt>45</dt><dd>58.2558482142857</dd><dt>46</dt><dd>58.2558482142857</dd><dt>47</dt><dd>58.2558482142857</dd><dt>48</dt><dd>64.7026666666666</dd><dt>49</dt><dd>58.2558482142857</dd><dt>50</dt><dd>58.2558482142857</dd><dt>51</dt><dd>64.7026666666666</dd><dt>52</dt><dd>58.2558482142857</dd><dt>53</dt><dd>58.2558482142857</dd><dt>54</dt><dd>58.2558482142857</dd><dt>55</dt><dd>64.7026666666666</dd><dt>56</dt><dd>58.2558482142857</dd><dt>57</dt><dd>58.2558482142857</dd><dt>58</dt><dd>58.2558482142857</dd><dt>59</dt><dd>58.2558482142857</dd><dt>60</dt><dd>58.2558482142857</dd><dt>61</dt><dd>58.2558482142857</dd><dt>62</dt><dd>58.2558482142857</dd><dt>63</dt><dd>58.2558482142857</dd><dt>64</dt><dd>64.7026666666666</dd><dt>65</dt><dd>58.2558482142857</dd><dt>66</dt><dd>64.7026666666666</dd><dt>67</dt><dd>64.7026666666666</dd><dt>68</dt><dd>64.7026666666666</dd><dt>69</dt><dd>58.2558482142857</dd><dt>70</dt><dd>64.7026666666666</dd><dt>71</dt><dd>64.7026666666666</dd><dt>72</dt><dd>58.2558482142857</dd><dt>73</dt><dd>64.7026666666666</dd><dt>74</dt><dd>64.7026666666666</dd><dt>75</dt><dd>58.2558482142857</dd><dt>76</dt><dd>58.2558482142857</dd><dt>77</dt><dd>58.2558482142857</dd><dt>78</dt><dd>58.2558482142857</dd><dt>79</dt><dd>58.2558482142857</dd><dt>80</dt><dd>64.7026666666666</dd><dt>81</dt><dd>58.2558482142857</dd><dt>82</dt><dd>58.2558482142857</dd><dt>83</dt><dd>58.2558482142857</dd><dt>84</dt><dd>58.2558482142857</dd><dt>85</dt><dd>64.7026666666666</dd><dt>86</dt><dd>58.2558482142857</dd><dt>87</dt><dd>58.2558482142857</dd><dt>88</dt><dd>64.7026666666666</dd><dt>89</dt><dd>58.2558482142857</dd><dt>90</dt><dd>58.2558482142857</dd><dt>91</dt><dd>58.2558482142857</dd><dt>92</dt><dd>58.2558482142857</dd><dt>93</dt><dd>58.2558482142857</dd><dt>94</dt><dd>58.2558482142857</dd><dt>95</dt><dd>58.2558482142857</dd><dt>96</dt><dd>64.7026666666666</dd><dt>97</dt><dd>58.2558482142857</dd><dt>98</dt><dd>58.2558482142857</dd><dt>99</dt><dd>64.7026666666666</dd><dt>100</dt><dd>58.2558482142857</dd><dt>101</dt><dd>64.7026666666666</dd><dt>102</dt><dd>58.2558482142857</dd><dt>103</dt><dd>58.2558482142857</dd><dt>104</dt><dd>58.2558482142857</dd><dt>105</dt><dd>58.2558482142857</dd><dt>106</dt><dd>64.7026666666666</dd><dt>107</dt><dd>58.2558482142857</dd><dt>108</dt><dd>58.2558482142857</dd><dt>109</dt><dd>64.7026666666666</dd><dt>110</dt><dd>58.2558482142857</dd><dt>111</dt><dd>58.2558482142857</dd><dt>112</dt><dd>64.7026666666666</dd><dt>113</dt><dd>58.2558482142857</dd><dt>114</dt><dd>58.2558482142857</dd><dt>115</dt><dd>58.2558482142857</dd><dt>116</dt><dd>58.2558482142857</dd><dt>117</dt><dd>64.7026666666666</dd><dt>118</dt><dd>64.7026666666666</dd><dt>119</dt><dd>64.7026666666666</dd><dt>120</dt><dd>64.7026666666666</dd><dt>121</dt><dd>58.2558482142857</dd><dt>122</dt><dd>64.7026666666666</dd><dt>123</dt><dd>58.2558482142857</dd><dt>124</dt><dd>58.2558482142857</dd><dt>125</dt><dd>58.2558482142857</dd><dt>126</dt><dd>58.2558482142857</dd><dt>127</dt><dd>58.2558482142857</dd><dt>128</dt><dd>64.7026666666666</dd><dt>129</dt><dd>58.2558482142857</dd><dt>130</dt><dd>58.2558482142857</dd><dt>131</dt><dd>58.2558482142857</dd><dt>132</dt><dd>58.2558482142857</dd><dt>133</dt><dd>58.2558482142857</dd><dt>134</dt><dd>64.7026666666666</dd><dt>135</dt><dd>64.7026666666666</dd><dt>136</dt><dd>58.2558482142857</dd><dt>137</dt><dd>58.2558482142857</dd><dt>138</dt><dd>58.2558482142857</dd><dt>139</dt><dd>58.2558482142857</dd><dt>140</dt><dd>58.2558482142857</dd><dt>141</dt><dd>58.2558482142857</dd><dt>142</dt><dd>64.7026666666666</dd><dt>143</dt><dd>64.7026666666666</dd><dt>144</dt><dd>58.2558482142857</dd><dt>145</dt><dd>58.2558482142857</dd><dt>146</dt><dd>58.2558482142857</dd><dt>147</dt><dd>58.2558482142857</dd><dt>148</dt><dd>58.2558482142857</dd><dt>149</dt><dd>58.2558482142857</dd><dt>150</dt><dd>64.7026666666666</dd><dt>151</dt><dd>64.7026666666666</dd><dt>152</dt><dd>58.2558482142857</dd><dt>153</dt><dd>58.2558482142857</dd><dt>154</dt><dd>58.2558482142857</dd><dt>155</dt><dd>58.2558482142857</dd><dt>156</dt><dd>58.2558482142857</dd><dt>157</dt><dd>58.2558482142857</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[1] 64.7026666666666\n",
       "\\item[2] 58.2558482142857\n",
       "\\item[3] 58.2558482142857\n",
       "\\item[4] 64.7026666666666\n",
       "\\item[5] 58.2558482142857\n",
       "\\item[6] 58.2558482142857\n",
       "\\item[7] 64.7026666666666\n",
       "\\item[8] 58.2558482142857\n",
       "\\item[9] 58.2558482142857\n",
       "\\item[10] 58.2558482142857\n",
       "\\item[11] 58.2558482142857\n",
       "\\item[12] 64.7026666666666\n",
       "\\item[13] 58.2558482142857\n",
       "\\item[14] 64.7026666666666\n",
       "\\item[15] 58.2558482142857\n",
       "\\item[16] 58.2558482142857\n",
       "\\item[17] 58.2558482142857\n",
       "\\item[18] 64.7026666666666\n",
       "\\item[19] 58.2558482142857\n",
       "\\item[20] 64.7026666666666\n",
       "\\item[21] 58.2558482142857\n",
       "\\item[22] 58.2558482142857\n",
       "\\item[23] 58.2558482142857\n",
       "\\item[24] 64.7026666666666\n",
       "\\item[25] 58.2558482142857\n",
       "\\item[26] 58.2558482142857\n",
       "\\item[27] 58.2558482142857\n",
       "\\item[28] 58.2558482142857\n",
       "\\item[29] 58.2558482142857\n",
       "\\item[30] 64.7026666666666\n",
       "\\item[31] 64.7026666666666\n",
       "\\item[32] 58.2558482142857\n",
       "\\item[33] 58.2558482142857\n",
       "\\item[34] 58.2558482142857\n",
       "\\item[35] 58.2558482142857\n",
       "\\item[36] 58.2558482142857\n",
       "\\item[37] 58.2558482142857\n",
       "\\item[38] 58.2558482142857\n",
       "\\item[39] 58.2558482142857\n",
       "\\item[40] 64.7026666666666\n",
       "\\item[41] 58.2558482142857\n",
       "\\item[42] 58.2558482142857\n",
       "\\item[43] 64.7026666666666\n",
       "\\item[44] 64.7026666666666\n",
       "\\item[45] 58.2558482142857\n",
       "\\item[46] 58.2558482142857\n",
       "\\item[47] 58.2558482142857\n",
       "\\item[48] 64.7026666666666\n",
       "\\item[49] 58.2558482142857\n",
       "\\item[50] 58.2558482142857\n",
       "\\item[51] 64.7026666666666\n",
       "\\item[52] 58.2558482142857\n",
       "\\item[53] 58.2558482142857\n",
       "\\item[54] 58.2558482142857\n",
       "\\item[55] 64.7026666666666\n",
       "\\item[56] 58.2558482142857\n",
       "\\item[57] 58.2558482142857\n",
       "\\item[58] 58.2558482142857\n",
       "\\item[59] 58.2558482142857\n",
       "\\item[60] 58.2558482142857\n",
       "\\item[61] 58.2558482142857\n",
       "\\item[62] 58.2558482142857\n",
       "\\item[63] 58.2558482142857\n",
       "\\item[64] 64.7026666666666\n",
       "\\item[65] 58.2558482142857\n",
       "\\item[66] 64.7026666666666\n",
       "\\item[67] 64.7026666666666\n",
       "\\item[68] 64.7026666666666\n",
       "\\item[69] 58.2558482142857\n",
       "\\item[70] 64.7026666666666\n",
       "\\item[71] 64.7026666666666\n",
       "\\item[72] 58.2558482142857\n",
       "\\item[73] 64.7026666666666\n",
       "\\item[74] 64.7026666666666\n",
       "\\item[75] 58.2558482142857\n",
       "\\item[76] 58.2558482142857\n",
       "\\item[77] 58.2558482142857\n",
       "\\item[78] 58.2558482142857\n",
       "\\item[79] 58.2558482142857\n",
       "\\item[80] 64.7026666666666\n",
       "\\item[81] 58.2558482142857\n",
       "\\item[82] 58.2558482142857\n",
       "\\item[83] 58.2558482142857\n",
       "\\item[84] 58.2558482142857\n",
       "\\item[85] 64.7026666666666\n",
       "\\item[86] 58.2558482142857\n",
       "\\item[87] 58.2558482142857\n",
       "\\item[88] 64.7026666666666\n",
       "\\item[89] 58.2558482142857\n",
       "\\item[90] 58.2558482142857\n",
       "\\item[91] 58.2558482142857\n",
       "\\item[92] 58.2558482142857\n",
       "\\item[93] 58.2558482142857\n",
       "\\item[94] 58.2558482142857\n",
       "\\item[95] 58.2558482142857\n",
       "\\item[96] 64.7026666666666\n",
       "\\item[97] 58.2558482142857\n",
       "\\item[98] 58.2558482142857\n",
       "\\item[99] 64.7026666666666\n",
       "\\item[100] 58.2558482142857\n",
       "\\item[101] 64.7026666666666\n",
       "\\item[102] 58.2558482142857\n",
       "\\item[103] 58.2558482142857\n",
       "\\item[104] 58.2558482142857\n",
       "\\item[105] 58.2558482142857\n",
       "\\item[106] 64.7026666666666\n",
       "\\item[107] 58.2558482142857\n",
       "\\item[108] 58.2558482142857\n",
       "\\item[109] 64.7026666666666\n",
       "\\item[110] 58.2558482142857\n",
       "\\item[111] 58.2558482142857\n",
       "\\item[112] 64.7026666666666\n",
       "\\item[113] 58.2558482142857\n",
       "\\item[114] 58.2558482142857\n",
       "\\item[115] 58.2558482142857\n",
       "\\item[116] 58.2558482142857\n",
       "\\item[117] 64.7026666666666\n",
       "\\item[118] 64.7026666666666\n",
       "\\item[119] 64.7026666666666\n",
       "\\item[120] 64.7026666666666\n",
       "\\item[121] 58.2558482142857\n",
       "\\item[122] 64.7026666666666\n",
       "\\item[123] 58.2558482142857\n",
       "\\item[124] 58.2558482142857\n",
       "\\item[125] 58.2558482142857\n",
       "\\item[126] 58.2558482142857\n",
       "\\item[127] 58.2558482142857\n",
       "\\item[128] 64.7026666666666\n",
       "\\item[129] 58.2558482142857\n",
       "\\item[130] 58.2558482142857\n",
       "\\item[131] 58.2558482142857\n",
       "\\item[132] 58.2558482142857\n",
       "\\item[133] 58.2558482142857\n",
       "\\item[134] 64.7026666666666\n",
       "\\item[135] 64.7026666666666\n",
       "\\item[136] 58.2558482142857\n",
       "\\item[137] 58.2558482142857\n",
       "\\item[138] 58.2558482142857\n",
       "\\item[139] 58.2558482142857\n",
       "\\item[140] 58.2558482142857\n",
       "\\item[141] 58.2558482142857\n",
       "\\item[142] 64.7026666666666\n",
       "\\item[143] 64.7026666666666\n",
       "\\item[144] 58.2558482142857\n",
       "\\item[145] 58.2558482142857\n",
       "\\item[146] 58.2558482142857\n",
       "\\item[147] 58.2558482142857\n",
       "\\item[148] 58.2558482142857\n",
       "\\item[149] 58.2558482142857\n",
       "\\item[150] 64.7026666666666\n",
       "\\item[151] 64.7026666666666\n",
       "\\item[152] 58.2558482142857\n",
       "\\item[153] 58.2558482142857\n",
       "\\item[154] 58.2558482142857\n",
       "\\item[155] 58.2558482142857\n",
       "\\item[156] 58.2558482142857\n",
       "\\item[157] 58.2558482142857\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "1\n",
       ":   64.70266666666662\n",
       ":   58.25584821428573\n",
       ":   58.25584821428574\n",
       ":   64.70266666666665\n",
       ":   58.25584821428576\n",
       ":   58.25584821428577\n",
       ":   64.70266666666668\n",
       ":   58.25584821428579\n",
       ":   58.255848214285710\n",
       ":   58.255848214285711\n",
       ":   58.255848214285712\n",
       ":   64.702666666666613\n",
       ":   58.255848214285714\n",
       ":   64.702666666666615\n",
       ":   58.255848214285716\n",
       ":   58.255848214285717\n",
       ":   58.255848214285718\n",
       ":   64.702666666666619\n",
       ":   58.255848214285720\n",
       ":   64.702666666666621\n",
       ":   58.255848214285722\n",
       ":   58.255848214285723\n",
       ":   58.255848214285724\n",
       ":   64.702666666666625\n",
       ":   58.255848214285726\n",
       ":   58.255848214285727\n",
       ":   58.255848214285728\n",
       ":   58.255848214285729\n",
       ":   58.255848214285730\n",
       ":   64.702666666666631\n",
       ":   64.702666666666632\n",
       ":   58.255848214285733\n",
       ":   58.255848214285734\n",
       ":   58.255848214285735\n",
       ":   58.255848214285736\n",
       ":   58.255848214285737\n",
       ":   58.255848214285738\n",
       ":   58.255848214285739\n",
       ":   58.255848214285740\n",
       ":   64.702666666666641\n",
       ":   58.255848214285742\n",
       ":   58.255848214285743\n",
       ":   64.702666666666644\n",
       ":   64.702666666666645\n",
       ":   58.255848214285746\n",
       ":   58.255848214285747\n",
       ":   58.255848214285748\n",
       ":   64.702666666666649\n",
       ":   58.255848214285750\n",
       ":   58.255848214285751\n",
       ":   64.702666666666652\n",
       ":   58.255848214285753\n",
       ":   58.255848214285754\n",
       ":   58.255848214285755\n",
       ":   64.702666666666656\n",
       ":   58.255848214285757\n",
       ":   58.255848214285758\n",
       ":   58.255848214285759\n",
       ":   58.255848214285760\n",
       ":   58.255848214285761\n",
       ":   58.255848214285762\n",
       ":   58.255848214285763\n",
       ":   58.255848214285764\n",
       ":   64.702666666666665\n",
       ":   58.255848214285766\n",
       ":   64.702666666666667\n",
       ":   64.702666666666668\n",
       ":   64.702666666666669\n",
       ":   58.255848214285770\n",
       ":   64.702666666666671\n",
       ":   64.702666666666672\n",
       ":   58.255848214285773\n",
       ":   64.702666666666674\n",
       ":   64.702666666666675\n",
       ":   58.255848214285776\n",
       ":   58.255848214285777\n",
       ":   58.255848214285778\n",
       ":   58.255848214285779\n",
       ":   58.255848214285780\n",
       ":   64.702666666666681\n",
       ":   58.255848214285782\n",
       ":   58.255848214285783\n",
       ":   58.255848214285784\n",
       ":   58.255848214285785\n",
       ":   64.702666666666686\n",
       ":   58.255848214285787\n",
       ":   58.255848214285788\n",
       ":   64.702666666666689\n",
       ":   58.255848214285790\n",
       ":   58.255848214285791\n",
       ":   58.255848214285792\n",
       ":   58.255848214285793\n",
       ":   58.255848214285794\n",
       ":   58.255848214285795\n",
       ":   58.255848214285796\n",
       ":   64.702666666666697\n",
       ":   58.255848214285798\n",
       ":   58.255848214285799\n",
       ":   64.7026666666666100\n",
       ":   58.2558482142857101\n",
       ":   64.7026666666666102\n",
       ":   58.2558482142857103\n",
       ":   58.2558482142857104\n",
       ":   58.2558482142857105\n",
       ":   58.2558482142857106\n",
       ":   64.7026666666666107\n",
       ":   58.2558482142857108\n",
       ":   58.2558482142857109\n",
       ":   64.7026666666666110\n",
       ":   58.2558482142857111\n",
       ":   58.2558482142857112\n",
       ":   64.7026666666666113\n",
       ":   58.2558482142857114\n",
       ":   58.2558482142857115\n",
       ":   58.2558482142857116\n",
       ":   58.2558482142857117\n",
       ":   64.7026666666666118\n",
       ":   64.7026666666666119\n",
       ":   64.7026666666666120\n",
       ":   64.7026666666666121\n",
       ":   58.2558482142857122\n",
       ":   64.7026666666666123\n",
       ":   58.2558482142857124\n",
       ":   58.2558482142857125\n",
       ":   58.2558482142857126\n",
       ":   58.2558482142857127\n",
       ":   58.2558482142857128\n",
       ":   64.7026666666666129\n",
       ":   58.2558482142857130\n",
       ":   58.2558482142857131\n",
       ":   58.2558482142857132\n",
       ":   58.2558482142857133\n",
       ":   58.2558482142857134\n",
       ":   64.7026666666666135\n",
       ":   64.7026666666666136\n",
       ":   58.2558482142857137\n",
       ":   58.2558482142857138\n",
       ":   58.2558482142857139\n",
       ":   58.2558482142857140\n",
       ":   58.2558482142857141\n",
       ":   58.2558482142857142\n",
       ":   64.7026666666666143\n",
       ":   64.7026666666666144\n",
       ":   58.2558482142857145\n",
       ":   58.2558482142857146\n",
       ":   58.2558482142857147\n",
       ":   58.2558482142857148\n",
       ":   58.2558482142857149\n",
       ":   58.2558482142857150\n",
       ":   64.7026666666666151\n",
       ":   64.7026666666666152\n",
       ":   58.2558482142857153\n",
       ":   58.2558482142857154\n",
       ":   58.2558482142857155\n",
       ":   58.2558482142857156\n",
       ":   58.2558482142857157\n",
       ":   58.2558482142857\n",
       "\n"
      ],
      "text/plain": [
       "       1        2        3        4        5        6        7        8 \n",
       "64.70267 58.25585 58.25585 64.70267 58.25585 58.25585 64.70267 58.25585 \n",
       "       9       10       11       12       13       14       15       16 \n",
       "58.25585 58.25585 58.25585 64.70267 58.25585 64.70267 58.25585 58.25585 \n",
       "      17       18       19       20       21       22       23       24 \n",
       "58.25585 64.70267 58.25585 64.70267 58.25585 58.25585 58.25585 64.70267 \n",
       "      25       26       27       28       29       30       31       32 \n",
       "58.25585 58.25585 58.25585 58.25585 58.25585 64.70267 64.70267 58.25585 \n",
       "      33       34       35       36       37       38       39       40 \n",
       "58.25585 58.25585 58.25585 58.25585 58.25585 58.25585 58.25585 64.70267 \n",
       "      41       42       43       44       45       46       47       48 \n",
       "58.25585 58.25585 64.70267 64.70267 58.25585 58.25585 58.25585 64.70267 \n",
       "      49       50       51       52       53       54       55       56 \n",
       "58.25585 58.25585 64.70267 58.25585 58.25585 58.25585 64.70267 58.25585 \n",
       "      57       58       59       60       61       62       63       64 \n",
       "58.25585 58.25585 58.25585 58.25585 58.25585 58.25585 58.25585 64.70267 \n",
       "      65       66       67       68       69       70       71       72 \n",
       "58.25585 64.70267 64.70267 64.70267 58.25585 64.70267 64.70267 58.25585 \n",
       "      73       74       75       76       77       78       79       80 \n",
       "64.70267 64.70267 58.25585 58.25585 58.25585 58.25585 58.25585 64.70267 \n",
       "      81       82       83       84       85       86       87       88 \n",
       "58.25585 58.25585 58.25585 58.25585 64.70267 58.25585 58.25585 64.70267 \n",
       "      89       90       91       92       93       94       95       96 \n",
       "58.25585 58.25585 58.25585 58.25585 58.25585 58.25585 58.25585 64.70267 \n",
       "      97       98       99      100      101      102      103      104 \n",
       "58.25585 58.25585 64.70267 58.25585 64.70267 58.25585 58.25585 58.25585 \n",
       "     105      106      107      108      109      110      111      112 \n",
       "58.25585 64.70267 58.25585 58.25585 64.70267 58.25585 58.25585 64.70267 \n",
       "     113      114      115      116      117      118      119      120 \n",
       "58.25585 58.25585 58.25585 58.25585 64.70267 64.70267 64.70267 64.70267 \n",
       "     121      122      123      124      125      126      127      128 \n",
       "58.25585 64.70267 58.25585 58.25585 58.25585 58.25585 58.25585 64.70267 \n",
       "     129      130      131      132      133      134      135      136 \n",
       "58.25585 58.25585 58.25585 58.25585 58.25585 64.70267 64.70267 58.25585 \n",
       "     137      138      139      140      141      142      143      144 \n",
       "58.25585 58.25585 58.25585 58.25585 58.25585 64.70267 64.70267 58.25585 \n",
       "     145      146      147      148      149      150      151      152 \n",
       "58.25585 58.25585 58.25585 58.25585 58.25585 64.70267 64.70267 58.25585 \n",
       "     153      154      155      156      157 \n",
       "58.25585 58.25585 58.25585 58.25585 58.25585 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict(sex_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3aeaa0b",
   "metadata": {},
   "source": [
    "This is a big output, but the results are just what we've already done - for each observation, their predicted thumb length is the mean of female students if their value on ```Sex``` is ```female``` (~58.256), or will be the mean of male students if their value on ```Sex``` is ```male``` (~64.703).\n",
    "\n",
    "Let’s say you want to save these predicted values for each person as a variable called ```Sex_predicted``` (in the ```fingers``` data frame). See if you can complete the R code to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13383c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fingers$Sex_predicted <-\n",
    "\n",
    "# this prints the first few lines of the fingers data frame, to check if your variable saved successfully\n",
    "head(fingers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03fb843",
   "metadata": {},
   "source": [
    "## 11.7 Quantifying model fit\n",
    "\n",
    "**CASE WHERE DIFFERENCE BETWEEN GROUP MEANS IS 0**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03633b7c",
   "metadata": {},
   "source": [
    "## 11.8 Improvement over empty model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
