mean(R2s)
trueR2
summary(sim_model)$coefficients[2,4]
summary(sim_model)
sigs <- vector(length=1000)
for (i in 1:1000) {
sim_sample <- sample_n(high_sim_df, size=100, replace=TRUE)
sim_model <- lm(y ~ x, data = sim_sample)  #fitting a linear model instead of nonlinear
sigs[i] <- summary(sim_model)$coefficients[2,4] < 0.05
}
sum(sigs)/1000
sigs <- vector(length=1000)
for (i in 1:1000) {
sim_sample <- sample_n(sim_df, size=100, replace=TRUE)
sim_model <- lm(y ~ x, data = sim_sample)  #fitting a linear model instead of nonlinear
sigs[i] <- summary(sim_model)$coefficients[2,4] < 0.05
}
sum(sigs)/1000
x <- runif(40000,0,1)    #oversimulating since we're going to cut out ~3/4 of the data
e <- rnorm(40000,0,1)
y <- 2 + 0.3*x + e       #0.3 is the true b1 value in population
sim_df <- data.frame(x, y)
high_sim_df <- filter(sim_df, x>0.75) #filtering to only large x values
#sampling many estimates of b1
b1s <- vector(length=1000)
for (i in 1:1000) {
sim_sample <- sample_n(high_sim_df, size=100, replace=TRUE)
sim_model <- lm(y ~ x, data = sim_sample)  #fitting a linear model instead of nonlinear
b1s[i] <- sim_model$coefficients[[2]]
}
#central tendency of b1 estimates
b1s_df <- data.frame(b1s)
gf_histogram(~ b1s, data = b1s_df) %>% gf_vline(., xintercept = 0.3) #true b1 is 0.3
mean(b1s)
sd(b1s)
b1s <- vector(length=1000)
for (i in 1:1000) {
sim_sample <- sample_n(sim_df, size=100, replace=TRUE)
sim_model <- lm(y ~ x, data = sim_sample)  #fitting a linear model instead of nonlinear
b1s[i] <- sim_model$coefficients[[2]]
}
b1s_df <- data.frame(b1s)
gf_histogram(~ b1s, data = b1s_df) %>% gf_vline(., xintercept = 0.3) #true b1 is 0.3
sd(b1s)
b1s_df <- data.frame(b1s)
gf_histogram(~ b1s, data = b1s_df) %>% gf_vline(., xintercept = 0.3) %>% #true b1 is 0.3
gf_refine(coord_cartesian(xlim=c(-5,5)))
sigs <- vector(length=1000)
for (i in 1:1000) {
sim_sample <- sample_n(sim_df, size=100, replace=TRUE)
sim_model <- lm(y ~ x, data = sim_sample)  #fitting a linear model instead of nonlinear
sigs[i] <- summary(sim_model)$coefficients[2,4] < 0.05
}
sum(sigs)/1000
summary(sim_model)
ses <- vector(length=1000)
for (i in 1:1000) {
sim_sample <- sample_n(sim_df, size=100, replace=TRUE)
sim_model <- lm(y ~ x, data = sim_sample)  #fitting a linear model instead of nonlinear
ses[i] <- summary(sim_model)$coefficients[2,2]
}
#central tendency of b1 estimates
ses_df <- data.frame(ses)
gf_histogram(~ ses, data = ses_df) %>% gf_vline(., xintercept = 0.3) %>% #true b1 is 0.3
gf_refine(coord_cartesian(xlim=c(-5,5)))
mean(ses)
ses_df <- data.frame(ses)
gf_histogram(~ ses, data = ses_df) %>% gf_vline(., xintercept = 0.3) #true b1 is 0.3
mean(ses)
ses_df <- data.frame(ses)
gf_histogram(~ ses, data = ses_df) %>% gf_vline(., xintercept = mean(ses)) #true b1 is 0.3
mean(ses)
ses <- vector(length=1000)
for (i in 1:1000) {
sim_sample <- sample_n(high_sim_df, size=100, replace=TRUE)
sim_model <- lm(y ~ x, data = sim_sample)  #fitting a linear model instead of nonlinear
ses[i] <- summary(sim_model)$coefficients[2,2]
}
#central tendency of b1 estimates
ses_df <- data.frame(ses)
gf_histogram(~ ses, data = ses_df) %>% gf_vline(., xintercept = 0.35) #true ses is 0.35
mean(ses)
sigs <- vector(length=1000)
for (i in 1:1000) {
sim_sample <- sample_n(high_sim_df, size=100, replace=TRUE)
sim_model <- lm(y ~ x, data = sim_sample)  #fitting a linear model instead of nonlinear
sigs[i] <- summary(sim_model)$coefficients[2,4] < 0.05
}
sum(sigs)/1000
x <- runif(40000,0,1)    #oversimulating since we're going to cut out ~3/4 of the data
e <- rnorm(40000,0,1)
y <- 2 + e       #0 is the true b1 value in population
sim_df <- data.frame(x, y)
high_sim_df <- filter(sim_df, x>0.75) #filtering to only large x values
#unbiased Type I error
sigs <- vector(length=1000)
for (i in 1:1000) {
sim_sample <- sample_n(sim_df, size=100, replace=TRUE)
sim_model <- lm(y ~ x, data = sim_sample)  #fitting a linear model instead of nonlinear
sigs[i] <- summary(sim_model)$coefficients[2,4] < 0.05
}
sum(sigs)/1000
sigs <- vector(length=1000)
for (i in 1:1000) {
sim_sample <- sample_n(high_sim_df, size=100, replace=TRUE)
sim_model <- lm(y ~ x, data = sim_sample)  #fitting a linear model instead of nonlinear
sigs[i] <- summary(sim_model)$coefficients[2,4] < 0.05
}
sum(sigs)/1000
x <- runif(10000,0,4)    #defining a random variable
e <- rnorm(10000,0,1)    #some unexplained error
x_squared <- x**2
y <- 2 + 0.5*x_squared + e  #0.5 is the true b1 value in a quadratic model
sim_df <- data.frame(x, x_squared, y)
#sampling many estimates of b1
b1s <- vector(length=1000)
for (i in 1:1000) {
sim_sample <- sample_n(sim_df, size=100, replace=TRUE)
sim_model <- lm(y ~ x, data = sim_sample)  #fitting a linear model instead of nonlinear
b1s[i] <- sim_model$coefficients[[2]]
}
#central tendency of b1 estimates
b1s_df <- data.frame(b1s)
gf_histogram(~ b1s, data = b1s_df) %>% gf_vline(., xintercept = 0.5) #true b1 is 0.5
mean(b1s)
ses <- vector(length=1000)
for (i in 1:1000) {
sim_sample <- sample_n(sim_df, size=100, replace=TRUE)
sim_model <- lm(y ~ x_squared, data = sim_sample)  #fitting a linear model instead of nonlinear
ses[i] <- summary(sim_model)$coefficients[2,2]
}
truese <- mean(ses)
#sampling biased SEs
ses <- vector(length=1000)
for (i in 1:1000) {
sim_sample <- sample_n(sim_df, size=100, replace=TRUE)
sim_model <- lm(y ~ x, data = sim_sample)  #fitting a linear model instead of nonlinear
ses[i] <- summary(sim_model)$coefficients[2,2]
}
mean(ses)
#central tendency of b1 estimates
ses_df <- data.frame(ses)
gf_histogram(~ ses, data = ses_df) %>% gf_vline(., xintercept = truese) #true b1 is 0.5
mean(ses)
ses <- vector(length=1000)
for (i in 1:1000) {
sim_sample <- sample_n(sim_df, size=100, replace=TRUE)
sim_model <- lm(y ~ x_squared, data = sim_sample)  #fitting a linear model instead of nonlinear
ses[i] <- summary(sim_model)$coefficients[2,2]
}
truese <- mean(ses)
truese
#sampling biased SEs
ses <- vector(length=1000)
for (i in 1:1000) {
sim_sample <- sample_n(sim_df, size=100, replace=TRUE)
sim_model <- lm(y ~ x, data = sim_sample)  #fitting a linear model instead of nonlinear
ses[i] <- summary(sim_model)$coefficients[2,2]
}
mean(ses)
#central tendency of b1 estimates
ses_df <- data.frame(ses)
gf_histogram(~ ses, data = ses_df) %>% gf_vline(., xintercept = truese) #true b1 is 0.5
#unbiased power
sigs <- vector(length=1000)
for (i in 1:1000) {
sim_sample <- sample_n(sim_df, size=100, replace=TRUE)
sim_model <- lm(y ~ x_squared, data = sim_sample)
sigs[i] <- summary(sim_model)$coefficients[2,4] < 0.05
}
sum(sigs)/1000
#biased power
sigs <- vector(length=1000)
for (i in 1:1000) {
sim_sample <- sample_n(sim_df, size=100, replace=TRUE)
sim_model <- lm(y ~ x, data = sim_sample)
sigs[i] <- summary(sim_model)$coefficients[2,4] < 0.05
}
sum(sigs)/1000
x <- runif(10000,0,4)    #defining a random variable
e <- rnorm(10000,0,1)    #some unexplained error
x_squared <- x**2
y <- 2 + 0.05*x_squared + e  #0.5 is the true b1 value in a quadratic model
sim_df <- data.frame(x, x_squared, y)
#sampling many estimates of b1
b1s <- vector(length=1000)
for (i in 1:1000) {
sim_sample <- sample_n(sim_df, size=100, replace=TRUE)
sim_model <- lm(y ~ x, data = sim_sample)  #fitting a linear model instead of nonlinear
b1s[i] <- sim_model$coefficients[[2]]
}
#central tendency of b1 estimates
b1s_df <- data.frame(b1s)
gf_histogram(~ b1s, data = b1s_df) %>% gf_vline(., xintercept = 0.5) #true b1 is 0.5
mean(b1s)
#central tendency of b1 estimates
b1s_df <- data.frame(b1s)
gf_histogram(~ b1s, data = b1s_df) %>% gf_vline(., xintercept = 0.05) #true b1 is 0.5
mean(b1s)
sigs <- vector(length=1000)
for (i in 1:1000) {
sim_sample <- sample_n(sim_df, size=100, replace=TRUE)
sim_model <- lm(y ~ x_squared, data = sim_sample)
sigs[i] <- summary(sim_model)$coefficients[2,4] < 0.05
}
sum(sigs)/1000
#biased power
sigs <- vector(length=1000)
for (i in 1:1000) {
sim_sample <- sample_n(sim_df, size=100, replace=TRUE)
sim_model <- lm(y ~ x, data = sim_sample)
sigs[i] <- summary(sim_model)$coefficients[2,4] < 0.05
}
sum(sigs)/1000
gf_point(y~x, data=sim_df)
x <- runif(10000,0,4)    #defining a random variable
e <- rnorm(10000,0,1)    #some unexplained error
x_squared <- x**2
y <- 2 + 0.5*x_squared + e  #0.5 is the true b1 value in a quadratic model
sim_df <- data.frame(x, x_squared, y)
gf_point(y~x, data=sim_df)
gf_point(y~x, data=sim_sample)
gf_point(y~x, data=sim_df[1:1000,])
gf_point(y~x, data=sim_df[1:500,])
gf_point(y~x, data=sim_df[1:400,])
gf_point(y~x, data=sim_df[1:500,])
set.seed(70)
subsample <- sample_n(sim_df, size=100, replace=TRUE)
goodmodel <- lm(y ~ x_squared, data = subsample)
summary(goodmodel)$coefficients[2,4] #return p-value
badmodel <- lm(y ~ x, data = subsample)
summary(badmodel)$coefficients[2,4] #return p-value
subsample$badpredicted <- predict(badmodel, subsample)
subsample$badresid <- subsample$y - predict(badmodel, subsample)
gf_point(badresid ~ badpredicted, data=subsample) %>% gf_smooth()
x2 <- runif(10000,0,4)    #defining a random variable
ex <- rnorm(10000,0,1)    #some unexplained error
x1 <- x2 + ex
ey <- rnorm(10000,0,1)    #some unexplained error
y <- x2 + ey
sim_df <- data.frame(x1, x2, y)
#sampling many estimates of b1
b1s <- vector(length=1000)
for (i in 1:1000) {
sim_sample <- sample_n(sim_df, size=100, replace=TRUE)
sim_model <- lm(y ~ x1, data = sim_sample)  #fitting an endogenous model
b1s[i] <- sim_model$coefficients[[2]]
}
#central tendency of b1 estimates
b1s_df <- data.frame(b1s)
gf_histogram(~ b1s, data = b1s_df) %>% gf_vline(., xintercept = 0) #true b1 is 0
mean(b1s)
#unbiased type 1 error
sigs <- vector(length=1000)
for (i in 1:1000) {
sim_sample <- sample_n(sim_df, size=100, replace=TRUE)
sim_model <- lm(y ~ x1 + x2, data = sim_sample)
sigs[i] <- summary(sim_model)$coefficients[2,4] < 0.05
}
sum(sigs)/1000
#biased type I error
sigs <- vector(length=1000)
for (i in 1:1000) {
sim_sample <- sample_n(sim_df, size=100, replace=TRUE)
sim_model <- lm(y ~ x1, data = sim_sample)
sigs[i] <- summary(sim_model)$coefficients[2,4] < 0.05
}
sum(sigs)/1000
subsample <- sample_n(sim_df, size=100, replace=TRUE)
badmodel <- lm(y ~ x2, data=subsample)
subsample$badresid <- subsample$y - predict(badmodel, subsample)
#correlation between model residuals and the omitted variable
gf_point(badresid ~ x1, data=subsample) %>% gf_lm()
set.seed(70)
subsample <- sample_n(sim_df, size=100, replace=TRUE)
badmodel <- lm(y ~ x2, data=subsample)
subsample$badresid <- subsample$y - predict(badmodel, subsample)
#correlation between model residuals and the omitted variable
gf_point(badresid ~ x1, data=subsample) %>% gf_lm()
subsample <- sample_n(sim_df, size=100, replace=TRUE)
badmodel <- lm(y ~ x2, data=subsample)
subsample$badresid <- subsample$y - predict(badmodel, subsample)
#correlation between model residuals and the omitted variable
gf_point(badresid ~ x1, data=subsample) %>% gf_lm()
subsample <- sample_n(sim_df, size=100, replace=TRUE)
badmodel <- lm(y ~ x1, data=subsample)
subsample$badresid <- subsample$y - predict(badmodel, subsample)
#correlation between model residuals and the omitted variable
gf_point(badresid ~ x1, data=subsample) %>% gf_lm()
subsample <- sample_n(sim_df, size=100, replace=TRUE)
badmodel <- lm(y ~ x1, data=subsample)
subsample$badresid <- subsample$y - predict(badmodel, subsample)
#correlation between model residuals and the omitted variable
gf_point(badresid ~ x2, data=subsample) %>% gf_lm()
cor(badresid$subsample, x2$subsample)
cor(subsample$badresid, subsample$x2)
set.seed(70)
subsample <- sample_n(sim_df, size=100, replace=TRUE)
goodmodel <- lm(y ~ x2, data=subsample)
subsample$goodresid <- subsample$y - predict(goodmodel, subsample)
#correlation between model residuals and the omitted variable
gf_point(goodresid ~ x1, data=subsample) %>% gf_lm()
cor(subsample$goodresid, subsample$x1)
x1 <- runif(10000,0,5)    #defining a random variable
ex <- rnorm(10000,0,0.5)  #some unexplained error between predictors
x2 <- x1 + ex             #another, highly related predictor variable
e <- rnorm(10000,0,1)     #some unexplained error
y <- 0.5*x1 + e           #true data generation process only involves x1, b=0.5
sim_df <- data.frame(x1, x2, y)
b1s <- vector(length=1000)
for (i in 1:1000) {
sim_sample <- sample_n(sim_df, size=100, replace=TRUE)
sim_model <- lm(y ~ x1 + x2, data = sim_sample)  #fitting a linear model instead of nonlinear
b1s[i] <- sim_model$coefficients[[2]]
}
#central tendency of b1 estimates
b1s_df <- data.frame(b1s)
gf_histogram(~ b1s, data = b1s_df) %>% gf_vline(., xintercept = 0.5) #true b1 is 0.5
mean(b1s)
cor(x1,x2)
b1s_df <- data.frame(b1s)
gf_histogram(~ b1s, data = b1s_df) %>% gf_vline(., xintercept = 0.5) #true b1 is 0.5
mean(b1s)
ses <- vector(length=1000)
for (i in 1:1000) {
sim_sample <- sample_n(sim_df, size=100, replace=TRUE)
sim_model <- lm(y ~ x1, data = sim_sample)  #fitting a linear model instead of nonlinear
ses[i] <- summary(sim_model)$coefficients[2,2]
}
truese <- mean(ses)
truese
ses_df <- data.frame(ses)
gf_histogram(~ ses, data = ses_df) %>% gf_vline(., xintercept = truese) #true b1 is 0.5
ses <- vector(length=1000)
for (i in 1:1000) {
sim_sample <- sample_n(sim_df, size=100, replace=TRUE)
sim_model <- lm(y ~ x1 + x2, data = sim_sample)  #fitting a linear model instead of nonlinear
ses[i] <- summary(sim_model)$coefficients[2,2]
}
mean(ses)
#central tendency of b1 estimates
ses_df <- data.frame(ses)
gf_histogram(~ ses, data = ses_df) %>% gf_vline(., xintercept = truese) #true b1 is 0.5
b1s <- vector(length=1000)
for (i in 1:1000) {
sim_sample <- sample_n(sim_df, size=100, replace=TRUE)
sim_model <- lm(y ~ x1, data = sim_sample)
b1s[i] <- sim_model$coefficients[[2]]
}
#central tendency of b1 estimates
b1s_df <- data.frame(b1s)
gf_histogram(~ b1s, data = b1s_df) %>% gf_vline(., xintercept = 0.5) %>%#true b1 is 0.5
gf_refine(coord_cartesian(xlim=c(-0.5,1.2)))
mean(b1s)
truese
ses <- vector(length=1000)
for (i in 1:1000) {
sim_sample <- sample_n(sim_df, size=100, replace=TRUE)
sim_model <- lm(y ~ x1 + x2, data = sim_sample)  #fitting a linear model instead of nonlinear
ses[i] <- summary(sim_model)$coefficients[2,2]
}
mean(ses)
sigs <- vector(length=1000)
for (i in 1:1000) {
sim_sample <- sample_n(sim_df, size=100, replace=TRUE)
sim_model <- lm(y ~ x1 + x2, data = sim_sample)
sigs[i] <- summary(sim_model)$coefficients[2,4] < 0.05
}
sum(sigs)/1000
sigs <- vector(length=1000)
for (i in 1:1000) {
sim_sample <- sample_n(sim_df, size=100, replace=TRUE)
sim_model <- lm(y ~ x1, data = sim_sample)
sigs[i] <- summary(sim_model)$coefficients[2,4] < 0.05
}
sum(sigs)/1000
sigs <- vector(length=1000)
for (i in 1:1000) {
sim_sample <- sample_n(sim_df, size=100, replace=TRUE)
sim_model <- lm(y ~ x1 + x2, data = sim_sample)
sigs[i] <- summary(sim_model)$coefficients[3,4] < 0.05
}
sum(sigs)/1000
#biased type I error
sigs <- vector(length=1000)
for (i in 1:1000) {
sim_sample <- sample_n(sim_df, size=100, replace=TRUE)
sim_model <- lm(y ~ x2, data = sim_sample)
sigs[i] <- summary(sim_model)$coefficients[2,4] < 0.05
}
sum(sigs)/1000
library(car)
mc_model <- lm(y ~ x1 + x2, data = sim_df)
vif(mc_model)
x <- runif(10000,0,5)    #defining a random variable
#e <- runif(10000,0,1)**2 #error is skewed, not normal
e <- log(runif(10000,0,1))
e <- e - mean(e)         #mean centering the error term
y <- 0.5*x + e
sim_df <- data.frame(x, y, e)
gf_histogram(~ e, data = sim_df)
e <- rnorm(10000,0,1)
y <- 0.5*x + e
sim_df <- data.frame(x, y, e)
gf_histogram(~ e, data = sim_df)
b1s <- vector(length=1000)
for (i in 1:1000) {
sim_sample <- sample_n(sim_df, size=100, replace=TRUE)
sim_model <- lm(y ~ x, data = sim_sample)  #fitting a linear model instead of nonlinear
b1s[i] <- sim_model$coefficients[[2]]
}
#central tendency of b1 estimates
b1s_df <- data.frame(b1s)
gf_histogram(~ b1s, data = b1s_df) %>% gf_vline(., xintercept = 0.5) #true b1 is 0.5
mean(b1s)
sd(b1s)
b1s <- vector(length=1000)
for (i in 1:1000) {
sim_sample <- sample_n(sim_df, size=20, replace=TRUE)
sim_model <- lm(y ~ x, data = sim_sample)
b1s[i] <- sim_model$coefficients[[2]]
}
#central tendency of b1 estimates
b1s_df <- data.frame(b1s)
gf_histogram(~ b1s, data = b1s_df) %>% gf_vline(., xintercept = 0.5) #true b1 is 0.5
mean(b1s)
sd(b1s)
b1s <- vector(length=1000)
for (i in 1:1000) {
sim_sample <- sample_n(sim_df, size=10, replace=TRUE)
sim_model <- lm(y ~ x, data = sim_sample)
b1s[i] <- sim_model$coefficients[[2]]
}
#central tendency of b1 estimates
b1s_df <- data.frame(b1s)
gf_histogram(~ b1s, data = b1s_df) %>% gf_vline(., xintercept = 0.5) #true b1 is 0.5
mean(b1s)
sd(b1s)
x <- runif(10000,0,5)      #defining a random variable
e <- x*rnorm(10000,0,1)    #error gets wider as a function of predictor
y <- 0.5*x + e
sim_df <- data.frame(x, y)
subsample <- sample_n(sim_df, size=100, replace=TRUE)
sub_model <- lm(y ~ x, data = subsample)
subsample$resid <- subsample$y - predict(sub_model, subsample)
gf_point(resid ~ x, data=subsample)
x <- runif(10000,0,5)      #defining a random variable
e <- rnorm(1000,0,1)
#e <- x*rnorm(10000,0,1)    #error gets wider as a function of predictor
y <- 0.5*x + e
sim_df <- data.frame(x, y)
subsample <- sample_n(sim_df, size=100, replace=TRUE)
sub_model <- lm(y ~ x, data = subsample)
subsample$resid <- subsample$y - predict(sub_model, subsample)
gf_point(resid ~ x, data=subsample)
x <- runif(10000,0,5)      #defining a random variable
e <- x*rnorm(10000,0,1)    #error gets wider as a function of predictor
y <- 0.5*x + e
sim_df <- data.frame(x, y)
subsample <- sample_n(sim_df, size=100, replace=TRUE)
sub_model <- lm(y ~ x, data = subsample)
subsample$resid <- subsample$y - predict(sub_model, subsample)
gf_point(resid ~ x, data=subsample)
x <- runif(10000,0,5)      #defining a random variable
e <- x*rnorm(10000,0,1)    #error gets wider as a function of predictor
y <- 0.5*x + e
sim_df <- data.frame(x, y)
subsample <- sample_n(sim_df, size=100, replace=TRUE)
sub_model <- lm(y ~ x, data = subsample)
subsample$resid <- subsample$y - predict(sub_model, subsample)
gf_point(resid ~ x, data=subsample)
b1s <- vector(length=1000)
for (i in 1:1000) {
sim_sample <- sample_n(sim_df, size=10, replace=TRUE)
sim_model <- lm(y ~ x, data = sim_sample)
b1s[i] <- sim_model$coefficients[[2]]
}
#central tendency of b1 estimates
b1s_df <- data.frame(b1s)
gf_histogram(~ b1s, data = b1s_df) %>% gf_vline(., xintercept = 0.5) #true b1 is 0.5
x <- runif(10000,0,5)      #defining a random variable
e <- rnorm(10000,0,1)
#e <- x*rnorm(10000,0,1)    #error gets wider as a function of predictor
y <- 0.5*x + e
sim_df <- data.frame(x, y)
subsample <- sample_n(sim_df, size=100, replace=TRUE)
sub_model <- lm(y ~ x, data = subsample)
subsample$resid <- subsample$y - predict(sub_model, subsample)
gf_point(resid ~ x, data=subsample)
b1s <- vector(length=1000)
for (i in 1:1000) {
sim_sample <- sample_n(sim_df, size=10, replace=TRUE)
sim_model <- lm(y ~ x, data = sim_sample)
b1s[i] <- sim_model$coefficients[[2]]
}
#central tendency of b1 estimates
b1s_df <- data.frame(b1s)
gf_histogram(~ b1s, data = b1s_df) %>% gf_vline(., xintercept = 0.5) %>%#true b1 is 0.5
gf_refine(coord_cartesian(xlim=c(-2,3)))
.libpaths)_
.libpaths()
.libPaths()
library(readr)
final_data <- read_csv("~/Desktop/Pomona/Classes/Stats/projects/life_satisfaction_strategy/final_data.csv")
View(final_data)
range(final_data$ls14)
library(readr)
GSS <- read_csv("~/Downloads/GSS.csv")
View(GSS)
filter(GSS, happt10>8 & happt10<9)
subset <- filter(GSS, happt10>8 & happt10<9)
View(subset)
