{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ada5b93f",
   "metadata": {},
   "source": [
    "statsthinking 14.1 where the name \"regression\" comes from.\n",
    "\n",
    "# Chapter 12 - Quantitative Predictor Models\n",
    "\n",
    "## 12.1 Categorical vs. interval predictors\n",
    "\n",
    "In the previous chapter we figured out how to add an explanatory variable to a model. We explained thumb length using sex, and noticed how doing so reduced the error in our model and made our predictions less accurate. \n",
    "\n",
    "Sex is a categorical variable, with two easily distinguishable groups and separate means for each of the groups that we can model with b<sub>0</sub> and b<sub>1</sub> in the general linear model equation. But what about a different sort of variable, like height? How do we add in continuous variables like this that don't have clearly distinguishable group means?\n",
    "\n",
    "One option is to create categorical groups out of this data. We could say anyone who is shorter than the mean height is short, and anyone taller than the mean height is tall. That way we now have a categorical variable with two levels, \"short\" and \"tall\", and we can use it in a model the same way we used Sex. \n",
    "\n",
    "There are some problems with this approach, however. First, remember that the definition of a categorical variable is one where there is no quantitative relationship between the different categories. That holds true for a variable like Sex - it doesn't make sense to say the \"female\" level is any more or less than the \"male\" level. But for categories like \"short\" and \"tall\", there is an inherent quantitative relationship between them. \"Short\" means less than \"tall\" by definition. So forcing Height to be a categorical variable is mispecifying the meaning of Height.\n",
    "\n",
    "The other problem is that forcing all values in Height to be in one category or another, we are inherently throwing away information that that variable can give us for the purposes of modeling the data generation process. Less information means less flexible models and worse predictions. We'll explore this is greater detail later in the chapter.\n",
    "\n",
    "So letâ€™s consider another approach for using Height as an explanatory variable in a statistical model: instead of using height in inches to divide students into groups (e.g., short or tall), what if we just model height as a continuous variable? Earlier in the course we learned how to visualize this approach in a scatterplot. In this chapter we will figure out how to extend our models to accommodate quantitative explanatory variables.\n",
    "\n",
    "The models we develop in this chapter are a special type usually called **regression models**. Before we start, though, note that the core ideas behind these new models are exactly the same as those we have developed for group-based models. A model still yields a single predicted score for each observation, based on some mathematical function of the explanatory variable.\n",
    "\n",
    "Further, in regression models, we still use residuals (the difference between the predicted and observed score) to measure error around the model. We also still use the sum of squared deviations from the model predictions as a measure of model fit. And, we still use PRE to indicate the proportion reduction in error of the regression model compared with the empty model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cebc331",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
