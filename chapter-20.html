

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Chapter 20 - Traditional Statistical Tools &#8212; Pomona Psych 158 Online Textbook</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapter-20';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Pomona College Psych 158 Online Textbook
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Unit 1 Describing Data</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-1.ipynb">Chapter 1 - Introduction to Statistical Thinking</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-2.ipynb">Chapter 2 - What are Data</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-3.ipynb">Chapter 3 - Organizing Data</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-4.ipynb">Chapter 4 - Cleaning Data</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-5.ipynb">Chapter 5 - Describing Data</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-6.ipynb">Chapter 6 - Variation in Multiple Variables</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-7.ipynb">Chapter 7 - Principles of Data Visualization</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Unit 2 - Modeling Data</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-8.ipynb">Chapter 8 - Where Data Come From</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-9.ipynb">Chapter 9 - Modeling the Data Generation Process</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-10.ipynb">Chapter 10 - Quantifying Model Error</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-11.ipynb">Chapter 11 - Adding an Explanatory Variable</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-12.ipynb">Chapter 12 - Quantitative Predictor Models</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-13.ipynb">Chapter 13 - Multivariable Models</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-14.ipynb">Chapter 14 - Models with Moderation</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Unit 3 - Evaluating Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-15.ipynb">Chapter 15 - Estimating Populations</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-16.ipynb">Chapter 16 - Significance Testing</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-17.ipynb">Chapter 17 - Significance Testing Whole Models</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-18.ipynb">Chapter 18 - Effect Sizes &amp; Statistical Power</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-19.ipynb">Chapter 19 - Bias due to Improper Model Building</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-20.ipynb">Chapter 20 - Alternate Approaches - Traditional Statistical Tools</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-21.ipynb">Chapter 21 - Alternative Approaches - Bayesian Statistics</a></li>
<li class="toctree-l1"><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-22.ipynb">Chapter 22 - Lying with Statistics</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/smburns47/Psyc158/main?urlpath=tree/chapter-20.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onBinder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="initThebeSBT()"
  class="btn btn-sm btn-launch-thebe dropdown-item"
  title="Launch Thebe"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="btn__text-container">Live Code</span>
</button>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/smburns47/Psyc158" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/smburns47/Psyc158/issues/new?title=Issue%20on%20page%20%2Fchapter-20.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/chapter-20.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Chapter 20 - Traditional Statistical Tools</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#one-sample-t-test">20.1 One-sample t-test</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#independent-samples-t-test">20.2 Independent-samples t-test</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#one-way-anova">20.3 One-way ANOVA</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#factorial-anova">20.4 Factorial ANOVA</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#correlation-multiple-regression">20.5 Correlation &amp; multiple regression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#chi-square">20.6 Chi-square</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#repeated-measures-tests">20.7 Repeated measures tests</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary-of-tests">20.8 Summary of tests</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#chapter-summary">Chapter summary</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <p><a class="reference external" href="https://www.shannonmburns.com/Psyc158/intro.html">Back to Table of Contents</a></p>
<p><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-19.ipynb">Previous: Chapter 19 - Model Bias</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Run this first so it&#39;s ready by the time you need it</span>
<span class="nf">install.packages</span><span class="p">(</span><span class="s">&quot;dplyr&quot;</span><span class="p">)</span>
<span class="nf">install.packages</span><span class="p">(</span><span class="s">&quot;ggformula&quot;</span><span class="p">)</span>
<span class="nf">install.packages</span><span class="p">(</span><span class="s">&quot;supernova&quot;</span><span class="p">)</span>
<span class="nf">install.packages</span><span class="p">(</span><span class="s">&quot;interactions&quot;</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">dplyr</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">ggformula</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">supernova</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">interactions</span><span class="p">)</span>

<span class="n">trackscores</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">read.csv</span><span class="p">(</span><span class="s">&quot;https://raw.githubusercontent.com/smburns47/Psyc158/main/trackscores.csv&quot;</span><span class="p">)</span>
<span class="n">trackscores</span><span class="o">$</span><span class="n">track_training</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">as.character</span><span class="p">(</span><span class="n">trackscores</span><span class="o">$</span><span class="n">track_training</span><span class="p">)</span>
<span class="n">trackscores</span><span class="o">$</span><span class="n">weight_training</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">as.character</span><span class="p">(</span><span class="n">trackscores</span><span class="o">$</span><span class="n">weight_training</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section class="tex2jax_ignore mathjax_ignore" id="chapter-20-traditional-statistical-tools">
<h1>Chapter 20 - Traditional Statistical Tools<a class="headerlink" href="#chapter-20-traditional-statistical-tools" title="Permalink to this heading">#</a></h1>
<p>In this course you have spent a long time learning about how to make predictions and do inference with the general linear model. This actually makes you rather unique in terms of how you’re getting started with statistics. Most students instead learn an assortment of different statistical procedures like the t-test, ANOVA, chi-square, etc. as their introduction to data analysis. Indeed many practicing researchers also use these tools exclusively.</p>
<p>So why learn the GLM at all if not everyone uses it? There are two pedagogical reasons for why this course emphasized this method instead of the traditional content:</p>
<ol class="arabic simple">
<li><p><strong>Traditional tools require learning how to do hypothesis testing first</strong> - Traditional methods fundamentally depend on Null Hypothesis Significance Testing. They start with defining a null hypothesis and cannot be interpreted without computing a t/F score and finding a p-value. This means to learn how to use these tools, students first have to learn about sampling distributions and significance testing. This is a rather abstract thing to learn first in one’s statistics journey and impedes understanding for many people. This leads them to using intellectual short cuts like “only care about p &lt; 0.05” despite the dangers of overrelying on that number.</p></li>
<li><p><strong>Traditional tools are more variable, harder to remember</strong> - When first starting out, the list of all the common statistical tools is often daunting. They are calculated all different ways, with different names, applied to different situations, and it’s hard to remember what goes where. In contrast, the GLM is ultimatly one tool: <span class="math notranslate nohighlight">\(Y_i = b_0 + b_1X_i + e_i\)</span>. How many predictors you add to the equation and how you interpret the coefficients varies depending on your use situation, but just knowing about this one equation gets you 80% of the way there. This makes it a better starting point to build conceptual understanding.</p></li>
</ol>
<p>Despite the advantages of the GLM however, many people still use the traditional tools. Thus, it is good for you to be able to identify them and understand how they map onto what you have learned with the GLM. Ultimately, the GLM and these tools will give you the same answer and you can choose which you prefer in your own research. Knowing both will enable you to read and understand research reports no matter what method the authors used. You may even find that most of these tools build on concepts you’ve already learned. They’re just a different way of showing that information.</p>
<section id="one-sample-t-test">
<h2>20.1 One-sample t-test<a class="headerlink" href="#one-sample-t-test" title="Permalink to this heading">#</a></h2>
<p>Previously in chapter 11, we were introduced to the idea of a t-test. To explain it in more depth, let’s start with the <strong>one-sample t-test</strong>.</p>
<p>Let’s say you are a track coach and you’re assessing the progress of your runners’ training. They all recorded their best times for running the 400m when they initially joined the team. Now after a month of training with track drills, you want to know if they, as a group, have improved.</p>
<p>Here is some data from your team. We will filter it down to just those scores at tryouts and 1 month later at the first meet, then calculate their change in running times. Negative scores mean they got faster (less time to complete the 100m), positive scores mean they ran slower.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1">#take a look at how this dataset was organized</span>
<span class="nf">head</span><span class="p">(</span><span class="n">trackscores</span><span class="p">)</span>

<span class="n">tryout_scores</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">filter</span><span class="p">(</span><span class="n">trackscores</span><span class="p">,</span><span class="w"> </span><span class="n">session</span><span class="o">==</span><span class="s">&quot;tryouts&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">condition</span><span class="o">==</span><span class="s">&quot;track-training&quot;</span><span class="p">)</span>
<span class="n">meet1_scores</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">filter</span><span class="p">(</span><span class="n">trackscores</span><span class="p">,</span><span class="w"> </span><span class="n">session</span><span class="o">==</span><span class="s">&quot;meet1&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">condition</span><span class="o">==</span><span class="s">&quot;track-training&quot;</span><span class="p">)</span>

<span class="n">change_scores</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">meet1_scores</span><span class="o">$</span><span class="n">time</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">tryout_scores</span><span class="o">$</span><span class="n">time</span>
</pre></div>
</div>
</div>
</div>
<p>If our question is restricted to just our team of runners and no one else, we can figure out their improvement really easily. We simply find the mean of their change scores:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">mean</span><span class="p">(</span><span class="n">change_scores</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Great! This number means that, on average, our team ran faster than before after training for a month. If we only care about evaluating our current team, we can stop here and don’t need to use any more statistics.</p>
<p>But let’s say our question goes beyond just our team. If we were to recruit new runners the following year, would they also improve their scores with this training regimen? Is it good enough to use for everyone? Now we are hypothesizing about data we don’t have. At this point we need inferential statistics, and a one-sample t-test can help.</p>
<p>A one-sample t-test answers a particular kind of question: is the mean of some data <span class="math notranslate nohighlight">\(\bar{X}\)</span> likely or unlikely to be from a population with a specific <span class="math notranslate nohighlight">\(\mu\)</span>? In other words, if we think the population <span class="math notranslate nohighlight">\(\mu\)</span> is a particular value and our data sample is drawn from that population, is it reasonable or surprising to find that our sample’s mean is the value we measured?</p>
<p>In the case of our specific example: is our data sample likely to happen even in a population of runners who on average didn’t improve?</p>
<p>In order to do a one-sample t-test to answer this question, we first need to set down our idea about what <span class="math notranslate nohighlight">\(\mu\)</span> should be. This is specifying the null hypothesis. For our particular example, the data we are evaluating are improvements in running time. We want to know if these data came from a population of scores where there’s no improvement. In such a population some people might run a bit faster than their initial time, some a bit slower, but on average there’s no change. Thus, to set our null hypothesis:</p>
<div class="math notranslate nohighlight">
\[H_0: \mu = 0\]</div>
<p>When we calculated our data sample earlier, it was -0.349, not 0. Does that mean we can conclude these runners did not come from a population of no improvement? Not necessarily. Remember, due to random sampling, it is frequently possible to get a sample mean that is not the same value as the population mean:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">set.seed</span><span class="p">(</span><span class="m">10</span><span class="p">)</span>
<span class="n">sim_sample</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rnorm</span><span class="p">(</span><span class="m">10</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="o">=</span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="o">=</span><span class="m">1</span><span class="p">)</span><span class="w"> </span><span class="c1">#random sample of 10 scores from population with mean 0</span>
<span class="nf">mean</span><span class="p">(</span><span class="n">sim_sample</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Thus we need a way of refining our question: given a population <span class="math notranslate nohighlight">\(\mu\)</span> <em>and</em> an expected variation among samples from that population, is our sample really surprising or not?</p>
<p>Enter the t-value. It is a way of scaling the difference between a sample and hypothesized population mean by the standard error of that population. For a one-sample t-test, this is calculated as:</p>
<div class="math notranslate nohighlight">
\[t = \frac{\bar{X} - \mu}{SEM}\]</div>
<p>If you recall from chapter 15, SEM in turn is calculated as:</p>
<div class="math notranslate nohighlight">
\[SEM = \frac{\hat{σ}}{\sqrt{N}}\]</div>
<p>All this together means that a t-value will be larger when there’s a bigger difference between our sample mean and the hypothesized population mean, or when the standard error is smaller.</p>
<p>The type of t-score we can get falls somewhere in the t distribution that we first encountered in chapter 16:</p>
<img src="images/ch16-tdist.png" width="600">
<p>The cumulative probability outside of our t-value is the corresponding p-value for that t-score. The smaller the p-value, the more surprising it is to get a t-value like ours when the true t in the population is 0. If the associated p-value is &lt;0.05, we would decide it’s so surprising that our sample probably came from a different sort of population instead - one with some alternative <span class="math notranslate nohighlight">\(\mu\)</span> that is not 0.</p>
<p>R provides us with a built-in function to quickly compute a one sample t-test:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">t.test</span><span class="p">(</span><span class="n">change_scores</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The output of this function gives us information about the calculated t-score (-1.9294), the degrees of freedom of the test (9), and the p-value (0.08575). It also gives us a 95% CI for our estimate of the mean, [-0.758, 0.060]. Note that a t-value can be positive or negative, signifying if our sample mean is higher or lower than the hypothesized population mean.</p>
<p>Based on these results, there is not enough evidence to reject the null hypothesis that our training regimen results in no improvement. In APA format, we would write these results as “There was no significant improvement in running time for this sample of runners (<em>t(9)</em> = -1.93, <em>p</em> = 0.086).”</p>
<p>The different parts of doing a t-test (calculating a mean, null hypothesis, standard error, and p-value) are all concepts you’ve learned before. For this reason, a t-test is actually just another way of getting to the same answer as we previously did with the general linear model. Check out the t and p values in the model output below, and compare them to the results of the above t-test:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">summary</span><span class="p">(</span><span class="nf">lm</span><span class="p">(</span><span class="n">change_scores</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="kc">NULL</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>In the null model of the GLM framework, we are estimating the sample mean as <span class="math notranslate nohighlight">\(b_0\)</span> and evaluating if it is significantly different from 0. In a one-sample t-test, we are evaluating whether a sample mean <span class="math notranslate nohighlight">\(\bar{X}\)</span> is significantly different from the null hypothesis <span class="math notranslate nohighlight">\(\mu = 0\)</span>. These are the exact same question, just posed different ways. Thus, you can get the same result using a null model form of the GLM or the one-sample t-test!</p>
<p>However, we should also point out that in the null model, the significance of <span class="math notranslate nohighlight">\(b_0\)</span> is specifically compared in the context of a null hypothesis where <span class="math notranslate nohighlight">\(\beta_0 = 0\)</span>. In the one-sample t-test, we can be more general that this. We don’t have to restrict ourselves to a null hypothesis of 0. For instance, let’s imagine that instead of running improvement, we are interested in whether our team’s new running times are significantly better than the <a class="reference external" href="https://www.ncsasports.org/mens-track-and-field/scholarship-standards">Division III track and field recruiting cut off</a> of 51.76. First we calculate the mean of everyone’s new running times:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">mean</span><span class="p">(</span><span class="n">meet1_scores</span><span class="o">$</span><span class="n">time</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Then we specify a null hypothesis:</p>
<div class="math notranslate nohighlight">
\[H_0: \mu = 51.76\]</div>
<p>This is a different null hypothesis than before. Now, we are wondering if our sample is likely to come from DIII track and field athletes, or if we should conclude they come from an even faster population.</p>
<p>Then we run the t-test to see if our sample mean is significantly different from this hypothesized population mean. To specify a null hypothesis in a t-test that is different than 0, add the <code class="docutils literal notranslate"><span class="pre">mu=</span></code> argument to the <code class="docutils literal notranslate"><span class="pre">t.test()</span></code> with this specific null hypothesis value.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">t.test</span><span class="p">(</span><span class="n">meet1_scores</span><span class="o">$</span><span class="n">time</span><span class="p">,</span><span class="w"> </span><span class="n">mu</span><span class="o">=</span><span class="m">51.76</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Based on these results, our sample mean of 48.354 would be very unusual if it were drawn from a population with <span class="math notranslate nohighlight">\(\mu = 51.76\)</span> (p &lt; 0.001). We reject this null hypothesis in favor of the alternative hypothesis that our team is from a faster population.</p>
</section>
<section id="independent-samples-t-test">
<h2>20.2 Independent-samples t-test<a class="headerlink" href="#independent-samples-t-test" title="Permalink to this heading">#</a></h2>
<p>A one sample t-test is used when you have one group of data and want to understand how likely it is that that one group came from a particular population. If you have two separate groups of data and want to be able to distingush them from each other, this calls for a different kind of t-test called an <strong>independent samples t-test</strong> or <strong>two-sample t-test</strong>.</p>
<p>Let’s say you’re still the track coach, but this time you want to compare how two different kinds of training impact your athletes. This time, you have half the team run track drills for a month and half the team do weights in the gym. Afterwards, you assess their running time on the 400m at their first meet. In this situation you no longer have one group of data like last time. You have two groups who went through different experiences that might make them different from each other.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">track_training</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">filter</span><span class="p">(</span><span class="n">trackscores</span><span class="p">,</span><span class="w"> </span><span class="n">session</span><span class="o">==</span><span class="s">&quot;meet1&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">condition</span><span class="o">==</span><span class="s">&quot;track-training&quot;</span><span class="p">)</span>
<span class="n">weight_training</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">filter</span><span class="p">(</span><span class="n">trackscores</span><span class="p">,</span><span class="w"> </span><span class="n">session</span><span class="o">==</span><span class="s">&quot;meet1&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">condition</span><span class="o">==</span><span class="s">&quot;weight-training&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>An independent samples t-test answers the question “are these two groups likely drawn from the same population?” The null hypothesis of this question would be:</p>
<div class="math notranslate nohighlight">
\[H_0: \mu_1 = \mu_2\]</div>
<p>Where <span class="math notranslate nohighlight">\(\mu_1\)</span> is the population from which group 1 came, and <span class="math notranslate nohighlight">\(\mu_2\)</span> is the population from which group 2 came. The alternative hypothesis, then, is that they come from different populations.</p>
<p>An independent samples t-score is calculated a bit differently than a one-sample t-score. This one comes out to:</p>
<div class="math notranslate nohighlight">
\[ t = \frac{\bar{X}_1 - \bar{X}_2}{s_p\sqrt{\frac{1}{n_1} + \frac{1}{n_2}}} \]</div>
<p>where <span class="math notranslate nohighlight">\(s_p\)</span> stands for the <em>pooled</em> standard deviation, a way of combining the standard deviations of two samples:</p>
<div class="math notranslate nohighlight">
\[s_p = \sqrt{\frac{(n_1 - 1)s^2_1 + (n_2 - 1)s^2_2}{n_1 + n_2 + 2}} \]</div>
<p>While this equation is more complicated, in general this t-score gets larger based on the same factors as the one-sample t-test. You will get a larger t-score, and thus more likely to reject the null hypothesis, if there is a large difference between the group means <em>or</em> if the sample sizes are large.</p>
<p>In R we can use the same <code class="docutils literal notranslate"><span class="pre">t.test()</span></code> function to do an independent-samples t-test. We just need to include more arguments. Specifically, we need to pass the separate groups to compare as separate vectors, and then add a <code class="docutils literal notranslate"><span class="pre">var.equal=</span></code> flag to tell this function to use the pooled variance.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">t.test</span><span class="p">(</span><span class="n">track_training</span><span class="o">$</span><span class="n">time</span><span class="p">,</span><span class="w"> </span><span class="n">weight_training</span><span class="o">$</span><span class="n">time</span><span class="p">,</span><span class="w"> </span><span class="n">var.equal</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Based on this result, what would you conclude about which populations each group likely came from?</p>
<p>Again, it is possible to get this same result using the GLM approach we already know. However we have to reshape our data a bit in order to make this possible. In the <code class="docutils literal notranslate"><span class="pre">t.test()</span></code> command above we wanted to compare values on the outcome variable for the two different groups, so we needed to divide the data in this variable into two separate vectors. To use <code class="docutils literal notranslate"><span class="pre">lm()</span></code>, we don’t separate our data into different datasets. We merely include another variable that stores information about which group is which.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1">#filtering to every time score during meet1, for track-training or weight-training athletes</span>
<span class="n">meet1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">filter</span><span class="p">(</span><span class="n">trackscores</span><span class="p">,</span><span class="w"> </span><span class="n">session</span><span class="o">==</span><span class="s">&#39;meet1&#39;</span><span class="p">,</span>
<span class="w">                       </span><span class="p">(</span><span class="n">condition</span><span class="o">==</span><span class="s">&#39;track-training&#39;</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">condition</span><span class="o">==</span><span class="s">&#39;weight-training&#39;</span><span class="p">))</span>

<span class="c1">#fitting glm version of test</span>
<span class="nf">summary</span><span class="p">(</span><span class="nf">lm</span><span class="p">(</span><span class="n">time</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">condition</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">meet1</span><span class="p">))</span>

<span class="c1">#visualizing group differences</span>
<span class="nf">gf_jitter</span><span class="p">(</span><span class="n">time</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">condition</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">meet1</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="o">=</span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">~</span><span class="n">condition</span><span class="p">,</span><span class="w"> </span><span class="n">width</span><span class="o">=</span><span class="m">0.1</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span>
<span class="w">    </span><span class="nf">gf_summary</span><span class="p">(</span><span class="n">fun.data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;mean_cl_boot&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&#39;black&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="one-way-anova">
<h2>20.3 One-way ANOVA<a class="headerlink" href="#one-way-anova" title="Permalink to this heading">#</a></h2>
<p>T-tests allow you to investigate differences in means between a population and one group of data, or two separate groups. Beyond that, you might encounter a situation where you want to investigate differences between more than two groups. E.g., instead of comparing just the athletes who did track training vs. weight training, you also have athletes who did neither type or both types of training.</p>
<p>There’s no t-test that helps you analyze more than two groups. Instead, we need to expand into a different kind of test known as a <strong>one-way ANOVA</strong>.</p>
<p>To start, we recognize that we’re interested in comparing the average 400m running time for the 4 different training conditions. In that sense, we’re still hypothesizing about differences in means, but between several groups. Specifically, it would be pretty uninteresting if no type of training made any difference in running time and all athletes were from the same population. Thus, our null hypothesis is:</p>
<div class="math notranslate nohighlight">
\[H_0: \mu_1 = \mu_2 = \mu_3 = \mu_4\]</div>
<p>Where each <span class="math notranslate nohighlight">\(\mu\)</span> is the population from which that group number came. In contrast, the alternative hypothesis is that <em>at least one</em> of the four different training conditions results in different running times. We’re not trying to predict which group(s) is different from which other group(s), just that at least one of those equal signs in the null hypothesis is not true.</p>
<p>Because there are many different ways the null hypothesis could be false (1 =/= 3, 2 =/=3 &amp; 4, etc.), this null hypothesis isn’t possible to test in the t-test framework. There isn’t one group difference to compare to one population parameter. Instead we use an ANOVA procedure, which stands for Analysis of Variance.</p>
<p>The way this works is by looking at variation in data and figuring out how much variation is within a group of data, vs. between different groups.</p>
<img src="images/ch20-btwn-within.png" width="800">
<p>To quantify variation, we’ve used the idea of sum of squares before. We can use it again here to calculate new* kinds of sum of squares to represent, instead of deviations between data and model predictions, deviations between groups or within groups. We’ll denote this as <span class="math notranslate nohighlight">\(SS_w\)</span> for the within-group variation, where <span class="math notranslate nohighlight">\(\bar{Y}_g\)</span> is the mean of some group G:</p>
<div class="math notranslate nohighlight">
\[SS_w = \sum_{i=1}^{N}(Y_i-\bar{Y}_G)^2\]</div>
<p>And here is <span class="math notranslate nohighlight">\(SS_b\)</span> for the between-groups variation, where <span class="math notranslate nohighlight">\(\bar{Y}\)</span> is the mean of all data regardless of group (the Grand Mean):</p>
<div class="math notranslate nohighlight">
\[SS_b = \sum_{i=1}^{N}(\bar{Y}_G - \bar{Y})^2\]</div>
<p>Now that we’ve defined these different types of sum of squares, we can ask a specific mathematical question: is there more variation between the groups of data than within a group? Are the differences between individual scores because of which group they belong to, or just randomness? A ratio is a good way to represent this question:</p>
<div class="math notranslate nohighlight">
\[\frac{SS_b}{SS_w}\]</div>
<p>But wait, if we’re calculating sum of squares then we know it’s problematic to not consider the size of our dataset. Thus we should convert these values to mean squared error by dividing SS by the degrees of freedom. As usual, the degrees of freedom corresponds to the number of ways data can vary once we have some existing information about it. For the within-groups variability, what we’re calculating is the variation of the individual observations (N data points) around the group means (all the <span class="math notranslate nohighlight">\(\bar{Y}_G\)</span> estimates). In contrast, for the between groups variability, we’re interested in the variation of the group means (G data points) around the Grand Mean (one <span class="math notranslate nohighlight">\(\bar{Y}\)</span> estimate). Therefore, the degrees of freedom here are:</p>
<div class="math notranslate nohighlight">
\[df_b = G - 1\]</div>
<div class="math notranslate nohighlight">
\[df_w = N - G\]</div>
<p>The ratio of mean squared differences then is:</p>
<div class="math notranslate nohighlight">
\[\frac{SS_b / df_b}{SS_w / df_w} = \frac{MS_b}{MS_w}\]</div>
<p>This ratio has a specific name: it is the <strong>F-ratio</strong> or the <strong>F-statistic</strong> (<a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-17.ipynb#scrollTo=509057e3">sound familiar?</a>).</p>
<p>That’s all a one-way ANOVA does: it calculates an F-statistic to compare between to within-group variation. If the value of this F-statistic is sufficiently large, that means the differences in the group means are so large that we’d be very surprised to hear they were actually sampled from the same population. We’d reject the null hypothesis in favor of an alternative, that at least one came from a different population.</p>
<p>That brings us to doing a one-way ANOVA test in R. There are a couple different implementations of ANOVA tests in R. The most basic is built into base R, called <code class="docutils literal notranslate"><span class="pre">aov()</span></code>. To use this one, you no longer need to save the data for the different groups into different vectors - we can keep it in one dataset like with a GLM model and simply pass a formula to ask how the outcome variable varies as a function of group.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1">#choosing all running times at meet1, regardless of condition</span>
<span class="n">meet1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">filter</span><span class="p">(</span><span class="n">trackscores</span><span class="p">,</span><span class="w"> </span><span class="n">session</span><span class="o">==</span><span class="s">&#39;meet1&#39;</span><span class="p">)</span>

<span class="c1">#running one-way ANOVA test</span>
<span class="n">anova_results</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">aov</span><span class="p">(</span><span class="n">time</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">condition</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">meet1</span><span class="p">)</span>
<span class="n">anova_results</span>

<span class="c1">#visualizing group differences</span>
<span class="nf">gf_jitter</span><span class="p">(</span><span class="n">time</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">condition</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">meet1</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="o">=</span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">~</span><span class="n">condition</span><span class="p">,</span><span class="w"> </span><span class="n">width</span><span class="o">=</span><span class="m">0.1</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span>
<span class="w">    </span><span class="nf">gf_summary</span><span class="p">(</span><span class="n">fun.data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;mean_cl_boot&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&#39;black&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The output of this code tells you <span class="math notranslate nohighlight">\(SS_b\)</span> (Sum of Squares in the ‘condition’ column) and <span class="math notranslate nohighlight">\(SS_w\)</span> (Sum of Squares in the ‘Residuals’ column). To get the corresponding F-statistic and p-value, wrap this command in the <code class="docutils literal notranslate"><span class="pre">summary()</span></code> function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">summary</span><span class="p">(</span><span class="n">anova_results</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Since this p-value is &lt;0.05, we’d reject the null hypothesis that all groups of athletes come from the same population. At least one of the group means is sufficiently different from at least one other that we decide there are different populations involved here - meaning, type of training matters for running time. In APA format, we’d write this as “there was a significant effect of training type on running time <em>F</em>(3,36) = 7.035, <em>p</em> &lt; 0.001.”</p>
<p>Now, at this moment we should pause so I can let you know that I actually lied to you earlier. <span class="math notranslate nohighlight">\(SS_b\)</span> and <span class="math notranslate nohighlight">\(SS_w\)</span> aren’t new kinds of sum of squares at all. To see what I mean, here’s the <span class="math notranslate nohighlight">\(SS_{model}\)</span> and <span class="math notranslate nohighlight">\(SS_{error}\)</span> from a GLM with the same formula:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">glm_results</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">time</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">condition</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">meet1</span><span class="p">)</span>
<span class="nf">supernova</span><span class="p">(</span><span class="n">glm_results</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><span class="math notranslate nohighlight">\(SS_b\)</span> is the exact same value as <span class="math notranslate nohighlight">\(SS_{model}\)</span>, just with a different name. Both refer to the amount of variation explained by this grouping variable. Likewise, <span class="math notranslate nohighlight">\(SS_w\)</span> is the same as <span class="math notranslate nohighlight">\(SS_{error}\)</span>, the amount of variation left unexplained. The F-statistic and p-value are also the same. That’s why this is called an ANOVA table - it’s the results of an ANOVA test. If we output the summary of a GLM model with <code class="docutils literal notranslate"><span class="pre">condition</span></code> predicting <code class="docutils literal notranslate"><span class="pre">time</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">summary</span><span class="p">(</span><span class="n">glm_results</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>That F-statistic and p-value for the significance of the whole model is also the same. Thus, a one-way ANOVA test is the exact same as testing a whole GLM model with multiple categorical predictors.</p>
<p>Now there are some differences between a one-way ANOVA and GLM on the other kinds of information you get from the model. Specifically, the significance of differences between <em>particular</em> pairs of groups. At baseline, an ANOVA test can’t tell you anything about this. It only tests the null hypothesis that all groups are the same. Any one pair being different results in rejecting the null hypothesis, but you don’t know which pair(s) of groups were different. To get this answer, you need to perform an independent-samples t-test on each unique pair. Because this involves many tests, you also have to correct for multiple comparisons.</p>
<p>In R, you can do this with the function <code class="docutils literal notranslate"><span class="pre">pairwise()</span></code> in the <code class="docutils literal notranslate"><span class="pre">supernova</span></code> package, which takes an object holding the results of an ANOVA test and returns the significance of the difference between every possible pair of groups:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">pairwise</span><span class="p">(</span><span class="n">anova_results</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The method of multiple comparison correction that <code class="docutils literal notranslate"><span class="pre">pairwise()</span></code> is using is called Tukey’s Honestly Significance Differences, which adjusts the calculated p-values up rather than pulling down the critical p-value.</p>
<p>Now compare these numbers to those in the summary report of the GLM model (where “both-training” is the reference group because it is first in the alphabet). For instance, look at the difference between the “no-training” and “both-training” conditions here, and then look at the estimate of the effect of “no-training” in the GLM output. Both of these numbers are the same (2.038), indicating that both methods are finding the difference in means between the “both-training” condition and the “no-training” condition. However, the p-values for these lines are different.</p>
<p>Why is that? The reason is, with the GLM model you don’t need to do multiple comparisons correction. This is because a multiple regression is just one test. It calculates the standard error of each coefficient at once, in the context of the other predictors. This means it’s essentially already correcting for the fact that there are other coefficients to test. Further, it is only doing this correction for 3 comparisons with the reference group (“both-training” against the other three).</p>
<p>In contrast, with the pairwise tests after the ANOVA, these are all done independently on separate subgroups of data. In addition, all 6 possible pairwise comparisons are done. With more comparisons, that means you have to correct the p-value by more in order to keep the family-wise error rate at <span class="math notranslate nohighlight">\(\alpha = 0.05\)</span>. With more correction, it is harder to find any one comparison as significant. This is why the comparison between “both-training” and “track-training” is significant in the GLM (effect of “track-training”, p = 0.0133) but not significant in the pairwise table of the ANOVA results (p = 0.0614). However, this is also why the pairwise table has comparisons for conditions like “weight-training” and “track-training”, while the GLM doesn’t. To get that result with a GLM approach, one of those conditions would need to be treated as the reference group.</p>
<p>For this multiple comparisons reason, it is often better to use a GLM than a one-way ANOVA.</p>
</section>
<section id="factorial-anova">
<h2>20.4 Factorial ANOVA<a class="headerlink" href="#factorial-anova" title="Permalink to this heading">#</a></h2>
<p>Of the traditional tools we’ve covered so far in this chapter, you can probably detect a general trend. So far we’ve looked at a fairly simple experimental design: each person falls into only one of several groups, and we want to know whether these groups have different means on some outcome variable. This assumes that there is only one variable that matters for differences in the outcome value - which of these groups someone is in.</p>
<p>But in the multiple regression version of the GLM framework, we learned that multiple different predictor variables can have separate effects on an outcome. They can even interact with each other, such that the effect of one predictor changes as a function of the value of another predictor. This might be a better way of understanding our athlete data - instead of four different categories of training regimens, maybe there is a more general effect of track-training and of weight-training that combine in order to produce someone’s running time. Being in the “both-training” condition just means being a part of both of these general groups, instead of its own unique category.</p>
<p>In the ANOVA approach to statistics, taking into account the effect of multiple grouping variables is called <strong>factorial ANOVA</strong>. Sometimes it is also called something like two-way ANOVA (which means two separate predictor variables) or 2x2 ANOVA (meaning there are two levels in the first predictor and two levels in the second). Like the one-way ANOVA, factorial ANOVA is a method of comparing group means to see if they come from the same population. So a sensible place to start would be to be explicit about a null hypothesis for these means. However, the fact that the different training groups are made of combinations of multiple variables means there are several different means that one might be interested. To see this, let’s start by thinking about all the different sample means that we can calculate for this kind of design:</p>
<p>Firstly, there’s the obvious idea that we might be interested in this table of group means for our athletes at their first meet:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-center"><p></p></th>
<th class="head text-center"><p>No weight training</p></th>
<th class="head text-center"><p>Weight training</p></th>
<th class="head text-center"><p>Any weight training</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><strong>No track training</strong></p></td>
<td class="text-center"><p>49.071</p></td>
<td class="text-center"><p>47.323</p></td>
<td class="text-center"><p>48.047</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><strong>Track training</strong></p></td>
<td class="text-center"><p>48.354</p></td>
<td class="text-center"><p>47.134</p></td>
<td class="text-center"><p>47.774</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p><strong>Any track training</strong></p></td>
<td class="text-center"><p>48.563</p></td>
<td class="text-center"><p>47.229</p></td>
<td class="text-center"><p>47.969</p></td>
</tr>
</tbody>
</table>
<p>In this table, the number in each cell stands for the group mean with that combination of track training type (row) and weight training type (column). The values in the last row are the means of each weight training group regardless of what type of track training they did. The values in the last column are the means of each track training group regardless of what type of weight training they did - aka the <strong>marginal means</strong>. The bottom right cell holds the Grand Mean, or the mean running time of everyone regardless of their value on any training variable.</p>
<p>These are all group means, which are statistical estimates. That means there are population parameter versions of these values that our estimates came from. We can express our table above with those values instead:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-center"><p></p></th>
<th class="head text-center"><p>No weight training</p></th>
<th class="head text-center"><p>Weight training</p></th>
<th class="head text-center"><p>Any weight training</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><strong>No track training</strong></p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\mu_{11}\)</span></p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\mu_{12}\)</span></p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\mu_{1.}\)</span></p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><strong>Track training</strong></p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\mu_{21}\)</span></p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\mu_{22}\)</span></p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\mu_{2.}\)</span></p></td>
</tr>
<tr class="row-even"><td class="text-center"><p><strong>Any track training</strong></p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\mu_{.1}\)</span></p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\mu_{.2}\)</span></p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\mu_{..}\)</span></p></td>
</tr>
</tbody>
</table>
<p>We have a bunch of <span class="math notranslate nohighlight">\(\mu\)</span> values with different subtexts. <span class="math notranslate nohighlight">\(\mu_{11}\)</span> means the population mean for the group in the first value of track training type and first value of the weight training type. <span class="math notranslate nohighlight">\(\mu_{12}\)</span> would be the population mean for the group in the first value of track training type and second value of the weight training type, and so on. A dot in the notation means any value for that variable.</p>
<p>Now that we have this notation, it is straightforward to formulate and express some null hypotheses. Let’s suppose that the goal is to find out two things: firstly, does track training have any effect on running time? Secondly, does weight training have any effect on running time? Formally, we write down our null hypotheses in terms of the equality of marginal means. We also create a separate null hypothesis for each predictor we are interested in:</p>
<p>row means are the same: <span class="math notranslate nohighlight">\(H_0: \mu_{1.} = \mu_{2.}\)</span></p>
<p>column means are the same: <span class="math notranslate nohighlight">\(H_0: \mu_{.1} = \mu_{.2}\)</span></p>
<p>Since this is a type of ANOVA, to test these hypotheses we investigate the within and between sum of squares for each of these hypotheses. At this point, this is done the same way as a one-way ANOVA (which, in the case of just two group means like here, also reduces to being the same thing as an independent samples t-test - it’s all connected!). The one-way ANOVA is applied for the effect of track training and separately for the effect of weight training.</p>
<p>In our dataset, information about athletes’ training is also stored in two variables <code class="docutils literal notranslate"><span class="pre">track_training</span></code> and <code class="docutils literal notranslate"><span class="pre">weight_training</span></code>. Try using the <code class="docutils literal notranslate"><span class="pre">aov()</span></code> function yourself using the formula <code class="docutils literal notranslate"><span class="pre">time</span> <span class="pre">~</span> <span class="pre">track_training</span> <span class="pre">+</span> <span class="pre">weight_training</span></code> in the dataset <code class="docutils literal notranslate"><span class="pre">meet1</span></code> in order to run this factorial ANOVA.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1">#run aov() with the formula time ~ track_training + weight_training</span>
<span class="n">anova_results</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="kc">NULL</span>

<span class="nf">summary</span><span class="p">(</span><span class="n">anova_results</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>In this table, remember we’re getting <span class="math notranslate nohighlight">\(SS_b\)</span> for the effect of each predictor (in the Sum Sq column) as well as <span class="math notranslate nohighlight">\(SS_w\)</span> for the between group variation (that which is not explained by the grouping variables). We also get a corresponding F and p value for each separate predictor that tells us whether there is a significant difference in group means for different levels of that predictor.</p>
<p>That’s how to run a factorial ANOVA to test the differences in marginal means. However, that might not be the full story with our data. We may decide that <span class="math notranslate nohighlight">\(\mu_{.1}\)</span> and <span class="math notranslate nohighlight">\(\mu_{.2}\)</span> are different from each other, but what about <span class="math notranslate nohighlight">\(\mu_{11}\)</span> and <span class="math notranslate nohighlight">\(\mu_{12}\)</span> or <span class="math notranslate nohighlight">\(\mu_{21}\)</span> and <span class="math notranslate nohighlight">\(\mu_{22}\)</span>? Is there always going to be the same difference in running time for different levels of weight training regardless of the value of track training, or might there be an interaction between these two variables?</p>
<p>It is possible to include an interaction in a factorial ANOVA as well. However, since ANOVAs are all about sum of squares, we need to be able to compute a sum of squares for the interaction term as well as the main effects. We won’t deal with the math of how to do this in the ANOVA framework, as you can easily run this factorial ANOVA in R:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1">#same formula as an interaction for a GLM </span>
<span class="n">anova_results</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">aov</span><span class="p">(</span><span class="n">time</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">track_training</span><span class="o">*</span><span class="n">weight_training</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">meet1</span><span class="p">)</span>

<span class="n">anova_results</span>
<span class="nf">summary</span><span class="p">(</span><span class="n">anova_results</span><span class="p">)</span>

<span class="c1">#visualizing interaction</span>
<span class="nf">cat_plot</span><span class="p">(</span><span class="n">anova_results</span><span class="p">,</span><span class="w"> </span><span class="n">pred</span><span class="o">=</span><span class="n">track_training</span><span class="p">,</span><span class="w"> </span><span class="n">modx</span><span class="o">=</span><span class="n">weight_training</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>As you might guess, you can run a comparable test using the GLM. It even uses the same formula:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">summary</span><span class="p">(</span><span class="nf">lm</span><span class="p">(</span><span class="n">time</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">track_training</span><span class="o">*</span><span class="n">weight_training</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">meet1</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Wait, we’ve found another situation where the p-values from the ANOVA analysis don’t exactly match those from the GLM. Before when this happened, this was because of extra multiple comparison corrections in the one-way ANOVA. But at least the model level F-statistics matched in that case. This time we have an even bigger issue - the factorial ANOVA is actually <em>wrong</em>. It’s wrong for a very small, but impactful reason:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">table</span><span class="p">(</span><span class="n">meet1</span><span class="o">$</span><span class="n">condition</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>As we can see here, there aren’t an equal number of data points in each level of each variable. In otherwords, our dataset is <strong>unbalanced</strong>. This isn’t a problem for the GLM - it will still calculate the <span class="math notranslate nohighlight">\(SS_{model}\)</span> and <span class="math notranslate nohighlight">\(SS_{error}\)</span> of the model regardless of how many data points are in each condition. In the GLM then, the p-values we get are correct. But the way <span class="math notranslate nohighlight">\(SS_b\)</span> and <span class="math notranslate nohighlight">\(SS_w\)</span> are calculated in a factorial ANOVA is different, and depends on each group having the same number of datapoints. These <em>should</em> come to the same value as <span class="math notranslate nohighlight">\(SS_{model}\)</span> and <span class="math notranslate nohighlight">\(SS_{error}\)</span>. But if the group sizes aren’t equal, these calculations are wrong and we get wrong p-values. To fix it, we’d have to <a class="reference external" href="https://bookdown.org/ndphillips/YaRrr/type-i-type-ii-and-type-iii-anovas.html">change the math that ANOVAs are based on</a>.</p>
<p>A lot of practicing researchers don’t know this about factorial ANOVAs. In consequence, many who are publishing the results of factorial ANOVAs with unbalanced datasets are reporting incorrect statistics that are hard to replicate. This is another reason why it is often better for you to use a GLM instead of an ANOVA for your analyses. We should really consider this test as outdated now that we have the GLM to handle everything for us.</p>
</section>
<section id="correlation-multiple-regression">
<h2>20.5 Correlation &amp; multiple regression<a class="headerlink" href="#correlation-multiple-regression" title="Permalink to this heading">#</a></h2>
<p>So far we are seeing how we can get similar results with traditional statistical tools as we do with the GLM, and thus use them interchangeably. However, we’ve also learned some situations where GLMs are more flexible and thus a better default to use (e.g., when using unbalanced data and/or multiple pairwise comparisons).</p>
<p>There’s another big limitation to know about for t-tests and ANOVAs - they can only ever handle categorical predictors. These tests were developed to compare group means for classic experimental designs, but they aren’t helpful if you don’t have separate conditions or groups as your manipulation.</p>
<p>To accommodate this, <strong>correlation</strong> was developed. We’ve already learned about this traditional tool, but to review, a correlation expresses the strength of covariance between two quantitative variables. It is calculated as:</p>
<div class="math notranslate nohighlight">
\[r = \frac{\sum(X_i - \bar{X})(Y_i - \bar{Y})}{\sqrt{\sum(X_i - \bar{X})^2 \sum(Y_i - \bar{Y})^2}} \]</div>
<p>In R, we can extract this value easily with the <code class="docutils literal notranslate"><span class="pre">cor()</span></code> function applied to two separate vectors that hold the X and Y variables. For instance, if we are interested in the correlation between an athlete’s height and how fast they run the 400m:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">cor</span><span class="p">(</span><span class="n">meet1</span><span class="o">$</span><span class="n">time</span><span class="p">,</span><span class="w"> </span><span class="n">meet1</span><span class="o">$</span><span class="n">height</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>This is an estimate drawn from a population, meaning we can set a null hypothesis and use inferential statistics to tell us if our estimate likely came from a population with this null hypothesis.</p>
<p>A correlation expresses strength of a relationship between these variables, so our null hypothesis about a correlation is that there is no relationship; r = 0.</p>
<div class="math notranslate nohighlight">
\[H_0: r = 0\]</div>
<p>To test this hypothesis, the sampling distribution of r scores also has the t-distribution shape. To calculate a t-score for a correlation:</p>
<div class="math notranslate nohighlight">
\[t = \frac{r}{\sqrt{1-r^2}}\sqrt{n-2}\]</div>
<p>In R, we can get this value and the associated p, as well as the correlation estimate, using the <code class="docutils literal notranslate"><span class="pre">cor.test()</span></code> function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">cor.test</span><span class="p">(</span><span class="n">meet1</span><span class="o">$</span><span class="n">time</span><span class="p">,</span><span class="w"> </span><span class="n">meet1</span><span class="o">$</span><span class="n">height</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>In APA format, we’d report the results of this analysis like so: “there was no significant correlation between an athlete’s height and their running time, <em>r</em>(37) = 0.129, <em>p</em> = 0.433.”</p>
<p>Now as we learned previously, there isn’t really a need to do this if we already know how to use the GLM. We can get this exact same answer if we simply perform a simple linear regression between the z-scored values of these variables:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1">#z-scoring the variables within the lm() call</span>
<span class="nf">summary</span><span class="p">(</span><span class="nf">lm</span><span class="p">(</span><span class="nf">scale</span><span class="p">(</span><span class="n">time</span><span class="p">)</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="nf">scale</span><span class="p">(</span><span class="n">height</span><span class="p">),</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">meet1</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Notably, we don’t even have to scale the variables if all we care about is looking at the p-value. The significance of the predictor’s effect is the same regardless of the units it’s in.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1">#raw versions of the variables</span>
<span class="nf">summary</span><span class="p">(</span><span class="nf">lm</span><span class="p">(</span><span class="n">time</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">height</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">meet1</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>A correlation can only handle relationships between two variables - one predictor and one outcome. To be able to integrate the effects of multiple quantitative predictors, that is what <strong>multiple regression</strong> and the general linear model was developed to do. Only at that point did people realize all the prior tests can also be answered with this same framework. All hail the GLM!</p>
</section>
<section id="chi-square">
<h2>20.6 Chi-square<a class="headerlink" href="#chi-square" title="Permalink to this heading">#</a></h2>
<p>You now know about a great many ways to analyze data - categorical or quantitative predictors, one or multiple, with main effects or interactions. You also now know multiple versions for each of these kinds of analysis, using either the GLM or traditional statistical tools. You’ve done a lot of work to get this far!</p>
<p>But this is an <em>Intro</em> to Psychological Statistics course, which means there’s still a lot of stuff we haven’t even touched on. So much to learn, so little time. We won’t learn these additional analyses in detail, but there are two categories of analyses we haven’t covered that are still fairly common in psychology research. So you should at least know about them and why they are different. We’ll do an overview of those here.</p>
<p>Firstly: across all the types of models and tests we’ve learned so far, one thing has been constant - we’ve always been predicting a <em>quantitative</em> outcome variable. But there are research questions concerning categorical outcome variables as well. What political party is someone likely to join, whether or not someone is admitted to college, etc. For this example, let’s load in a dataset of hospital patients and see how their levels of anemia relate to their appetite:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">patient_data</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">read.csv</span><span class="p">(</span><span class="s">&quot;https://raw.githubusercontent.com/smburns47/Psyc158/main/ckd.csv&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">    </span><span class="nf">select</span><span class="p">(</span><span class="n">Appetite</span><span class="p">,</span><span class="w"> </span><span class="n">Anemia</span><span class="p">)</span>
<span class="nf">head</span><span class="p">(</span><span class="n">patient_data</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>In these data, values for both of these variables were stored categorically. One <em>could</em> imagine recording severity of anemia and strength of appetite as quantitative, but that’s not the data we have here. Patients were only coded as having anemia or not, and a good or poor appetite. Thus, we don’t have any information about the quantitative difference between these variable levels. They are categorical.</p>
<p>Using a regression, t-test, ANOVA, etc. to predict a categorical outcome variable is not appropriate. This is because these models require numeric variation in outcome score values to calculate means, predictions, and residuals. If we built a model for a categorical outcome variable in the same way, our residuals would only ever have two values - correct prediction, or incorrect. The equations for sum of squares would break over this.</p>
<p>Thus, we need a different approach. For situations where you have a categorical predictor and categorical outcome, traditional statisticians developed a tool called the <strong>chi-square test</strong>. This test solves our problem of categorical data by reasoning about <em>probabilities</em> of certain values, rather than the values themselves.</p>
<p>Let’s break down how to do this. First, we can see that each person falls into one of four groups - either they have anemia or not, and they have a good appetite or not. We can put the number of people in each of these groups in a table like so, called a <strong>contingency table</strong>:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-center"><p></p></th>
<th class="head text-center"><p>Anemia</p></th>
<th class="head text-center"><p>No anemia</p></th>
<th class="head text-center"><p>Row total</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><strong>Good appetite</strong></p></td>
<td class="text-center"><p>6</p></td>
<td class="text-center"><p>133</p></td>
<td class="text-center"><p>139</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><strong>Bad appetite</strong></p></td>
<td class="text-center"><p>10</p></td>
<td class="text-center"><p>9</p></td>
<td class="text-center"><p>19</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p><strong>Column total</strong></p></td>
<td class="text-center"><p>16</p></td>
<td class="text-center"><p>142</p></td>
<td class="text-center"><p>158</p></td>
</tr>
</tbody>
</table>
<p>This is similar to the means table from our ANOVA example, except now these numbers are group and marginal counts instead of group and marginal means. From these counts, we can calculate what proportion of people in the dataset are in each group. ~4% of the people in this data are anemic with a good appetite (6/158) while 6% are anemic with a bad appetite (10/158). These numbers are small, but that’s because not many of our patients are anemic. If we looked at the anemic patients only, 37.5% have a good appetite (6/16) while 62.5% don’t (10/16).</p>
<p>If we thought anemia was unrelated to appetite, we might expect some people with anemia to have a good appetite and some to have a poor appetite. Further, we’d expect the <em>proportion</em> of people with good/poor appetites to be the same regardless of whether or not someone has anemia. In otherwords, knowing someone’s anemia status doesn’t change our prediction of how likely they are to have a poor appetite. This is the null hypothesis for a chi-square test. Formally, if P stands for probability:</p>
<div class="math notranslate nohighlight">
\[H_0: P_{(poor|anemic)} = P_{(poor|not anemic)}\]</div>
<p>However, instead we might actually believe that having anemia increases your risk of a poor appetite. In this case, we’d expect the <em>probability</em> of having a poor appetite to be different in the anemia condition compared to the no-anemia condition. A <span class="math notranslate nohighlight">\(\chi^2\)</span> or chi-statistic (pronounced “kai-square”) represents the ratio difference in these probabilities.</p>
<p>That’s what we’d expect from the population of people with anemia and appetites. But of course, our sample is just a subset of the population, so the actual proportions of these values in our data might be slightly different even if the null hypothesis is true. The sampling distribution of <span class="math notranslate nohighlight">\(\chi^2\)</span> looks like so, depending on how many rows and columns in the contingency table that you have (k = (r-1)(c-1)):</p>
<img src="images/ch20-chisquare.png" width="500">
<p>While 62.5% of anemic patients had a poor appetite, only 6.3% of non-anemic patients did (9/142). Is this a big enough difference in the probability of a poor appetite between the two conditions to consider them to come from different populations? A chi-square test calculates a chi-square statistic for your sample and then finds an associated p-value for how likely it is your sample came from a population with no difference in group probabilities.</p>
<p>To perform a chi-square test in R, we can use the <code class="docutils literal notranslate"><span class="pre">chisq.test()</span></code> function with two separate vectors that each hold the values for the predictor and outcome variables.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">chisq.test</span><span class="p">(</span><span class="n">patient_data</span><span class="o">$</span><span class="n">Appetite</span><span class="p">,</span><span class="w"> </span><span class="n">patient_data</span><span class="o">$</span><span class="n">Anemia</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We’d report this result in APA format as: “there is a significant association between patient anemia and their appetite, <span class="math notranslate nohighlight">\(\chi^2\)</span>(1) = 37.728, <em>p</em> &lt; 0.001.”</p>
<p>There is a way to generalize this and perform the same test with the general linear model. Doing so is called a <strong>logistic regression</strong> which you can learn more about <a class="reference external" href="http://localhost:8888/notebooks/adv-logistic.ipynb">here</a>.</p>
</section>
<section id="repeated-measures-tests">
<h2>20.7 Repeated measures tests<a class="headerlink" href="#repeated-measures-tests" title="Permalink to this heading">#</a></h2>
<p>There’s another broad category of analyses that we’ve also ignored in this class. Recall last chapter when we discussed the assumptions of the general linear model. These assumptions hold for the above set of tools as well. This means we need a different approach if our data has <strong>repeated measures</strong>, or data points that are not completely independent of each other.</p>
<p>This simplest version of this situation is when you have two scores per person - you did a within-subjects experiment where you measured something about them before treatment, and then again on the same variable after treatment. You want to know if scores on average changed from before to after. For example, going back to our track training data, we may wonder if our athletes continued to improve between meet 1 and meet 2.</p>
<p>Your first instinct might be to do an independent samples t-test for the scores during meet 1 and the scores during meet 2:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">meet1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">filter</span><span class="p">(</span><span class="n">trackscores</span><span class="p">,</span><span class="w"> </span><span class="n">session</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s">&#39;meet1&#39;</span><span class="p">)</span>
<span class="n">meet2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">filter</span><span class="p">(</span><span class="n">trackscores</span><span class="p">,</span><span class="w"> </span><span class="n">session</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s">&#39;meet2&#39;</span><span class="p">)</span>

<span class="c1">#use t.test() to compare the mean of meet1$time with the mean of meet2$time</span>
<span class="nf">t.test</span><span class="p">(</span><span class="c1">#YOUR CODE HERE)</span>
</pre></div>
</div>
</div>
</div>
<p>R doesn’t stop you from doing this, but it is incorrect. This is because the independent samples t-test assumes, well, that the samples are independent. That they contain completely separate sets of people. If this isn’t actually true of your data, the analysis will be wrong.</p>
<p>In contrast, a <strong>paired-samples t-test</strong> is for when you have non-independent data. This test looks at the <em>change</em> in scores within a person to see if the mean of that change is non-zero.</p>
<p>To run a paired-samples t-test in R, we can still use the <code class="docutils literal notranslate"><span class="pre">t.test()</span></code> function while adding a <code class="docutils literal notranslate"><span class="pre">paired=TRUE</span></code> argument.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">t.test</span><span class="p">(</span><span class="n">meet1</span><span class="o">$</span><span class="n">time</span><span class="p">,</span><span class="w"> </span><span class="n">meet2</span><span class="o">$</span><span class="n">time</span><span class="p">,</span><span class="w"> </span><span class="n">var.equal</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">paired</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The degrees of freedom here is less because we technically don’t have 78 unique points of data - we have 39 unique people, measured twice. But our p-value is much lower because this other way of measuring differences in scores results in a much bigger mean difference.</p>
<p>We can also do a paired-samples t-test with the GLM. We just have to calculate this change score ourselves, and then test the size of <span class="math notranslate nohighlight">\(b_0\)</span> in a null model (i.e., is this change score significantly different than 0):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">score_change</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">meet2</span><span class="o">$</span><span class="n">time</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">meet1</span><span class="o">$</span><span class="n">time</span>

<span class="nf">summary</span><span class="p">(</span><span class="nf">lm</span><span class="p">(</span><span class="n">score_change</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="kc">NULL</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>An extension of a paired-samples t-test is when you have some predictor variables that may be influencing the size of the score difference within a person. If that predictor variable(s) is categorical, we can use a <strong>repeated measures ANOVA</strong>. If the predictor variable(s) is quantitative, we can use a version of multiple regression known as <strong>mixed-effects modeling</strong>.</p>
<p>Entire classes can be taught on these last two sections (categorical outcomes and repeated measures). Maybe some day you will take an advanced stats class and learn more about them. For now, just know why we need to use different tools for these situations.</p>
</section>
<section id="summary-of-tests">
<h2>20.8 Summary of tests<a class="headerlink" href="#summary-of-tests" title="Permalink to this heading">#</a></h2>
<p>Altogether, the purpose of this chapter is to acquaint you with the most common statistical tools used in psychology, and help you understand how they map onto the GLM framework that you already know. This way if you encounter these tests in published research, you’ll know what sort of hypothesis is being tested and you’ll know how to replicate it yourself, either with that same test or the GLM. You should also now have an appreciation of why we learned the GLM in this class first: it doesn’t rely solely on hypothesis testing, and it is more flexible for various situations than these more rigid tools.</p>
<p>For ease of memory, here is all the important information of this chapter stored in one table. It tells you when to use various tests and what the comparable GLM version is. This would make a great reference sheet for you to keep for the rest of this class and beyond.</p>
<img src="images/ch20-testreference.png" width="800"></section>
<section id="chapter-summary">
<h2>Chapter summary<a class="headerlink" href="#chapter-summary" title="Permalink to this heading">#</a></h2>
<p>After reading this chapter, you should be able to:</p>
<ul class="simple">
<li><p>perform t-tests, ANOVAs, and correlations</p></li>
<li><p>conduct GLM models that give you the same answers as these traditional tools</p></li>
<li><p>Identify which tests to use when the outcome variable is categorical</p></li>
<li><p>Identify which tests to use when there are repeated measures</p></li>
</ul>
<p><a class="reference external" href="https://colab.research.google.com/github/smburns47/Psyc158/blob/main/chapter-21.ipynb">Next: Chapter 21 - Alternate Approaches - Bayesian Statistics</a></p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "smburns47/Psyc158",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "r"
        },
        kernelOptions: {
            name: "ir",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'ir'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#one-sample-t-test">20.1 One-sample t-test</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#independent-samples-t-test">20.2 Independent-samples t-test</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#one-way-anova">20.3 One-way ANOVA</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#factorial-anova">20.4 Factorial ANOVA</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#correlation-multiple-regression">20.5 Correlation &amp; multiple regression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#chi-square">20.6 Chi-square</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#repeated-measures-tests">20.7 Repeated measures tests</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary-of-tests">20.8 Summary of tests</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#chapter-summary">Chapter summary</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Shannon Burns
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>